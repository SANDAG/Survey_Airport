{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef4bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath(\"../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed990b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import ValidationError\n",
    "import data_model\n",
    "import enums as e\n",
    "from utils import extract_base_type, add_enum_label_columns, add_list_objects, add_synthetic_records, map_zones\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fd4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_model)\n",
    "importlib.reload(e)\n",
    "from data_model import Respondent, Employee, AirPassenger, Trip, DepartingPassengerResident, DepartingPassengerVisitor, ArrivingPassengerResident, ArrivingPassengerVisitor, DepartingAirPassenger, ArrivingAirPassenger, Resident, Visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2759821",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dir = \"../data/external\"\n",
    "interim_dir = \"../data/interim\"\n",
    "processed_dir = \"../data/processed\"\n",
    "\n",
    "# input_file1 = os.path.join(external_dir, \"etc/od_20250226_sandag_airport_draftfinal.xlsx\") # latest\n",
    "# input_file2 = os.path.join(external_dir, \"etc/od_20250226_sandag_airport_pilotdata.xlsx\") #older version but records needed\n",
    "# input_file3 = os.path.join(external_dir, \"etc/od_20250131_sandag_airport_sas_draftinal.xlsx\")\n",
    "# input_file4 = os.path.join(external_dir, \"etc/SP_rating_questions_data_022125.csv\")\n",
    "\n",
    "input_file1 = os.path.join(external_dir, \"etc/od_20250314_sandag_airport_draftfinal.xlsx\") # latest\n",
    "input_file2 = os.path.join(external_dir, \"etc/od_20250314_sandag_airport_pilotdata.xlsx\") #older version but records needed\n",
    "input_file3 = os.path.join(external_dir, \"etc/od_20253014_sandag_airport_sas_draftinal.xlsx\")\n",
    "input_file4 = os.path.join(external_dir, \"etc/ATC_airport_travel_survey_SP_data_03072025.xlsx\")\n",
    "\n",
    "variable_map_file = os.path.join(processed_dir, \"revised_names.csv\")\n",
    "clean_survey_file = os.path.join(interim_dir, \"survey_data_clean.csv\")\n",
    "output_csv_filename = os.path.join(processed_dir, \"data_model_output.csv\")\n",
    "#summary_csv_filename = os.path.join(processed_dir, \"data_model_output_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f389d5",
   "metadata": {},
   "source": [
    "### Clean Data , Rename fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2cf10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2624854089.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['is_completed'] = 1\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2624854089.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight'] = 1\n"
     ]
    }
   ],
   "source": [
    "in_df_complete1 = pd.read_excel(input_file1, sheet_name = 0)\n",
    "in_df_incomplete1 = pd.read_excel(input_file1, sheet_name = 1)\n",
    "\n",
    "in_df_complete2 = pd.read_excel(input_file2, sheet_name = 0)\n",
    "in_df_incomplete2 = pd.read_excel(input_file2, sheet_name = 1)\n",
    "\n",
    "in_df_complete3 = pd.read_excel(input_file3, sheet_name = 0)\n",
    "in_df_incomplete3 = pd.read_excel(input_file3, sheet_name = 1)\n",
    "\n",
    "#in_df_sp = pd.read_csv(input_file4, encoding = 'latin1')\n",
    "in_df_sp = pd.read_excel(input_file4, sheet_name = 1)\n",
    "\n",
    "in_df_complete2['is_self_administered'], in_df_incomplete2['is_self_administered'] = False, False\n",
    "in_df_complete1['is_self_administered'], in_df_incomplete1['is_self_administered'] = False, False\n",
    "in_df_complete3['is_self_administered'], in_df_incomplete3['is_self_administered'] = True, True\n",
    "\n",
    "\n",
    "header_df = pd.read_csv(variable_map_file)[['ETC_name','WSP_name']]\n",
    "header_dict = pd.Series(header_df.WSP_name.values,index=header_df.ETC_name).to_dict()\n",
    "\n",
    "in_df_complete1 = in_df_complete1.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_complete2 = in_df_complete2.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_complete3 = in_df_complete3.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "\n",
    "\n",
    "in_df_incomplete1 = in_df_incomplete1.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_incomplete2 = in_df_incomplete2.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_incomplete3 = in_df_incomplete3.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_sp = in_df_sp.rename(columns=header_dict).copy()\n",
    "\n",
    "\n",
    "in_df_complete = pd.concat([in_df_complete1, in_df_complete2, in_df_complete3], ignore_index = True)\n",
    "in_df_incomplete = pd.concat([in_df_incomplete1, in_df_incomplete2, in_df_incomplete3], ignore_index = True)\n",
    "\n",
    "in_df_complete['is_completed'] = 1\n",
    "in_df_incomplete['is_completed'] = 0\n",
    "\n",
    "in_df_complete['weight'] = 1\n",
    "in_df_incomplete['weight'] = 0\n",
    "\n",
    "#Concat incomplete and complete dataframes\n",
    "clean_df = pd.concat([in_df_complete, in_df_incomplete], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f2b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_self_administered\n",
       "False    8997\n",
       "True      955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['is_self_administered'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab00dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Records:  (5378, 329)\n",
      "Incomplete Records:  (4574, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Complete Records: \", in_df_complete.shape)\n",
    "print(\"Incomplete Records: \", in_df_incomplete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1dec692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9952, 330)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53c5017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5934"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_df['respondentid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e9c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5934, 330)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the duplicate respondentids\n",
    "clean_df.drop_duplicates('respondentid', keep = 'first', inplace = True)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9b4683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5378, 330)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['is_completed']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd74b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates from SP\n",
    "in_df_sp = in_df_sp.drop_duplicates(subset=['respondentid'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee2362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge SP\n",
    "clean_df = clean_df.merge(in_df_sp, on=\"respondentid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1686f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5934, 396)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c75691",
   "metadata": {},
   "source": [
    "#### Add Zones Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5414e88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(origin_pmsa\n",
       " 2     1586\n",
       " 3     1316\n",
       " 1      723\n",
       " 6      460\n",
       " 99     449\n",
       " 4      330\n",
       " 5      311\n",
       " 7      196\n",
       " 8        7\n",
       " Name: count, dtype: int64,\n",
       " destination_pmsa\n",
       " 2     5208\n",
       " 3       50\n",
       " 1       42\n",
       " 99      40\n",
       " 6       17\n",
       " 5       13\n",
       " 4        6\n",
       " 7        2\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PMSA\n",
    "pmsa_zones_shapefile = \"../data/external/geometry/pmsa_geoms/pmsa_geoms.shp\"\n",
    "clean_df['origin_pmsa'] = map_zones(clean_df, 'origin_latitude', 'origin_longitude', pmsa_zones_shapefile, 'pseudomsa', 99)\n",
    "clean_df['destination_pmsa'] = map_zones(clean_df, 'destination_latitude', 'destination_longitude', pmsa_zones_shapefile, 'pseudomsa', 99)\n",
    "clean_df['origin_pmsa'].value_counts(), clean_df['destination_pmsa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93bb5c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(origin_municipal_zone\n",
       " SAN DIEGO         3431\n",
       " EXTERNAL           449\n",
       " S.D. COUNTY        260\n",
       " CHULA VISTA        233\n",
       " CARLSBAD           168\n",
       " OCEANSIDE          141\n",
       " CORONADO           112\n",
       " ESCONDIDO           77\n",
       " ENCINITAS           74\n",
       " LA MESA             72\n",
       " EL CAJON            59\n",
       " NATIONAL CITY       57\n",
       " POWAY               47\n",
       " SAN MARCOS          42\n",
       " VISTA               38\n",
       " DEL MAR             30\n",
       " LEMON GROVE         27\n",
       " IMPERIAL BEACH      26\n",
       " SANTEE              21\n",
       " SOLANA BEACH        14\n",
       " Name: count, dtype: int64,\n",
       " destination_municipal_zone\n",
       " SAN DIEGO        5293\n",
       " EXTERNAL           40\n",
       " EL CAJON            7\n",
       " S.D. COUNTY         6\n",
       " CARLSBAD            6\n",
       " CHULA VISTA         5\n",
       " OCEANSIDE           5\n",
       " CORONADO            4\n",
       " NATIONAL CITY       3\n",
       " LA MESA             3\n",
       " ENCINITAS           3\n",
       " POWAY               2\n",
       " SOLANA BEACH        1\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Municipal Zones\n",
    "municipal_zones_shapefile = \"../data/external/geometry/Municipal_Boundaries/Municipal_Boundaries.shp\"\n",
    "clean_df['origin_municipal_zone'] = map_zones(clean_df, 'origin_latitude', 'origin_longitude', municipal_zones_shapefile, 'name', 'EXTERNAL')\n",
    "clean_df['destination_municipal_zone'] = map_zones(clean_df, 'destination_latitude', 'destination_longitude', municipal_zones_shapefile, 'name', 'EXTERNAL')\n",
    "clean_df['origin_municipal_zone'].value_counts(), clean_df['destination_municipal_zone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df51c19",
   "metadata": {},
   "source": [
    "### Commonly occuring invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d47497",
   "metadata": {},
   "source": [
    "### Making all modes consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec161a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egress_mode_label\n",
       "Walk                                 30\n",
       "Picked up by car by family/friend    15\n",
       "Drive alone and park                  2\n",
       "Uber/Lyft                             2\n",
       "Taxi                                  2\n",
       "Other shared van (please specify)     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['egress_mode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f794079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "DROPPED OFF BY CAR BY FRIEND FAMILY               242\n",
       "UBER LYFT                                         107\n",
       "DROVE ALONE AND PARKED                             42\n",
       "DROVE WITH OTHERS AND PARKED                       28\n",
       "OTHER PUBLIC TRANSIT                               24\n",
       "RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY     22\n",
       "TAXI                                               14\n",
       "RENTAL CAR AND PARKED IT                           11\n",
       "WHEELCHAIR OR OTHER MOBILITY DEVICE                11\n",
       "WALK                                                9\n",
       "Public transit                                      5\n",
       "Uber / Lyft                                         5\n",
       "CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR            4\n",
       "Rental car and dropped it off at rental agency      4\n",
       "HOTEL SHUTTLE VAN                                   3\n",
       "Drove alone and parked                              2\n",
       "RODE WITH OTHER TRAVELER AND PARKED                 2\n",
       "NON ELECTRIC BIKESHARE                              2\n",
       "Personal e-scooter                                  2\n",
       "OTHER SHARED RIDE VAN SERVICE                       1\n",
       "PERSONAL NON ELECTRIC BICYCLE                       1\n",
       "Walk                                                1\n",
       "Taxi                                                1\n",
       "CHARTERED TOUR BUS                                  1\n",
       "EMPLOYEE SHUTTLE                                    1\n",
       "ELECTRIC BIKESHARE                                  1\n",
       "Other                                               1\n",
       "Car service / Black car / Limo / Executive car      1\n",
       "E scooter share                                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70042bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_airport_accessmode_label_map = {\n",
    "    'Walk': 'Walk',\n",
    "    'Wheelchair or other mobility device': 'Wheelchair or other mobility device',\n",
    "    'ELECTRIC BIKESHARE': 'Bicycle: electric bikeshare',\n",
    "    'NON ELECTRIC BIKESHARE': 'Bicycle: non-electric bikeshare',\n",
    "    'E SCOOTER SHARE': 'E-scooter: shared',\n",
    "    'PERSONAL ELECTRIC BICYCLE': 'Bicycle: personal electric bicycle',\n",
    "    'PERSONAL NON ELECTRIC BICYCLE': 'Bicycle: personal non-electric bicycle',\n",
    "    'PERSONAL E SCOOTER': 'E-scooter: personal',\n",
    "    'Taxi': 'Taxi',\n",
    "    'UBER LYFT': 'Uber/Lyft',\n",
    "    'CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR': 'Car service/black car/limo/executive car',\n",
    "    'DROPPED OFF BY CAR BY FRIEND FAMILY': 'Dropped off by car by family/friend',\n",
    "    'Drove alone and parked': 'Drove alone and parked',\n",
    "    'Drove with others and parked': 'Drove with others and parked',\n",
    "    'RODE WITH OTHER TRAVELER AND PARKED': 'Rode with other traveler(s) and parked',\n",
    "    'Other public transit': 'Other public transit',\n",
    "    'Chartered tour bus': 'Chartered tour bus',\n",
    "    'Employee shuttle': 'Employee shuttle',\n",
    "    'RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY': 'Rental car: Dropped off at rental agency',\n",
    "    'RENTAL CAR AND PARKED IT': 'Rental car: parked rental car',\n",
    "    'Hotel shuttle van': 'Hotel shuttle van',\n",
    "    'OTHER SHARED RIDE VAN SERVICE': 'Other shared van (please specify)',\n",
    "    'Other': 'Other',\n",
    "    'Refused/No Answer': 'Refused/No Answer'\n",
    "}\n",
    "clean_df['other_airport_accessmode_label'] = clean_df['other_airport_accessmode_label'].map(other_airport_accessmode_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb3b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Drove alone and parked                        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Taxi                                          1\n",
       "Walk                                          1\n",
       "Other                                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05df29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_dict = {\n",
    "    'Walk': 1,\n",
    "    'Wheelchair or other mobility device': 2,\n",
    "    'Bicycle: electric bikeshare': 3,\n",
    "    'Bicycle: non-electric bikeshare': 4,\n",
    "    'E-scooter: shared': 5,\n",
    "    'Bicycle: personal electric bicycle': 6,\n",
    "    'Bicycle: personal non-electric bicycle': 7,\n",
    "    'E-scooter: personal': 8,\n",
    "    'Taxi': 9,\n",
    "    'Uber/Lyft': 10,\n",
    "    'Car service/black car/limo/executive car': 11,\n",
    "    'Dropped off by car by family/friend': 12,\n",
    "    'Drove alone and parked': 13,\n",
    "    'Drove with others and parked': 14,\n",
    "    'MTS Route 992': 15,\n",
    "    'Airport flyer shuttle': 16,\n",
    "    'Chartered tour bus': 17,\n",
    "    'Employee shuttle': 18,\n",
    "    'Rental car: Dropped off at rental agency': 19,\n",
    "    'Rental car: parked rental car': 20,\n",
    "    'Hotel shuttle van': 21,\n",
    "    'Other shared van (please specify)': 22,\n",
    "    'Picked up by car by family/friend': 23,\n",
    "    'Get in a parked vehicle and drive alone': 24,\n",
    "    'Get in a parked vehicle and drive with others': 25,\n",
    "    'Get in a parked vehicle and ride with other traveler(s)': 26,\n",
    "    'Rental car: Picked up at rental agency': 27,\n",
    "    'Rental car: get in a parked rental car': 28,\n",
    "    'Rode with other traveler(s) and parked': 29,\n",
    "    'Other public transit': 30,\n",
    "    'Public Transit': 30,\n",
    "    'Other': 98,\n",
    "    'Refused/No Answer': 99,\n",
    "    'None of the above': 98\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07974c0f",
   "metadata": {},
   "source": [
    "### Modes to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4be478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_code_columns = ['main_transit_mode', 'main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "mode_label_columns = ['main_transit_mode_label', 'main_mode_label', 'access_mode_label', 'egress_mode_label', 'reverse_mode_label', 'reverse_mode_predicted_label', 'other_airport_accessmode_label', 'reverse_commute_mode_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cf0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping codes using label strings\n",
    "travel_mode_dict = {k.lower(): v for k, v in travel_mode_dict.items()}\n",
    "for mode_code_col, mode_label_col in zip(mode_code_columns, mode_label_columns):\n",
    "    # Apply the mapping for each pair of columns\n",
    "    clean_df[mode_code_col] = clean_df[mode_label_col].str.lower().map(travel_mode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d33510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Drove alone and parked                        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Taxi                                          1\n",
       "Walk                                          1\n",
       "Other                                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2195ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode\n",
       "12.0    242\n",
       "10.0    107\n",
       "19.0     22\n",
       "20.0     11\n",
       "11.0      4\n",
       "29.0      2\n",
       "13.0      2\n",
       "4.0       2\n",
       "7.0       1\n",
       "22.0      1\n",
       "3.0       1\n",
       "9.0       1\n",
       "1.0       1\n",
       "98.0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b31b5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_transit_mode\n",
       "98.0    4919\n",
       "16.0     249\n",
       "15.0     209\n",
       "99.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['main_transit_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfbb23",
   "metadata": {},
   "source": [
    "### Pre-processing of some fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ce82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\495989901.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  clean_df.replace('-oth-', 98, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "clean_df['date_completed'] = pd.to_datetime(clean_df['date_completed'])\n",
    "clean_df['is_pilot'] = np.where(clean_df['date_completed'].dt.date<=datetime.date(2024, 10, 3), 1, 0)\n",
    "clean_df['record_type_synthetic'] = 0\n",
    "clean_df.replace('-oth-', 98, inplace=True)\n",
    "clean_df.replace('-', None, inplace = True )\n",
    "clean_df['is_income_below_poverty'] = np.where(clean_df['is_income_below_poverty'] == 0, 2, clean_df['is_income_below_poverty'])\n",
    "clean_df['household_income'] = np.where(clean_df['household_income']=='13B', 17, clean_df['household_income'] )\n",
    "\n",
    "clean_df['stay_informed'] = np.where(clean_df['stay_informed'] == 0, 2, clean_df['stay_informed'])\n",
    "#Maps\n",
    "interview_location_map = {'Term1' : 1, 'Term2': 2, 'MTS_1_992': 3, 'SDA_1_FLYER': 4, 'ConracShuttle': 5, 'ParkingShuttle': 6, 'EmplParking': 7, '-oth-':98} \n",
    "inbound_outbound_map = {'IN':1, 'OUT':2}\n",
    "\n",
    "#route_fields:\n",
    "route_fields = ['to_airport_transit_route_1', 'to_airport_transit_route_2', 'to_airport_transit_route_3', 'to_airport_transit_route_4',\n",
    "                'from_airport_transit_route_1', 'from_airport_transit_route_2', 'from_airport_transit_route_3', 'from_airport_transit_route_4']\n",
    "\n",
    "#Replacement\n",
    "clean_df['interview_location'] = clean_df['interview_location'].map(interview_location_map)\n",
    "clean_df['inbound_or_outbound'] = clean_df['inbound_or_outbound'].map(inbound_outbound_map)\n",
    "clean_df['main_mode'] = np.where(clean_df['main_transit_mode'].isin([15,16]), clean_df['main_transit_mode'], clean_df['main_mode'])\n",
    "\n",
    "clean_df[route_fields] = clean_df[route_fields].replace(98, 'OTHER')\n",
    "clean_df['nights_visited'] = clean_df['nights_visited'] - 1\n",
    "\n",
    "clean_df['same_commute_mode'] = np.where(clean_df['same_commute_mode'] == 0, 2, clean_df['same_commute_mode'])\n",
    "clean_df['resident_visitor_followup'] = np.where(clean_df['resident_visitor_followup'] == 0, 2, clean_df['resident_visitor_followup'])\n",
    "\n",
    "#activity_type\n",
    "clean_df['origin_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.OUTBOUND_FROM_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['origin_activity_type'])\n",
    "clean_df['destination_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.INBOUND_TO_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['destination_activity_type'])\n",
    "\n",
    "#For incomplete records:\n",
    "clean_df['marketsegment'] = clean_df['marketsegment'].fillna(99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f315a",
   "metadata": {},
   "source": [
    "### Fix main_mode to not take EMPLOYEE_SHUTTLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815c14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['main_mode'] = np.where(\n",
    "    clean_df['main_mode'] == e.TravelMode.EMPLOYEE_SHUTTLE,\n",
    "    np.where(\n",
    "        clean_df['marketsegment'] == e.Type.PASSENGER,\n",
    "        e.TravelMode.OTHER,\n",
    "        np.where(\n",
    "            clean_df['marketsegment'] == e.Type.EMPLOYEE,\n",
    "            clean_df['reverse_commute_mode'],\n",
    "            clean_df['main_mode']  # fallback if neither condition is met\n",
    "        )\n",
    "    ),\n",
    "    clean_df['main_mode']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ba9f2",
   "metadata": {},
   "source": [
    "### Re-assign some main_mode_others to main_mode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b1c8d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketsegment_label                             main_mode_other                                           \n",
       "Air passenger                                   Hospital shuttle                                              2\n",
       "                                                Medical shuttle                                               2\n",
       "                                                Refugee shuttle                                               2\n",
       "Employee working at the airport                 Motorcycle                                                    2\n",
       "Air passenger                                   Bus                                                           1\n",
       "                                                Connecting flights                                            1\n",
       "                                                Airplane                                                      1\n",
       "                                                Medical                                                       1\n",
       "                                                Flew in                                                       1\n",
       "                                                Personal car                                                  1\n",
       "                                                Paratransit                                                   1\n",
       "                                                Shelter                                                       1\n",
       "                                                Stayed with family near airport and they drove me             1\n",
       "                                                Team bus                                                      1\n",
       "                                                Personal shuttle                                              1\n",
       "                                                Turo                                                          1\n",
       "                                                Work                                                          1\n",
       "Airport employee (including airline employees)  Flight                                                        1\n",
       "                                                Flew                                                          1\n",
       "                                                Mts blue line                                                 1\n",
       "                                                Route 10 and then Employee Shuttle                            1\n",
       "Employee working at the airport                 Telecommute Day but on a working day I use the hours below    1\n",
       "                                                Work from home today                                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[['marketsegment_label', 'main_mode_other']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d1d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes which are invalid, should make main_mode blank, and hence throw a critical validation error\n",
    "# Some of the modes can stay as they are (i.e., OTHER) - Like, Refugee Shuttle, Hospital Shuttle, Medical Shuttle. \n",
    "# Others can be classified - for example \n",
    "# Mapping for reclassification\n",
    "mode_mapping = {\n",
    "    \"Hospital shuttle\": e.TravelMode.OTHER,\n",
    "    \"Medical shuttle\": e.TravelMode.OTHER,\n",
    "    \"Refugee shuttle\": e.TravelMode.OTHER,\n",
    "    \"Motorcycle\": e.TravelMode.OTHER,\n",
    "    \"Bus\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Connecting flights\": None,\n",
    "    \"Airplane\": None,\n",
    "    \"Flew in\": None,\n",
    "    \"Medical\": e.TravelMode.OTHER,\n",
    "    \"Personal car\": e.TravelMode.DROVE_ALONE_AND_PARKED,\n",
    "    \"Paratransit\": e.TravelMode.OTHER,\n",
    "    \"Shelter\": None,\n",
    "    \"Stayed with family near airport and they drove me\": e.TravelMode.DROPPED_OFF_BY_FAMILY_FRIEND,\n",
    "    \"Team bus\": e.TravelMode.CHARTERED_TOUR_BUS,\n",
    "    \"Personal shuttle\": e.TravelMode.OTHER_SHARED_VAN,\n",
    "    \"Turo\": e.TravelMode.RENTAL_CAR_PICKED_UP,\n",
    "    \"Work\": None,\n",
    "    \"Flight\": None,\n",
    "    \"Flew\": None,\n",
    "    \"Mts blue line\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Route 10 and then Employee Shuttle\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Telecommute Day but on a working day I use the hours below\": None,\n",
    "    \"Work from home today\": None\n",
    "}\n",
    "\n",
    "# Create a mapped column without modifying main_mode yet\n",
    "# Create a mapped column\n",
    "mapped_modes = clean_df[\"main_mode_other\"].map(mode_mapping)\n",
    "\n",
    "# Update main_mode where main_mode_other exists in mode_mapping (including None values)\n",
    "clean_df.loc[clean_df[\"main_mode_other\"].isin(mode_mapping.keys()), \"main_mode\"] = mapped_modes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "766defc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "        ..\n",
       "5929   NaN\n",
       "5930   NaN\n",
       "5931   NaN\n",
       "5932   NaN\n",
       "5933   NaN\n",
       "Name: main_mode_other, Length: 5934, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdda2d",
   "metadata": {},
   "source": [
    "### Create Grouped Modes\n",
    "This section creates grouped modes for better readability and analysis. Particularly, it makes modes direction-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "773afd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_to_grouped = {\n",
    "    e.TravelMode.WALK: e.TravelModeGrouped.WALK,\n",
    "    e.TravelMode.WHEELCHAIR_OR_MOBILITY_DEVICE: e.TravelModeGrouped.WHEELCHAIR_OR_OTHER_MOBILITY_DEVICE,\n",
    "    e.TravelMode.BICYCLE_ELECTRIC_BIKESHARE: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.BICYCLE_NON_ELECTRIC_BIKESHARE: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.BICYCLE_PERSONAL_ELECTRIC: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.BICYCLE_PERSONAL_NON_ELECTRIC: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.E_SCOOTER_SHARED: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.E_SCOOTER_PERSONAL: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.TAXI: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.UBER_LYFT: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.CAR_SERVICE_BLACK_LIMO: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.MTS_ROUTE_992: e.TravelModeGrouped.BUS_992,\n",
    "    e.TravelMode.AIRPORT_FLYER_SHUTTLE: e.TravelModeGrouped.AIRPORT_FLYER_SHUTTLE,\n",
    "    e.TravelMode.OTHER_PUBLIC_TRANSIT: e.TravelModeGrouped.PUBLIC_TRANSPORTATION,\n",
    "    e.TravelMode.DROPPED_OFF_BY_FAMILY_FRIEND: e.TravelModeGrouped.PERSONAL_CAR_DROPPED_OFF_PICKED_UP,\n",
    "    e.TravelMode.PICKED_UP_BY_FAMILY_FRIEND: e.TravelModeGrouped.PERSONAL_CAR_DROPPED_OFF_PICKED_UP,\n",
    "    e.TravelMode.DROVE_ALONE_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.DROVE_WITH_OTHERS_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.RODE_WITH_OTHER_TRAVELERS_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_DRIVE_ALONE: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_DRIVE_WITH_OTHERS: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_RIDE_WITH_OTHER_TRAVELERS: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.RENTAL_CAR_DROPPED_OFF: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_PARKED: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_PICKED_UP: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_GET_IN_PARKED: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.HOTEL_SHUTTLE_VAN: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.EMPLOYEE_SHUTTLE: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.OTHER_SHARED_VAN: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.CHARTERED_TOUR_BUS: e.TravelModeGrouped.OTHER,\n",
    "    e.TravelMode.OTHER: e.TravelModeGrouped.OTHER,\n",
    "    e.TravelMode.REFUSED_NO_ANSWER: e.TravelModeGrouped.REFUSED_NO_ANSWER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20809722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping Done for main_mode\n",
      "Remapping Done for access_mode\n",
      "Remapping Done for egress_mode\n",
      "Remapping Done for reverse_mode\n",
      "Remapping Done for reverse_mode_predicted\n",
      "Remapping Done for other_airport_accessmode\n",
      "Remapping Done for reverse_commute_mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n"
     ]
    }
   ],
   "source": [
    "mode_columns_to_remap = ['main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "for col in mode_columns_to_remap:\n",
    "    clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
    "    print(f\"Remapping Done for {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab605f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"general_modes_used_visitor_list\"] = clean_df[general_modes_used_visitor_mode_columns].apply(lambda row:\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"alt_commute_mode_list\"] = clean_df[alt_commute_mode_columns].apply(lambda row:\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"sdia_accessmode_split_list\"] = clean_df[sdia_accessmode_split_columns].apply(lambda row:\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"race_list\"] = clean_df[race_columns].apply(lambda row:\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"reasons_no_transit_list\"] = clean_df[reasons_no_transit_columns].apply(lambda row:\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2978600297.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['party_composition_list'] = clean_df[party_composition_columns].apply(lambda row:\n"
     ]
    }
   ],
   "source": [
    "#### Consolidating multiple columns into one string column:\n",
    "general_modes_used_visitor_mode_columns = [col for col in clean_df.columns if col.startswith(\"general_modes_used_visitor\")]\n",
    "alt_commute_mode_columns = [col for col in clean_df.columns if col.startswith(\"alt_commute_mode\")]\n",
    "sdia_accessmode_split_columns = [col for col in clean_df.columns if col.startswith(\"sdia_accessmode_split_\")]\n",
    "race_columns = [col for col in clean_df.columns if col.startswith(\"race_\")]\n",
    "reasons_no_transit_columns = [col for col in clean_df.columns if col.startswith(\"reasons_no_transit_\")]\n",
    "party_composition_columns = [col for col in clean_df.columns if col.startswith(\"party_includes_\")]\n",
    "\n",
    "\n",
    "# Create a new column with a comma-separated list of active modes\n",
    "clean_df[\"general_modes_used_visitor_list\"] = clean_df[general_modes_used_visitor_mode_columns].apply(lambda row: \n",
    "    \", \".join([col.replace(\"general_modes_used_visitor_\", \"\").replace(\"_\", \" \") for col in general_modes_used_visitor_mode_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"alt_commute_mode_list\"] = clean_df[alt_commute_mode_columns].apply(lambda row: \n",
    "    \", \".join([col.replace(\"alt_commute_mode_\", \"\").replace(\"_\", \" \") for col in alt_commute_mode_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"sdia_accessmode_split_list\"] = clean_df[sdia_accessmode_split_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"sdia_accessmode_split_\", \"\").replace(\"_\", \" \") for col in sdia_accessmode_split_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"race_list\"] = clean_df[race_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"race_\", \"\").replace(\"_\", \" \") for col in race_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"reasons_no_transit_list\"] = clean_df[reasons_no_transit_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"reasons_no_transit_\", \"\").replace(\"_\", \" \") for col in reasons_no_transit_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df['party_composition_list'] = clean_df[party_composition_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"party_includes_\", \"\").replace(\"_\", \" \") for col in party_composition_columns if row[col]=='Yes']), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef6cfb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1507753342.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"transit_routes_list\"] = clean_df[valid_transit_columns].apply(\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1507753342.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"num_transit_transfers\"] = clean_df[\"transit_routes_list\"].apply(lambda x: max(len(x.split(\", \")) - 1, 0) if x else 0)\n"
     ]
    }
   ],
   "source": [
    "ordered_transit_columns = [\n",
    "    \"from_airport_transit_route_1\", \"from_airport_transit_route_1_other\",\n",
    "    \"from_airport_transit_route_2\", \"from_airport_transit_route_2_other\",\n",
    "    \"from_airport_transit_route_3\", \"from_airport_transit_route_3_other\",\n",
    "    \"from_airport_transit_route_4\", \"from_airport_transit_route_4_other\",\n",
    "    \"to_airport_transit_route_1\", \"to_airport_transit_route_1_other\",\n",
    "    \"to_airport_transit_route_2\", \"to_airport_transit_route_2_other\",\n",
    "    \"to_airport_transit_route_3\", \"to_airport_transit_route_3_other\",\n",
    "    \"to_airport_transit_route_4\", \"to_airport_transit_route_4_other\"\n",
    "]\n",
    "\n",
    "# Ensure only valid columns (those that exist in the DataFrame)\n",
    "valid_transit_columns = [col for col in ordered_transit_columns if col in clean_df.columns]\n",
    "\n",
    "# Concatenate only non-null values while maintaining the correct order\n",
    "clean_df[\"transit_routes_list\"] = clean_df[valid_transit_columns].apply(\n",
    "    lambda row: \", \".join(row.dropna().astype(str)), axis=1\n",
    ")\n",
    "\n",
    "# Compute the number of transfers (number of routes - 1), ensuring no negative values\n",
    "clean_df[\"num_transit_transfers\"] = clean_df[\"transit_routes_list\"].apply(lambda x: max(len(x.split(\", \")) - 1, 0) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8224cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2655610374.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"sp_other_airport_list\"] = clean_df[sp_other_airport_columns].apply(lambda row:\n"
     ]
    }
   ],
   "source": [
    "##Merge SP Survey fields:\n",
    "sp_other_airport_columns = [col for col in clean_df.columns if col.startswith(\"sp_other_airport_\")]\n",
    "\n",
    "\n",
    "# Create a new column with a comma-separated list of active modes\n",
    "clean_df[\"sp_other_airport_list\"] = clean_df[sp_other_airport_columns].apply(lambda row: \n",
    "    \", \".join([col.replace(\"sp_other_airport_\", \"\").replace(\"_\", \" \") for col in sp_other_airport_columns if row[col]==1]), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b216f",
   "metadata": {},
   "source": [
    "### Add Passenger Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d7e6bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1432817681.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"passenger_segment\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "# Add the `passenger_segment` column based on the updated logic\n",
    "clean_df[\"passenger_segment\"] = np.where(\n",
    "    # Resident Arriving\n",
    "    (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING) & \n",
    "    ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.COMING_HOME) |\n",
    "     (clean_df[\"resident_visitor_followup\"] == e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT)),\n",
    "    e.PassengerSegment.RESIDENT_ARRIVING,  # Resident Arriving\n",
    "    np.where(\n",
    "        (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING),\n",
    "        e.PassengerSegment.VISITOR_ARRIVING,  # Visitor Arriving\n",
    "        np.where(\n",
    "            (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING) & \n",
    "            ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.LEAVING_HOME) |\n",
    "             (clean_df[\"resident_visitor_followup\"] == e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT)),\n",
    "            e.PassengerSegment.RESIDENT_DEPARTING,  # Resident Departing\n",
    "            np.where(\n",
    "                # Visitor Departing\n",
    "                (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING),\n",
    "                e.PassengerSegment.VISITOR_DEPARTING,  # Visitor Departing\n",
    "                None  # Default case (if no conditions match)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b875c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\268666340.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"resident_visitor_purpose\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "clean_df[\"resident_visitor_purpose\"] = np.where(\n",
    "    # Resident Business\n",
    "    (clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING])) & \n",
    "    (clean_df[\"flight_purpose\"].isin([e.FlightPurpose.BUSINESS_WORK, e.FlightPurpose.COMBINATION_BUSINESS_LEISURE])),\n",
    "    e.ResidentVisitorPurpose.RESIDENT_BUSINESS,\n",
    "    \n",
    "    np.where(\n",
    "        # Resident Non-Business\n",
    "        clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING]),\n",
    "        e.ResidentVisitorPurpose.RESIDENT_NON_BUSINESS,\n",
    "        \n",
    "        np.where(\n",
    "            # Visitor Business\n",
    "            (clean_df[\"flight_purpose\"].isin([e.FlightPurpose.BUSINESS_WORK, e.FlightPurpose.COMBINATION_BUSINESS_LEISURE])),\n",
    "            e.ResidentVisitorPurpose.VISITOR_BUSINESS,\n",
    "            \n",
    "            # Visitor Non-Business (default case)\n",
    "            e.ResidentVisitorPurpose.VISITOR_NON_BUSINESS\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dfa9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\4117330195.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"qualified_visitor\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "## Explicit Visitor Check\n",
    "clean_df[\"qualified_visitor\"] = np.where(\n",
    "    # Arriving and visiting or neither, and does not live in the same region traveled\n",
    "    (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING) & \n",
    "    ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.VISITING) | \n",
    "     (clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.NEITHER)) &\n",
    "    (clean_df[\"resident_visitor_followup\"] != e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT),\n",
    "    1,  # Qualified visitor\n",
    "    np.where(\n",
    "        # Departing and going home or neither, and does not live in the same region traveled\n",
    "        (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING) &\n",
    "        ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.GOING_HOME) | \n",
    "         (clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.NEITHER)) &\n",
    "        (clean_df[\"resident_visitor_followup\"] != e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT),\n",
    "        1,  # Qualified visitor\n",
    "        0  # Not a qualified visitor\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd18340",
   "metadata": {},
   "source": [
    "### Add some new consolidated variables, Combine some variables to exclude directionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8194a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1696998419.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['number_of_nights'] = clean_df['nights_away'].fillna(clean_df['nights_visited'])\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1696998419.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"is_sdia_home_airport\"] = np.where(\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1696998419.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['reverse_mode_combined'] = clean_df['reverse_mode_grouped'].combine_first(clean_df['reverse_mode_predicted_grouped'])\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\1696998419.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['reverse_mode_combined_other'] = clean_df['reverse_mode_predicted_other']\n"
     ]
    }
   ],
   "source": [
    "## New changes:\n",
    "clean_df['number_of_nights'] = clean_df['nights_away'].fillna(clean_df['nights_visited'])\n",
    "\n",
    "# Set is_sdia_home_airport to 1 for resident arriving or departing passengers\n",
    "clean_df[\"is_sdia_home_airport\"] = np.where(\n",
    "    clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING]), \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "### Combining reverse_mode, as reverse_mode_combined - \n",
    "clean_df['reverse_mode_combined'] = clean_df['reverse_mode_grouped'].combine_first(clean_df['reverse_mode_predicted_grouped'])\n",
    "clean_df['reverse_mode_combined_other'] = clean_df['reverse_mode_predicted_other']\n",
    "\n",
    "## party size\n",
    "clean_df[\"party_size_ground_access\"] = np.where(\n",
    "    clean_df[\"party_size_ground_access_same\"] == \"Yes\", \n",
    "    clean_df[\"party_size_flight\"], \n",
    "    clean_df[\"party_size_ground_access\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a90f77",
   "metadata": {},
   "source": [
    "Remove origin, destination coordinates, when the location does not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c95c71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For origin columns: if origin_state not in ['CA', 'BC'] OR origin_city is not 'Yuma'\n",
    "mask_origin = ((clean_df['origin_state'].isin(['CA', 'BC'])) | (clean_df['origin_city'] == 'Yuma'))\n",
    "clean_df.loc[~mask_origin, ['origin_latitude', 'origin_longitude']] = np.nan\n",
    "\n",
    "# For destination columns: if destination_state not in ['CA', 'BC'] OR destination_city is not 'Yuma'\n",
    "mask_destination = ((clean_df['destination_state'].isin(['CA', 'BC'])) | (clean_df['destination_city'] == 'Yuma'))\n",
    "clean_df.loc[~mask_destination, ['destination_latitude', 'destination_longitude']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d42d85",
   "metadata": {},
   "source": [
    "### Populate Home Location fields when it is not explicitly asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01ab7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2353382450.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'origin_municipal_zone']\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\2353382450.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'origin_pmsa']\n"
     ]
    }
   ],
   "source": [
    "# Create masks for home activity types\n",
    "mask_origin_home = clean_df['origin_activity_type'] == e.ActivityType.HOME\n",
    "mask_destination_home = clean_df['destination_activity_type'] == e.ActivityType.HOME\n",
    "\n",
    "# For rows where origin is home, copy the origin fields to home_location_ fields\n",
    "clean_df.loc[mask_origin_home, 'home_location_city'] = clean_df.loc[mask_origin_home, 'origin_city']\n",
    "clean_df.loc[mask_origin_home, 'home_location_state'] = clean_df.loc[mask_origin_home, 'origin_state']\n",
    "clean_df.loc[mask_origin_home, 'home_location_zip'] = clean_df.loc[mask_origin_home, 'origin_zip']\n",
    "clean_df.loc[mask_origin_home, 'home_location_latitude'] = clean_df.loc[mask_origin_home, 'origin_latitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_longitude'] = clean_df.loc[mask_origin_home, 'origin_longitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'origin_municipal_zone']\n",
    "clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'origin_pmsa']\n",
    "\n",
    "# For rows where destination is home, copy the destination fields to home_location_ fields\n",
    "clean_df.loc[mask_destination_home, 'home_location_city'] = clean_df.loc[mask_destination_home, 'destination_city']\n",
    "clean_df.loc[mask_destination_home, 'home_location_state'] = clean_df.loc[mask_destination_home, 'destination_state']\n",
    "clean_df.loc[mask_destination_home, 'home_location_zip'] = clean_df.loc[mask_destination_home, 'destination_zip']\n",
    "clean_df.loc[mask_destination_home, 'home_location_latitude'] = clean_df.loc[mask_destination_home, 'destination_latitude']\n",
    "clean_df.loc[mask_destination_home, 'home_location_longitude'] = clean_df.loc[mask_destination_home, 'destination_longitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'destination_municipal_zone']\n",
    "clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'destination_pmsa']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60c2a1",
   "metadata": {},
   "source": [
    "#### Fix transit_boarding and alighting coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6a45327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\3010364468.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_boarding_latitude'] = (\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\3010364468.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_boarding_longitude'] = (\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\3010364468.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_alighting_latitude'] = (\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_29680\\3010364468.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_alighting_longitude'] = (\n"
     ]
    }
   ],
   "source": [
    "clean_df['transit_boarding_latitude'] = (\n",
    "    clean_df['transit_board_1_lat']\n",
    "    .combine_first(clean_df['stop_on_latitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_boarding_longitude'] = (\n",
    "    clean_df['transit_board_1_long']\n",
    "    .combine_first(clean_df['stop_on_longitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_alighting_latitude'] = (\n",
    "    clean_df['transit_alight_4_lat']\n",
    "    .combine_first(clean_df['transit_alight_3_lat'])\n",
    "    .combine_first(clean_df['transit_alight_2_lat'])\n",
    "    .combine_first(clean_df['transit_alight_1_lat'])\n",
    "    .combine_first(clean_df['stop_off_latitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_alighting_longitude'] = (\n",
    "    clean_df['transit_alight_4_long']\n",
    "    .combine_first(clean_df['transit_alight_3_long'])\n",
    "    .combine_first(clean_df['transit_alight_2_long'])\n",
    "    .combine_first(clean_df['transit_alight_1_long'])\n",
    "    .combine_first(clean_df['stop_off_longitude'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96a5bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(clean_survey_file, index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
