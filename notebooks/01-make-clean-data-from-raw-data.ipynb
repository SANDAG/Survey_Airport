{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath(\"../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import ValidationError\n",
    "import data_model\n",
    "import enums as e\n",
    "from utils import extract_base_type, add_enum_label_columns, add_list_objects, add_synthetic_records\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_model)\n",
    "importlib.reload(e)\n",
    "from data_model import Respondent, Employee, AirPassenger, Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dir = \"../data/external\"\n",
    "interim_dir = \"../data/interim\"\n",
    "processed_dir = \"../data/processed\"\n",
    "\n",
    "input_file1 = os.path.join(external_dir, \"etc/od_20241121_sandag_airport_draftfinal.xlsx\") # latest\n",
    "input_file2 = os.path.join(external_dir, \"etc/od_20241015_sandag_airport_pilot_4.xlsx\") #older version but records needed\n",
    "variable_map_file = os.path.join(processed_dir, \"revised_names.csv\")\n",
    "clean_survey_file = os.path.join(interim_dir, \"survey_data_clean.csv\")\n",
    "output_csv_filename = os.path.join(processed_dir, \"data_model_output.csv\")\n",
    "#summary_csv_filename = os.path.join(processed_dir, \"data_model_output_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data , Rename fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_27016\\3592152132.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['is_completed'] = 1\n",
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_27016\\3592152132.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight'] = 1\n"
     ]
    }
   ],
   "source": [
    "in_df_complete1 = pd.read_excel(input_file1, sheet_name = 0)\n",
    "in_df_incomplete1 = pd.read_excel(input_file1, sheet_name = 1)\n",
    "\n",
    "in_df_complete2 = pd.read_excel(input_file2, sheet_name = 0)\n",
    "in_df_incomplete2 = pd.read_excel(input_file2, sheet_name = 1)\n",
    "\n",
    "in_df_complete = pd.concat([in_df_complete1, in_df_complete2], ignore_index = True)\n",
    "in_df_incomplete = pd.concat([in_df_incomplete1, in_df_incomplete2], ignore_index = True)\n",
    "\n",
    "in_df_complete['is_completed'] = 1\n",
    "in_df_incomplete['is_completed'] = 0\n",
    "\n",
    "in_df_complete['weight'] = 1\n",
    "in_df_incomplete['weight'] = 0\n",
    "\n",
    "in_df = pd.concat([in_df_complete, in_df_incomplete], ignore_index = True)\n",
    "header_df = pd.read_csv(variable_map_file)[['ETC_name','WSP_name']]\n",
    "header_dict = pd.Series(header_df.WSP_name.values,index=header_df.ETC_name).to_dict()\n",
    "clean_df = in_df.rename(columns=header_dict).copy().drop(columns=[\"delete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Records:  (7532, 372)\n",
      "Incomplete Records:  (9069, 29)\n"
     ]
    }
   ],
   "source": [
    "print(\"Complete Records: \", in_df_complete.shape)\n",
    "print(\"Incomplete Records: \", in_df_incomplete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16601, 315)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_df['respondentid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5104, 315)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the duplicate respondentids\n",
    "clean_df.drop_duplicates('respondentid', keep = 'first', inplace = True)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4731, 315)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['is_completed']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondentid</th>\n",
       "      <th>submit</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>interview_location</th>\n",
       "      <th>interview_location_label</th>\n",
       "      <th>interview_location_other</th>\n",
       "      <th>inbound_or_outbound</th>\n",
       "      <th>inbound_or_outbound_label</th>\n",
       "      <th>marketsegment</th>\n",
       "      <th>marketsegment_label</th>\n",
       "      <th>...</th>\n",
       "      <th>number_workers_label</th>\n",
       "      <th>sp_invitation</th>\n",
       "      <th>sp_invitation_label</th>\n",
       "      <th>stay_informed</th>\n",
       "      <th>stay_informed_label</th>\n",
       "      <th>survey_language</th>\n",
       "      <th>survey_language_label</th>\n",
       "      <th>survey_language_other</th>\n",
       "      <th>is_completed</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5385</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04 00:00:00</td>\n",
       "      <td>Term2</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>THREE (3)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5386</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04 00:00:00</td>\n",
       "      <td>Term2</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>TWO (2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5387</td>\n",
       "      <td>NO</td>\n",
       "      <td>2024-10-04 00:00:00</td>\n",
       "      <td>Term2</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE (0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5388</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04 00:00:00</td>\n",
       "      <td>SDA_1_FLYER</td>\n",
       "      <td>San Diego Flyer/Old Town Shuttle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>TWO (2)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5389</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04 00:00:00</td>\n",
       "      <td>Term2</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>THREE (3)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondentid submit       date_completed interview_location  \\\n",
       "0          5385    YES  2024-10-04 00:00:00              Term2   \n",
       "1          5386    YES  2024-10-04 00:00:00              Term2   \n",
       "2          5387     NO  2024-10-04 00:00:00              Term2   \n",
       "3          5388    YES  2024-10-04 00:00:00        SDA_1_FLYER   \n",
       "4          5389    YES  2024-10-04 00:00:00              Term2   \n",
       "\n",
       "           interview_location_label interview_location_other  \\\n",
       "0                        Terminal 2                      NaN   \n",
       "1                        Terminal 2                      NaN   \n",
       "2                        Terminal 2                      NaN   \n",
       "3  San Diego Flyer/Old Town Shuttle                      NaN   \n",
       "4                        Terminal 2                      NaN   \n",
       "\n",
       "  inbound_or_outbound inbound_or_outbound_label  marketsegment  \\\n",
       "0                  IN                   INBOUND            1.0   \n",
       "1                  IN                   INBOUND            1.0   \n",
       "2                  IN                   INBOUND            1.0   \n",
       "3                  IN                   INBOUND            1.0   \n",
       "4                  IN                   INBOUND            1.0   \n",
       "\n",
       "  marketsegment_label  ... number_workers_label  sp_invitation  \\\n",
       "0       Air passenger  ...            THREE (3)            2.0   \n",
       "1       Air passenger  ...              TWO (2)            1.0   \n",
       "2       Air passenger  ...             NONE (0)            2.0   \n",
       "3       Air passenger  ...              TWO (2)            2.0   \n",
       "4       Air passenger  ...            THREE (3)            1.0   \n",
       "\n",
       "  sp_invitation_label  stay_informed stay_informed_label  survey_language  \\\n",
       "0                  No            0.0                  NO          ENGLISH   \n",
       "1                 Yes            NaN                 NaN          ENGLISH   \n",
       "2                  No            0.0                  NO          ENGLISH   \n",
       "3                  No            0.0                  NO          ENGLISH   \n",
       "4                 Yes            NaN                 NaN          ENGLISH   \n",
       "\n",
       "  survey_language_label survey_language_other  is_completed weight  \n",
       "0               ENGLISH                   NaN             1      1  \n",
       "1               ENGLISH                   NaN             1      1  \n",
       "2               ENGLISH                   NaN             1      1  \n",
       "3               ENGLISH                   NaN             1      1  \n",
       "4               ENGLISH                   NaN             1      1  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly occuring invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interview_location']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of columns that contain '-oth-' as a value\n",
    "columns_with_oth_value = [col for col in clean_df.columns if clean_df[col].eq('-oth-').any()]\n",
    "\n",
    "print(columns_with_oth_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight_number', 'origin_city', 'origin_state', 'origin_zip', 'destination_city', 'destination_state', 'destination_zip', 'transit_boarding_stop_name', 'transit_boarding_latitude', 'transit_boarding_longitude', 'transit_alighting_stop_name', 'transit_alighting_latitude', 'transit_alighting_longitude', 'home_location_city', 'home_location_state', 'home_location_zip', 'home_location_latitude', 'home_location_longitude']\n"
     ]
    }
   ],
   "source": [
    "columns_with_dash_value = [col for col in clean_df.columns if clean_df[col].eq('-').any()]\n",
    "\n",
    "print(columns_with_dash_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making all modes consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egress_mode_label\n",
       "Walk                                 25\n",
       "Picked up by car by family/friend    12\n",
       "Drive alone and park                  2\n",
       "Uber/Lyft                             2\n",
       "Other shared van (please specify)     1\n",
       "Taxi                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['egress_mode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "DROPPED OFF BY CAR BY FRIEND FAMILY               242\n",
       "UBER LYFT                                         107\n",
       "DROVE ALONE AND PARKED                             42\n",
       "DROVE WITH OTHERS AND PARKED                       28\n",
       "OTHER PUBLIC TRANSIT                               24\n",
       "RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY     22\n",
       "TAXI                                               14\n",
       "WHEELCHAIR OR OTHER MOBILITY DEVICE                11\n",
       "RENTAL CAR AND PARKED IT                           11\n",
       "WALK                                                9\n",
       "CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR            4\n",
       "HOTEL SHUTTLE VAN                                   3\n",
       "RODE WITH OTHER TRAVELER AND PARKED                 2\n",
       "NON ELECTRIC BIKESHARE                              2\n",
       "PERSONAL NON ELECTRIC BICYCLE                       1\n",
       "OTHER SHARED RIDE VAN SERVICE                       1\n",
       "ELECTRIC BIKESHARE                                  1\n",
       "EMPLOYEE SHUTTLE                                    1\n",
       "CHARTERED TOUR BUS                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_airport_accessmode_label_map = {\n",
    "    'Walk': 'Walk',\n",
    "    'Wheelchair or other mobility device': 'Wheelchair or other mobility device',\n",
    "    'ELECTRIC BIKESHARE': 'Bicycle: electric bikeshare',\n",
    "    'NON ELECTRIC BIKESHARE': 'Bicycle: non-electric bikeshare',\n",
    "    'E SCOOTER SHARE': 'E-scooter: shared',\n",
    "    'PERSONAL ELECTRIC BICYCLE': 'Bicycle: personal electric bicycle',\n",
    "    'PERSONAL NON ELECTRIC BICYCLE': 'Bicycle: personal non-electric bicycle',\n",
    "    'PERSONAL E SCOOTER': 'E-scooter: personal',\n",
    "    'Taxi': 'Taxi',\n",
    "    'UBER LYFT': 'Uber/Lyft',\n",
    "    'CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR': 'Car service/black car/limo/executive car',\n",
    "    'DROPPED OFF BY CAR BY FRIEND FAMILY': 'Dropped off by car by family/friend',\n",
    "    'Drove alone and parked': 'Drove alone and parked',\n",
    "    'Drove with others and parked': 'Drove with others and parked',\n",
    "    'RODE WITH OTHER TRAVELER AND PARKED': 'Rode with other traveler(s) and parked',\n",
    "    'Other public transit': 'Other public transit',\n",
    "    'Chartered tour bus': 'Chartered tour bus',\n",
    "    'Employee shuttle': 'Employee shuttle',\n",
    "    'RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY': 'Rental car: Dropped off at rental agency',\n",
    "    'RENTAL CAR AND PARKED IT': 'Rental car: parked rental car',\n",
    "    'Hotel shuttle van': 'Hotel shuttle van',\n",
    "    'OTHER SHARED RIDE VAN SERVICE': 'Other shared van (please specify)',\n",
    "    'Other': 'Other',\n",
    "    'Refused/No Answer': 'Refused/No Answer'\n",
    "}\n",
    "clean_df['other_airport_accessmode_label'] = clean_df['other_airport_accessmode_label'].map(other_airport_accessmode_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_dict = {\n",
    "    'Walk': 1,\n",
    "    'Wheelchair or other mobility device': 2,\n",
    "    'Bicycle: electric bikeshare': 3,\n",
    "    'Bicycle: non-electric bikeshare': 4,\n",
    "    'E-scooter: shared': 5,\n",
    "    'Bicycle: personal electric bicycle': 6,\n",
    "    'Bicycle: personal non-electric bicycle': 7,\n",
    "    'E-scooter: personal': 8,\n",
    "    'Taxi': 9,\n",
    "    'Uber/Lyft': 10,\n",
    "    'Car service/black car/limo/executive car': 11,\n",
    "    'Dropped off by car by family/friend': 12,\n",
    "    'Drove alone and parked': 13,\n",
    "    'Drove with others and parked': 14,\n",
    "    'MTS Route 992': 15,\n",
    "    'Airport flyer shuttle': 16,\n",
    "    'Chartered tour bus': 17,\n",
    "    'Employee shuttle': 18,\n",
    "    'Rental car: Dropped off at rental agency': 19,\n",
    "    'Rental car: parked rental car': 20,\n",
    "    'Hotel shuttle van': 21,\n",
    "    'Other shared van (please specify)': 22,\n",
    "    'Picked up by car by family/friend': 23,\n",
    "    'Get in a parked vehicle and drive alone': 24,\n",
    "    'Get in a parked vehicle and drive with others': 25,\n",
    "    'Get in a parked vehicle and ride with other traveler(s)': 26,\n",
    "    'Rental car: Picked up at rental agency': 27,\n",
    "    'Rental car: get in a parked rental car': 28,\n",
    "    'Rode with other traveler(s) and parked': 29,\n",
    "    'Other public transit': 30,\n",
    "    'Other': 98,\n",
    "    'Refused/No Answer': 99,\n",
    "    'None of the above': 98\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modes to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_code_columns = ['main_transit_mode', 'main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "mode_label_columns = ['main_transit_mode_label', 'main_mode_label', 'access_mode_label', 'egress_mode_label', 'reverse_mode_label', 'reverse_mode_predicted_label', 'other_airport_accessmode_label', 'reverse_commute_mode_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping codes using label strings\n",
    "for mode_code_col, mode_label_col in zip(mode_code_columns, mode_label_columns):\n",
    "    # Apply the mapping for each pair of columns\n",
    "    clean_df[mode_code_col] = clean_df[mode_label_col].map(travel_mode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode\n",
       "12.0    242\n",
       "10.0    107\n",
       "19.0     22\n",
       "20.0     11\n",
       "11.0      4\n",
       "29.0      2\n",
       "4.0       2\n",
       "7.0       1\n",
       "22.0      1\n",
       "3.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_transit_mode\n",
       "98.0    4361\n",
       "16.0     214\n",
       "15.0     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['main_transit_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of some fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_27016\\2868064111.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  clean_df.replace('-oth-', 98, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "clean_df['date_completed'] = pd.to_datetime(clean_df['date_completed'])\n",
    "clean_df['is_pilot'] = np.where(clean_df['date_completed'].dt.date<=datetime.date(2024, 9, 30), 1, 0)\n",
    "clean_df['record_type_synthetic'] = 0\n",
    "clean_df.replace('-oth-', 98, inplace=True)\n",
    "clean_df.replace('-', None, inplace = True )\n",
    "clean_df['is_income_below_poverty'] = np.where(clean_df['is_income_below_poverty'] == 0, 2, clean_df['is_income_below_poverty'])\n",
    "clean_df['stay_informed'] = np.where(clean_df['stay_informed'] == 0, 2, clean_df['stay_informed'])\n",
    "#Maps\n",
    "interview_location_map = {'Term1' : 1, 'Term2': 2, 'MTS_1_992': 3, 'SDA_1_FLYER': 4, 'ConracShuttle': 5, 'ParkingShuttle': 6, 'EmplParking': 7, '-oth-':98} \n",
    "inbound_outbound_map = {'IN':1, 'OUT':2}\n",
    "\n",
    "#route_fields:\n",
    "route_fields = ['to_airport_transit_route_1', 'to_airport_transit_route_2', 'to_airport_transit_route_3', 'to_airport_transit_route_4',\n",
    "                'from_airport_transit_route_1', 'from_airport_transit_route_2', 'from_airport_transit_route_3', 'from_airport_transit_route_4']\n",
    "\n",
    "#Replacement\n",
    "clean_df['interview_location'] = clean_df['interview_location'].map(interview_location_map)\n",
    "clean_df['inbound_or_outbound'] = clean_df['inbound_or_outbound'].map(inbound_outbound_map)\n",
    "clean_df['main_mode'] = np.where(clean_df['main_transit_mode'].isin([15,16]), clean_df['main_transit_mode'], clean_df['main_mode'])\n",
    "\n",
    "clean_df[route_fields] = clean_df[route_fields].replace(98, 'OTHER')\n",
    "clean_df['nights_visited'] = clean_df['nights_visited'] - 1\n",
    "\n",
    "clean_df['same_commute_mode'] = np.where(clean_df['same_commute_mode'] == 0, 2, clean_df['same_commute_mode'])\n",
    "clean_df['resident_visitor_followup'] = np.where(clean_df['resident_visitor_followup'] == 0, 2, clean_df['resident_visitor_followup'])\n",
    "\n",
    "#activity_type\n",
    "clean_df['origin_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.OUTBOUND_FROM_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['origin_activity_type'])\n",
    "clean_df['destination_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.INBOUND_TO_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['destination_activity_type'])\n",
    "\n",
    "#For incomplete records:\n",
    "clean_df['marketsegment'] = clean_df['marketsegment'].fillna(99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(clean_survey_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondentid</th>\n",
       "      <th>submit</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>interview_location</th>\n",
       "      <th>interview_location_label</th>\n",
       "      <th>interview_location_other</th>\n",
       "      <th>inbound_or_outbound</th>\n",
       "      <th>inbound_or_outbound_label</th>\n",
       "      <th>marketsegment</th>\n",
       "      <th>marketsegment_label</th>\n",
       "      <th>...</th>\n",
       "      <th>sp_invitation_label</th>\n",
       "      <th>stay_informed</th>\n",
       "      <th>stay_informed_label</th>\n",
       "      <th>survey_language</th>\n",
       "      <th>survey_language_label</th>\n",
       "      <th>survey_language_other</th>\n",
       "      <th>is_completed</th>\n",
       "      <th>weight</th>\n",
       "      <th>is_pilot</th>\n",
       "      <th>record_type_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5385</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5386</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5387</td>\n",
       "      <td>NO</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5388</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>San Diego Flyer/Old Town Shuttle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5389</td>\n",
       "      <td>YES</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Terminal 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondentid submit date_completed  interview_location  \\\n",
       "0          5385    YES     2024-10-04                 2.0   \n",
       "1          5386    YES     2024-10-04                 2.0   \n",
       "2          5387     NO     2024-10-04                 2.0   \n",
       "3          5388    YES     2024-10-04                 4.0   \n",
       "4          5389    YES     2024-10-04                 2.0   \n",
       "\n",
       "           interview_location_label interview_location_other  \\\n",
       "0                        Terminal 2                      NaN   \n",
       "1                        Terminal 2                      NaN   \n",
       "2                        Terminal 2                      NaN   \n",
       "3  San Diego Flyer/Old Town Shuttle                      NaN   \n",
       "4                        Terminal 2                      NaN   \n",
       "\n",
       "   inbound_or_outbound inbound_or_outbound_label  marketsegment  \\\n",
       "0                  1.0                   INBOUND            1.0   \n",
       "1                  1.0                   INBOUND            1.0   \n",
       "2                  1.0                   INBOUND            1.0   \n",
       "3                  1.0                   INBOUND            1.0   \n",
       "4                  1.0                   INBOUND            1.0   \n",
       "\n",
       "  marketsegment_label  ... sp_invitation_label  stay_informed  \\\n",
       "0       Air passenger  ...                  No            2.0   \n",
       "1       Air passenger  ...                 Yes            NaN   \n",
       "2       Air passenger  ...                  No            2.0   \n",
       "3       Air passenger  ...                  No            2.0   \n",
       "4       Air passenger  ...                 Yes            NaN   \n",
       "\n",
       "  stay_informed_label  survey_language survey_language_label  \\\n",
       "0                  NO          ENGLISH               ENGLISH   \n",
       "1                 NaN          ENGLISH               ENGLISH   \n",
       "2                  NO          ENGLISH               ENGLISH   \n",
       "3                  NO          ENGLISH               ENGLISH   \n",
       "4                 NaN          ENGLISH               ENGLISH   \n",
       "\n",
       "   survey_language_other is_completed weight  is_pilot record_type_synthetic  \n",
       "0                    NaN            1      1         0                     0  \n",
       "1                    NaN            1      1         0                     0  \n",
       "2                    NaN            1      1         0                     0  \n",
       "3                    NaN            1      1         0                     0  \n",
       "4                    NaN            1      1         0                     0  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Variables to verify for the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_parking</th>\n",
       "      <th>alt_commute_mode_bicycle_electric_bikeshare</th>\n",
       "      <th>resident_visitor</th>\n",
       "      <th>race_hp</th>\n",
       "      <th>general_modes_used_visitor_rental_car_dropped_off</th>\n",
       "      <th>from_airport_transit_route_2</th>\n",
       "      <th>general_modes_used_visitor_chartered_tour_bus</th>\n",
       "      <th>home_location_zip</th>\n",
       "      <th>from_airport_transit_route_1_other</th>\n",
       "      <th>record_type_synthetic</th>\n",
       "      <th>...</th>\n",
       "      <th>parking_cost_frequency_other</th>\n",
       "      <th>submit</th>\n",
       "      <th>sdia_accessmode_split_uber_lyft</th>\n",
       "      <th>race_other</th>\n",
       "      <th>sdia_accessmode_split_mts992</th>\n",
       "      <th>to_airport_transit_route_3_other</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>reasons_no_transit_ride_too_long</th>\n",
       "      <th>sdia_accessmode_split_other</th>\n",
       "      <th>general_modes_used_visitor_bicycle_electric_bikeshare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_parking alt_commute_mode_bicycle_electric_bikeshare  \\\n",
       "0              NaN                                         NaN   \n",
       "1              NaN                                         NaN   \n",
       "2              NaN                                         NaN   \n",
       "3              NaN                                         NaN   \n",
       "4              NaN                                         NaN   \n",
       "\n",
       "   resident_visitor race_hp general_modes_used_visitor_rental_car_dropped_off  \\\n",
       "0               8.0      No                                                No   \n",
       "1               1.0      No                                               NaN   \n",
       "2               8.0      No                                                No   \n",
       "3               1.0      No                                               NaN   \n",
       "4               1.0      No                                               NaN   \n",
       "\n",
       "  from_airport_transit_route_2 general_modes_used_visitor_chartered_tour_bus  \\\n",
       "0                          NaN                                            No   \n",
       "1                          NaN                                           NaN   \n",
       "2                          NaN                                            No   \n",
       "3                          NaN                                           NaN   \n",
       "4                          NaN                                           NaN   \n",
       "\n",
       "  home_location_zip  from_airport_transit_route_1_other  \\\n",
       "0              None                                 NaN   \n",
       "1              None                                 NaN   \n",
       "2               NaN                                 NaN   \n",
       "3              None                                 NaN   \n",
       "4              None                                 NaN   \n",
       "\n",
       "   record_type_synthetic  ...  parking_cost_frequency_other submit  \\\n",
       "0                      0  ...                           NaN    YES   \n",
       "1                      0  ...                           NaN    YES   \n",
       "2                      0  ...                           NaN     NO   \n",
       "3                      0  ...                           NaN    YES   \n",
       "4                      0  ...                           NaN    YES   \n",
       "\n",
       "   sdia_accessmode_split_uber_lyft  race_other sdia_accessmode_split_mts992  \\\n",
       "0                              NaN         NaN                          NaN   \n",
       "1                              Yes         NaN                           No   \n",
       "2                              NaN         NaN                          NaN   \n",
       "3                              NaN         NaN                          NaN   \n",
       "4                              NaN         NaN                          NaN   \n",
       "\n",
       "  to_airport_transit_route_3_other destination_city  \\\n",
       "0                              NaN        San Diego   \n",
       "1                              NaN        San Diego   \n",
       "2                              NaN              NaN   \n",
       "3                              NaN        San Diego   \n",
       "4                              NaN        San Diego   \n",
       "\n",
       "  reasons_no_transit_ride_too_long sdia_accessmode_split_other  \\\n",
       "0                              NaN                         NaN   \n",
       "1                              NaN                         NaN   \n",
       "2                              NaN                         NaN   \n",
       "3                              NaN                         NaN   \n",
       "4                              NaN                         NaN   \n",
       "\n",
       "  general_modes_used_visitor_bicycle_electric_bikeshare  \n",
       "0                                                 No     \n",
       "1                                                NaN     \n",
       "2                                                 No     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respondent_variables = [field_name for field_name, field_info in Respondent.__fields__.items()]\n",
    "\n",
    "\n",
    "trip_variables = [field_name for field_name, field_info in Trip.__fields__.items()]\n",
    "trip_variables.append('respondentid')\n",
    "\n",
    "employee_variables = [field_name for field_name, field_info in Employee.__fields__.items()]\n",
    "employee_variables.remove('trip')\n",
    "\n",
    "air_passenger_variables = [field_name for field_name, field_info in AirPassenger.__fields__.items()]\n",
    "air_passenger_variables.remove('trip')\n",
    "\n",
    "variables_to_verify = list(set(air_passenger_variables + respondent_variables + trip_variables + employee_variables))\n",
    "variables_to_verify.remove('trip')\n",
    "variables_to_verify.remove('valid_record')\n",
    "variables_to_verify.remove('validation_error')\n",
    "variables_to_verify.remove('validation_severity')\n",
    "\n",
    "\n",
    "working_df = clean_df.copy()\n",
    "working_df = working_df[variables_to_verify].copy()\n",
    "working_df = working_df.loc[working_df['marketsegment'].notna()].copy()\n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5104, 251)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = working_df[trip_variables].copy()\n",
    "persons_df = working_df[list[set(employee_variables + respondent_variables + air_passenger_variables)]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "respondent_list = add_list_objects(\n",
    "        trips_df.to_dict(orient=\"records\"),  #child list\n",
    "        \"respondentid\", # child key\n",
    "        persons_df.to_dict(orient=\"records\"), # parent list\n",
    "        \"respondentid\", # parent key\n",
    "        \"trip\", # parent var\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5104"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(respondent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_list = []\n",
    "air_passenger_list = []\n",
    "other_list = []\n",
    "failed_records = []\n",
    "\n",
    "for respondent in respondent_list:\n",
    "    market_segment = respondent[\"marketsegment\"]\n",
    "    try:\n",
    "        if market_segment == e.Type.EMPLOYEE:\n",
    "            ev = Employee(** respondent)\n",
    "            employee_list.append(ev)\n",
    "        elif market_segment == e.Type.PASSENGER:\n",
    "             av = AirPassenger(** respondent)\n",
    "             air_passenger_list.append(av)\n",
    "        else:\n",
    "            rv = Respondent(** respondent)\n",
    "            other_list.append(rv)\n",
    "    except ValidationError as err:\n",
    "            respondent['error_flag'] = 'failed'\n",
    "            respondent['error_message'] = str(err)\n",
    "            failed_records.append(respondent) \n",
    "\n",
    "\n",
    "failed_df = pd.DataFrame(failed_records)\n",
    "failed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failed_df['error_message'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failed_df.to_csv('../data/processed/failed_records.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = pd.DataFrame([Employee.model_dump() for Employee in employee_list])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `enum` but got `Terminal` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `Terminal` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `enum` but got `Terminal` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "passenger_df = pd.DataFrame([AirPassenger.model_dump() for AirPassenger in air_passenger_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = pd.DataFrame([Respondent.model_dump() for Respondent in other_list])\n",
    "# other_df = add_enum_label_columns(other_df, Respondent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "trip_list = []\n",
    "id_list = []\n",
    "for record in employee_list + air_passenger_list + other_list:\n",
    "    trip_list.append(record.trip)\n",
    "    id_list.append(record.respondentid)\n",
    "\n",
    "trip_df = pd.DataFrame([Trip.model_dump() for Trip in trip_list])\n",
    "id_df = pd.DataFrame(id_list, columns=[\"respondentid\"])\n",
    "\n",
    "trip_df = pd.concat([id_df, trip_df], axis=1)\n",
    "trip_df = add_enum_label_columns(trip_df,Trip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_27016\\2189731026.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat([employee_df, passenger_df, other_df], axis=0).reset_index(drop=True).drop(columns=[\"trip\"])\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.concat([employee_df, passenger_df, other_df], axis=0).reset_index(drop=True).drop(columns=[\"trip\"])\n",
    "output_df = pd.merge(output_df, trip_df, on=\"respondentid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5104, 278)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = add_synthetic_records(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n",
      "c:\\projects\\SANDAG\\Questionarie_excel_to_word\\Survey_Airport\\data_model\\utils.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[enum_name_col] = df[field].map(enum_names).astype(str)\n"
     ]
    }
   ],
   "source": [
    "output_df =  add_enum_label_columns(output_df, Respondent)\n",
    "output_df =  add_enum_label_columns(output_df, AirPassenger)\n",
    "output_df =  add_enum_label_columns(output_df, Trip)\n",
    "output_df =  add_enum_label_columns(output_df, Employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination_activity_type_label\n",
       "SAN_DIEGO_AIRPORT    4863\n",
       "HOME                 1581\n",
       "HOTEL                1518\n",
       "OTHER_RESIDENCE       983\n",
       "OTHER                 102\n",
       "nan                    63\n",
       "USUAL_WORKPLACE        52\n",
       "OTHER_BUSINESS         50\n",
       "CONVENTION_CENTER       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['destination_activity_type_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_completed</th>\n",
       "      <th>is_pilot</th>\n",
       "      <th>record_type_synthetic</th>\n",
       "      <th>respondentid</th>\n",
       "      <th>submit</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>interview_location</th>\n",
       "      <th>interview_location_label</th>\n",
       "      <th>interview_location_other</th>\n",
       "      <th>inbound_or_outbound</th>\n",
       "      <th>...</th>\n",
       "      <th>next_flight_destination</th>\n",
       "      <th>non_airport_activity_type</th>\n",
       "      <th>parking_cost_numeric</th>\n",
       "      <th>previous_flight_origin</th>\n",
       "      <th>taxi_fhv_fare_numeric</th>\n",
       "      <th>taxi_fhv_wait_numeric</th>\n",
       "      <th>valid_record</th>\n",
       "      <th>validation_error</th>\n",
       "      <th>validation_severity</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5473</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TERMINAL_2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5476</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ONBOARD_992</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Prefer Not to disclose cannot be combined with...</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5489</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TERMINAL_2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5558</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TERMINAL_2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5593</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TERMINAL_2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_completed  is_pilot  record_type_synthetic respondentid submit  \\\n",
       "0          True     False                      0         5473   True   \n",
       "1          True     False                      0         5476   True   \n",
       "2          True     False                      0         5489   True   \n",
       "3          True     False                      0         5558   True   \n",
       "4          True     False                      0         5593   True   \n",
       "\n",
       "  date_completed  interview_location interview_location_label  \\\n",
       "0     2024-10-04                 2.0               TERMINAL_2   \n",
       "1     2024-10-04                 3.0              ONBOARD_992   \n",
       "2     2024-10-04                 2.0               TERMINAL_2   \n",
       "3     2024-10-04                 2.0               TERMINAL_2   \n",
       "4     2024-10-04                 2.0               TERMINAL_2   \n",
       "\n",
       "  interview_location_other  inbound_or_outbound  ... next_flight_destination  \\\n",
       "0                     None                  1.0  ...                     NaN   \n",
       "1                     None                  1.0  ...                     NaN   \n",
       "2                     None                  1.0  ...                     NaN   \n",
       "3                     None                  1.0  ...                     NaN   \n",
       "4                     None                  1.0  ...                     NaN   \n",
       "\n",
       "   non_airport_activity_type parking_cost_numeric previous_flight_origin  \\\n",
       "0                        2.0                100.0                    NaN   \n",
       "1                        2.0                  NaN                    NaN   \n",
       "2                        2.0                134.0                    NaN   \n",
       "3                        2.0                  NaN                    NaN   \n",
       "4                        2.0                  NaN                    NaN   \n",
       "\n",
       "   taxi_fhv_fare_numeric taxi_fhv_wait_numeric  valid_record  \\\n",
       "0                   None                  None          True   \n",
       "1                   None                  None         False   \n",
       "2                   None                  None          True   \n",
       "3                   None                  None          True   \n",
       "4                   None                  None          True   \n",
       "\n",
       "                                    validation_error  validation_severity  \\\n",
       "0                                                                           \n",
       "1  Prefer Not to disclose cannot be combined with...                  Low   \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "\n",
       "  weight  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3    1.0  \n",
       "4    1.0  \n",
       "\n",
       "[5 rows x 329 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_columns = clean_df.columns.tolist()\n",
    "\n",
    "important_columns = ['is_completed', 'is_pilot', 'record_type_synthetic', 'weight']\n",
    "\n",
    "\n",
    "# Ensure no duplicate columns by removing important_columns from reference_columns\n",
    "reference_columns = [col for col in reference_columns if col not in important_columns]\n",
    "\n",
    "# Identify remaining columns that are not in reference_columns or important_columns\n",
    "remaining_columns = [col for col in output_df.columns if col not in (reference_columns + important_columns)]\n",
    "\n",
    "# Create the new column order\n",
    "new_column_order = ['is_completed', 'is_pilot', 'record_type_synthetic'] + reference_columns + sorted(remaining_columns) + ['weight']\n",
    "\n",
    "# Reorder the DataFrame\n",
    "output_df = output_df[new_column_order]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.index = output_df.index+1\n",
    "output_df.to_csv(output_csv_filename, index_label = 'unique_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
