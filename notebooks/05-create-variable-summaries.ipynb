{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath(\"../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"../data/processed\"\n",
    "reports_dir = \"../reports\"\n",
    "data_model_output_file = os.path.join(processed_dir, \"data_model_output.csv\")\n",
    "\n",
    "summary_document = os.path.join(reports_dir, \"variable_summary_for_appendix.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_14864\\304344899.py:1: DtypeWarning: Columns (1,13,14,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,54,55,59,65,70,74,77,78,80,82,83,86,93,95,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,142,147,150,151,152,155,156,157,167,169,177,179,194,195,196,199,208,209,214,221,237,239,240,241,242,243,244,246,248,249,273,283,284,285,288,291,295,296,297,299,300,335,337,338,340,410,413) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_model_output_df = pd.read_csv(data_model_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9208, 439)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df = pd.read_csv(data_model_output_file)\n",
    "data_model_output_df = data_model_output_df[data_model_output_df['is_valid_record']==True]\n",
    "data_model_output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>respondentid</th>\n",
       "      <th>is_completed</th>\n",
       "      <th>is_valid_record</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>is_pilot</th>\n",
       "      <th>is_self_administered</th>\n",
       "      <th>record_type_synthetic</th>\n",
       "      <th>access_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>validation_error_trip</th>\n",
       "      <th>validation_num_errors_person</th>\n",
       "      <th>validation_num_errors_trip</th>\n",
       "      <th>validation_severity_person</th>\n",
       "      <th>validation_severity_trip</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight_departing_and_arriving</th>\n",
       "      <th>weight_departing_only</th>\n",
       "      <th>weight_departing_only_with_time_of_day</th>\n",
       "      <th>weight_non_sas_departing_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5473</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:41:12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5476</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:40:04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5489</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:51:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5558</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>10:32:58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5593</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>11:09:46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id respondentid  is_completed  is_valid_record date_completed  \\\n",
       "0          1         5473          True             True     2024-10-04   \n",
       "1          2         5476          True             True     2024-10-04   \n",
       "2          3         5489          True             True     2024-10-04   \n",
       "3          4         5558          True             True     2024-10-04   \n",
       "4          5         5593          True             True     2024-10-04   \n",
       "\n",
       "  time_completed  is_pilot  is_self_administered  record_type_synthetic  \\\n",
       "0       08:41:12     False                 False                      0   \n",
       "1       08:40:04     False                 False                      0   \n",
       "2       08:51:36     False                 False                      0   \n",
       "3       10:32:58     False                 False                      0   \n",
       "4       11:09:46     False                 False                      0   \n",
       "\n",
       "   access_mode  ...  validation_error_trip validation_num_errors_person  \\\n",
       "0          NaN  ...                     []                            0   \n",
       "1          1.0  ...                     []                            0   \n",
       "2          NaN  ...                     []                            0   \n",
       "3          1.0  ...                     []                            0   \n",
       "4          1.0  ...                     []                            0   \n",
       "\n",
       "   validation_num_errors_trip validation_severity_person  \\\n",
       "0                           0                        NaN   \n",
       "1                           0                        NaN   \n",
       "2                           0                        NaN   \n",
       "3                           0                        NaN   \n",
       "4                           0                        NaN   \n",
       "\n",
       "  validation_severity_trip weight  weight_departing_and_arriving  \\\n",
       "0                      NaN    1.0                            1.0   \n",
       "1                      NaN    1.0                            1.0   \n",
       "2                      NaN    1.0                            1.0   \n",
       "3                      NaN    1.0                            1.0   \n",
       "4                      NaN    1.0                            1.0   \n",
       "\n",
       "  weight_departing_only  weight_departing_only_with_time_of_day  \\\n",
       "0                   1.0                                     1.0   \n",
       "1                   1.0                                     1.0   \n",
       "2                   1.0                                     1.0   \n",
       "3                   1.0                                     1.0   \n",
       "4                   1.0                                     1.0   \n",
       "\n",
       "  weight_non_sas_departing_only  \n",
       "0                           1.0  \n",
       "1                           1.0  \n",
       "2                           1.0  \n",
       "3                           1.0  \n",
       "4                           1.0  \n",
       "\n",
       "[5 rows x 439 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(df, col, weight_col=None):\n",
    "    \"\"\"\n",
    "    Create a summary table with value counts, percentages, weighted percentages, \n",
    "    and cumulative percentages for a specified label column, ordered by its corresponding code column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        col (str): Label column to analyze (e.g., 'gender_label').\n",
    "        weight_col (str, optional): Column containing weights. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary table with value counts, percentages, weighted percentages, \n",
    "                      and cumulative percentages, ordered by code column values.\n",
    "    \"\"\"\n",
    "    # Identify code column (assumes it's the same as `col` without \"_label\")\n",
    "    code_col = col.replace('_label', '')\n",
    "\n",
    "    # Combine label and code columns into a temporary DataFrame for sorting\n",
    "    temp_df = df[[col, code_col]].drop_duplicates().set_index(col)\n",
    "\n",
    "    # Create mapping from label to code for sorting\n",
    "    label_to_code = temp_df[code_col].to_dict()\n",
    "\n",
    "    # Calculate value counts and percentages\n",
    "    value_counts = df[col].value_counts()\n",
    "    percentages = df[col].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Sort by the corresponding code values\n",
    "    sorted_index = sorted(value_counts.index, key=lambda x: label_to_code.get(x, float('inf')))\n",
    "    sorted_value_counts = value_counts.loc[sorted_index]\n",
    "    sorted_percentages = percentages.loc[sorted_index]\n",
    "\n",
    "    # Calculate weighted percentages if weight_col is provided\n",
    "    if weight_col:\n",
    "        weights = df.groupby(col)[weight_col].sum()\n",
    "        sorted_weights = weights.loc[sorted_index]\n",
    "        weighted_percentages = (sorted_weights / sorted_weights.sum()) * 100\n",
    "    else:\n",
    "        weighted_percentages = pd.Series([None] * len(sorted_value_counts), index=sorted_index)\n",
    "\n",
    "    # Calculate cumulative percentage\n",
    "    cumulative_percentages = sorted_percentages.cumsum()\n",
    "\n",
    "    # Combine into a summary table\n",
    "    output_df = pd.DataFrame({\n",
    "        'Responses': sorted_value_counts,\n",
    "        'Raw %': round(sorted_percentages, 2),\n",
    "        'Weighted %': round(weighted_percentages, 2),\n",
    "        'Cumulative %': round(cumulative_percentages, 2)\n",
    "    }).reset_index().rename(columns={col: 'Response'})\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "access_mode_label\n",
       "WALK                                    0.471204\n",
       "DROVE_ALONE_AND_PARKED                  0.191099\n",
       "DROPPED_OFF_BY_FAMILY_FRIEND            0.167539\n",
       "UBER_LYFT                               0.054974\n",
       "OTHER_PUBLIC_TRANSIT                    0.047120\n",
       "DROVE_WITH_OTHERS_AND_PARKED            0.023560\n",
       "OTHER                                   0.015707\n",
       "CAR_SERVICE_BLACK_LIMO                  0.013089\n",
       "RODE_WITH_OTHER_TRAVELERS_AND_PARKED    0.007853\n",
       "TAXI                                    0.005236\n",
       "BICYCLE_PERSONAL_NON_ELECTRIC           0.002618\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df['access_mode_label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Raw %</th>\n",
       "      <th>Weighted %</th>\n",
       "      <th>Cumulative %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>8549</td>\n",
       "      <td>92.84</td>\n",
       "      <td>92.84</td>\n",
       "      <td>92.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>659</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.16</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Response  Responses  Raw %  Weighted %  Cumulative %\n",
       "0  PASSENGER       8549  92.84       92.84         92.84\n",
       "1   EMPLOYEE        659   7.16        7.16        100.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = create_summary_table(data_model_output_df, 'marketsegment_label', 'weight_departing_only')\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_type_label\n",
       "ARRIVING     4369\n",
       "DEPARTING    4180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df['passenger_type_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def generate_summary_document(df, weight_col=None, segment_cols=None, output_file='summary_tables.docx'):\n",
    "    \"\"\"\n",
    "    Generate a Word document with summary tables for all columns in a dataframe,\n",
    "    optionally grouped by a concatenated custom segmentation column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        weight_col (str, optional): Column containing weights. Defaults to None.\n",
    "        segment_cols (list of str, optional): Columns to segment by. Defaults to None.\n",
    "        output_file (str): Path to save the generated Word document.\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "\n",
    "    if segment_cols:\n",
    "        doc.add_heading(\"Segment Columns Summary\", level=1)\n",
    "        for col in segment_cols:\n",
    "            pretty_col = col.replace(\"_label\", \"\").replace(\"_\", \" \").title()\n",
    "            doc.add_heading(pretty_col, level=2)\n",
    "\n",
    "            # Use your function for consistency\n",
    "            summary_table = create_summary_table(df, col, weight_col)\n",
    "\n",
    "            # Skip if summary is empty\n",
    "            if summary_table.empty:\n",
    "                continue\n",
    "\n",
    "            table = doc.add_table(rows=1, cols=summary_table.shape[1])\n",
    "            table.style = 'Light Grid Accent 1'\n",
    "\n",
    "            # Add headers\n",
    "            for i, column_name in enumerate(summary_table.columns):\n",
    "                clean_name = column_name.replace(\"_\", \" \").title()\n",
    "                table.cell(0, i).text = clean_name if column_name != 'Response' else 'Response'\n",
    "\n",
    "            # Add data rows\n",
    "            for _, row in summary_table.iterrows():\n",
    "                cells = table.add_row().cells\n",
    "                for i, value in enumerate(row):\n",
    "                    cells[i].text = str(value)\n",
    "\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    # Create custom segmentation column\n",
    "    if segment_cols:\n",
    "        df['custom_segmentation'] = df[segment_cols].astype(str).agg(\" | \".join, axis=1)\n",
    "        segments = df['custom_segmentation'].unique()\n",
    "    else:\n",
    "        df['custom_segmentation'] = 'All Data'\n",
    "        segments = ['All Data']\n",
    "\n",
    "    # Filter columns ending with '_label' and exclude segment columns\n",
    "    label_columns = [col for col in df.columns if col.endswith('_label') and col not in (segment_cols or [])]\n",
    "\n",
    "    # Iterate through each unique segment\n",
    "    for segment in segments:\n",
    "        subset_df = df[df['custom_segmentation'] == segment]\n",
    "        doc.add_heading(f\"Segment: {segment}\", level=1)\n",
    "\n",
    "        for col in label_columns:\n",
    "            summary_table = create_summary_table(subset_df, col, weight_col)\n",
    "\n",
    "            # Skip if summary is empty\n",
    "            if summary_table.empty:\n",
    "                continue\n",
    "\n",
    "            doc.add_heading(f'{col.replace(\"_label\", \"\").replace(\"_\", \" \").title()}', level=2)\n",
    "\n",
    "            table = doc.add_table(rows=1, cols=summary_table.shape[1])\n",
    "            table.style = 'Light Grid Accent 1'# 'Table Grid'\n",
    "\n",
    "            for i, column_name in enumerate(summary_table.columns):\n",
    "                table.cell(0, i).text = column_name\n",
    "\n",
    "            for _, row in summary_table.iterrows():\n",
    "                cells = table.add_row().cells\n",
    "                for i, value in enumerate(row):\n",
    "                    cells[i].text = str(value)\n",
    "\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    # Save the document\n",
    "    doc.save(output_file)\n",
    "    print(f\"Word document saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word document saved as ../reports\\variable_summary_for_appendix.docx\n"
     ]
    }
   ],
   "source": [
    "generate_summary_document(data_model_output_df, weight_col='weight_departing_and_arriving', segment_cols=['marketsegment_label', 'passenger_type_label'], output_file = summary_document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
