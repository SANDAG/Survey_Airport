{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath(\"../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = \"../data/processed\"\n",
    "reports_dir = \"../reports\"\n",
    "data_model_output_file = os.path.join(processed_dir, \"data_model_output.csv\")\n",
    "\n",
    "summary_document = os.path.join(reports_dir, \"variable_summary_for_appendix.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_18372\\304344899.py:1: DtypeWarning: Columns (1,13,14,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,54,55,59,65,69,74,77,78,80,82,83,86,93,95,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,142,147,150,151,152,155,156,157,167,169,177,179,196,197,198,201,210,211,216,223,237,239,240,241,242,243,244,246,248,249,273,283,284,285,288,291,295,296,297,299,300,335,337,338,340,411,414) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_model_output_df = pd.read_csv(data_model_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9098, 439)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df = pd.read_csv(data_model_output_file)\n",
    "data_model_output_df = data_model_output_df[data_model_output_df['is_valid_record']==True]\n",
    "data_model_output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>respondentid</th>\n",
       "      <th>is_completed</th>\n",
       "      <th>is_valid_record</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>time_completed</th>\n",
       "      <th>is_pilot</th>\n",
       "      <th>is_self_administered</th>\n",
       "      <th>record_type_synthetic</th>\n",
       "      <th>access_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>validation_error_person</th>\n",
       "      <th>validation_error_trip</th>\n",
       "      <th>validation_num_errors_person</th>\n",
       "      <th>validation_num_errors_trip</th>\n",
       "      <th>validation_severity_person</th>\n",
       "      <th>validation_severity_trip</th>\n",
       "      <th>weight_departing_and_arriving</th>\n",
       "      <th>weight_departing_only</th>\n",
       "      <th>weight_non_sas_departing_only</th>\n",
       "      <th>weight_departing_only_with_time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5473</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:41:12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.840259</td>\n",
       "      <td>10.854572</td>\n",
       "      <td>19.179428</td>\n",
       "      <td>10.874504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5476</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:40:04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.487856</td>\n",
       "      <td>6.534190</td>\n",
       "      <td>8.687559</td>\n",
       "      <td>6.502862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5489</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>08:51:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.840259</td>\n",
       "      <td>10.854572</td>\n",
       "      <td>19.179428</td>\n",
       "      <td>10.874504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5558</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>10:32:58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.487856</td>\n",
       "      <td>6.534190</td>\n",
       "      <td>8.687559</td>\n",
       "      <td>6.502862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5593</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>11:09:46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.487856</td>\n",
       "      <td>6.534190</td>\n",
       "      <td>8.687559</td>\n",
       "      <td>6.502862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id respondentid  is_completed  is_valid_record date_completed  \\\n",
       "0          1         5473          True             True     2024-10-04   \n",
       "1          2         5476          True             True     2024-10-04   \n",
       "2          3         5489          True             True     2024-10-04   \n",
       "3          4         5558          True             True     2024-10-04   \n",
       "4          5         5593          True             True     2024-10-04   \n",
       "\n",
       "  time_completed  is_pilot  is_self_administered  record_type_synthetic  \\\n",
       "0       08:41:12     False                 False                      0   \n",
       "1       08:40:04     False                 False                      0   \n",
       "2       08:51:36     False                 False                      0   \n",
       "3       10:32:58     False                 False                      0   \n",
       "4       11:09:46     False                 False                      0   \n",
       "\n",
       "   access_mode  ...  validation_error_person validation_error_trip  \\\n",
       "0          NaN  ...                       []                    []   \n",
       "1          1.0  ...                       []                    []   \n",
       "2          NaN  ...                       []                    []   \n",
       "3          1.0  ...                       []                    []   \n",
       "4          1.0  ...                       []                    []   \n",
       "\n",
       "   validation_num_errors_person validation_num_errors_trip  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "  validation_severity_person validation_severity_trip  \\\n",
       "0                        NaN                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                        NaN                      NaN   \n",
       "3                        NaN                      NaN   \n",
       "4                        NaN                      NaN   \n",
       "\n",
       "   weight_departing_and_arriving weight_departing_only  \\\n",
       "0                      10.840259             10.854572   \n",
       "1                       6.487856              6.534190   \n",
       "2                      10.840259             10.854572   \n",
       "3                       6.487856              6.534190   \n",
       "4                       6.487856              6.534190   \n",
       "\n",
       "   weight_non_sas_departing_only weight_departing_only_with_time_of_day  \n",
       "0                      19.179428                              10.874504  \n",
       "1                       8.687559                               6.502862  \n",
       "2                      19.179428                              10.874504  \n",
       "3                       8.687559                               6.502862  \n",
       "4                       8.687559                               6.502862  \n",
       "\n",
       "[5 rows x 439 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(df, col, weight_col=None):\n",
    "    \"\"\"\n",
    "    Create a summary table with value counts, percentages, weighted percentages, \n",
    "    and cumulative percentages for a specified label column, ordered by its corresponding code column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        col (str): Label column to analyze (e.g., 'gender_label').\n",
    "        weight_col (str, optional): Column containing weights. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary table with value counts, percentages, weighted percentages, \n",
    "                      and cumulative percentages, ordered by code column values.\n",
    "    \"\"\"\n",
    "    # Identify code column (assumes it's the same as `col` without \"_label\")\n",
    "    code_col = col.replace('_label', '')\n",
    "\n",
    "    # Combine label and code columns into a temporary DataFrame for sorting\n",
    "    temp_df = df[[col, code_col]].drop_duplicates().set_index(col)\n",
    "\n",
    "    # Create mapping from label to code for sorting\n",
    "    label_to_code = temp_df[code_col].to_dict()\n",
    "\n",
    "    # Calculate value counts and percentages\n",
    "    value_counts = df[col].value_counts()\n",
    "    percentages = df[col].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Sort by the corresponding code values\n",
    "    sorted_index = sorted(value_counts.index, key=lambda x: label_to_code.get(x, float('inf')))\n",
    "    sorted_value_counts = value_counts.loc[sorted_index]\n",
    "    sorted_percentages = percentages.loc[sorted_index]\n",
    "\n",
    "    # Calculate weighted percentages if weight_col is provided\n",
    "    if weight_col:\n",
    "        weights = df.groupby(col)[weight_col].sum()\n",
    "        sorted_weights = weights.loc[sorted_index]\n",
    "        weighted_percentages = (sorted_weights / sorted_weights.sum()) * 100\n",
    "    else:\n",
    "        weighted_percentages = pd.Series([None] * len(sorted_value_counts), index=sorted_index)\n",
    "\n",
    "    # Calculate cumulative percentage\n",
    "    cumulative_percentages = sorted_percentages.cumsum()\n",
    "\n",
    "    # Combine into a summary table\n",
    "    output_df = pd.DataFrame({\n",
    "        'Responses': sorted_value_counts,\n",
    "        'Raw %': round(sorted_percentages, 2),\n",
    "        'Weighted %': round(weighted_percentages, 2),\n",
    "        'Cumulative %': round(cumulative_percentages, 2)\n",
    "    }).reset_index().rename(columns={col: 'Response'})\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "access_mode_label\n",
       "WALK                                    0.459459\n",
       "DROVE_ALONE_AND_PARKED                  0.197297\n",
       "DROPPED_OFF_BY_FAMILY_FRIEND            0.170270\n",
       "UBER_LYFT                               0.056757\n",
       "OTHER_PUBLIC_TRANSIT                    0.045946\n",
       "DROVE_WITH_OTHERS_AND_PARKED            0.024324\n",
       "OTHER                                   0.016216\n",
       "CAR_SERVICE_BLACK_LIMO                  0.013514\n",
       "RODE_WITH_OTHER_TRAVELERS_AND_PARKED    0.008108\n",
       "TAXI                                    0.005405\n",
       "BICYCLE_PERSONAL_NON_ELECTRIC           0.002703\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df['access_mode_label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_segment  passenger_segment_label\n",
       "3.0                VISITOR_ARRIVING           2549\n",
       "4.0                VISITOR_DEPARTING          2428\n",
       "1.0                RESIDENT_ARRIVING          1763\n",
       "2.0                RESIDENT_DEPARTING         1699\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df[['passenger_segment', 'passenger_segment_label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_output_df['summary_segment'] = np.where(\n",
    "    data_model_output_df['marketsegment_label'] == 'EMPLOYEE', 1,\n",
    "    np.where(data_model_output_df['passenger_segment_label'] == 'RESIDENT_DEPARTING', 2,\n",
    "    np.where(data_model_output_df['passenger_segment_label'] == 'VISITOR_DEPARTING', 3, np.nan))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_output_df['summary_segment_label'] = np.where(\n",
    "    data_model_output_df['marketsegment_label'] == 'EMPLOYEE', 'EMPLOYEE',\n",
    "    np.where(data_model_output_df['passenger_segment_label'] == 'RESIDENT_DEPARTING', 'RESIDENT_DEPARTING',\n",
    "    np.where(data_model_output_df['passenger_segment_label'] == 'VISITOR_DEPARTING', 'VISITOR_DEPARTING', None))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary_segment_label\n",
       "VISITOR_DEPARTING     2428\n",
       "RESIDENT_DEPARTING    1699\n",
       "EMPLOYEE               659\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_output_df['summary_segment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4786, 441)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = data_model_output_df[data_model_output_df['summary_segment_label'].isin(['VISITOR_DEPARTING', 'RESIDENT_DEPARTING', 'EMPLOYEE'])]\n",
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Raw %</th>\n",
       "      <th>Weighted %</th>\n",
       "      <th>Cumulative %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>659</td>\n",
       "      <td>13.77</td>\n",
       "      <td>32.72</td>\n",
       "      <td>13.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RESIDENT_DEPARTING</td>\n",
       "      <td>1699</td>\n",
       "      <td>35.50</td>\n",
       "      <td>25.45</td>\n",
       "      <td>49.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VISITOR_DEPARTING</td>\n",
       "      <td>2428</td>\n",
       "      <td>50.73</td>\n",
       "      <td>41.83</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Response  Responses  Raw %  Weighted %  Cumulative %\n",
       "0            EMPLOYEE        659  13.77       32.72         13.77\n",
       "1  RESIDENT_DEPARTING       1699  35.50       25.45         49.27\n",
       "2   VISITOR_DEPARTING       2428  50.73       41.83        100.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = create_summary_table(working_df, 'summary_segment_label', 'weight_departing_only')\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.shared import Inches\n",
    "\n",
    "def set_column_widths(table, widths):\n",
    "    for col_idx, width in enumerate(widths):\n",
    "        for row in table.rows:\n",
    "            row.cells[col_idx].width = Inches(width)\n",
    "        table.columns[col_idx].width = Inches(width)\n",
    "\n",
    "def generate_summary_document(df, weight_col=None, segment_col=None, output_file='summary_tables.docx'):\n",
    "    doc = Document()\n",
    "    section = doc.sections[-1]\n",
    "    section.orientation = WD_ORIENT.LANDSCAPE\n",
    "    section.page_width, section.page_height = section.page_height, section.page_width\n",
    "\n",
    "    usable_width = 8.5\n",
    "    first_col_width = 3.0\n",
    "\n",
    "    def get_widths(n_cols):\n",
    "        if n_cols == 1:\n",
    "            return [usable_width]\n",
    "        remaining = usable_width - first_col_width\n",
    "        other_width = remaining / (n_cols - 1)\n",
    "        return [first_col_width] + [other_width] * (n_cols - 1)\n",
    "\n",
    "    if segment_col:\n",
    "        pretty_col = segment_col.replace(\"_label\", \"\").replace(\"_\", \" \").title()\n",
    "        doc.add_heading(\"Segment Columns Summary\", level=1)\n",
    "        doc.add_heading(pretty_col, level=2)\n",
    "\n",
    "        summary_table = create_summary_table(df, segment_col, weight_col)\n",
    "        if not summary_table.empty:\n",
    "            num_cols = summary_table.shape[1]\n",
    "            table = doc.add_table(rows=1, cols=num_cols)\n",
    "            table.style = 'Light Grid Accent 1'\n",
    "            table.autofit = False\n",
    "            set_column_widths(table, get_widths(num_cols))\n",
    "\n",
    "            for i, column_name in enumerate(summary_table.columns):\n",
    "                clean_name = column_name.replace(\"_\", \" \").title()\n",
    "                table.cell(0, i).text = clean_name if column_name != 'Response' else 'Response'\n",
    "\n",
    "            for _, row in summary_table.iterrows():\n",
    "                cells = table.add_row().cells\n",
    "                for i, value in enumerate(row):\n",
    "                    cells[i].text = f'{str(value).replace(\"_label\", \"\").replace(\"_\", \" \").title()}'\n",
    "\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    if segment_col:\n",
    "        segments = df[segment_col].dropna().unique()\n",
    "    else:\n",
    "        df['custom_segmentation'] = 'All Data'\n",
    "        segments = ['All Data']\n",
    "\n",
    "    label_columns = [col for col in df.columns if col.endswith('_label') and col != segment_col]\n",
    "\n",
    "    for idx, segment in enumerate(segments):\n",
    "        if idx > 0:\n",
    "            doc.add_page_break()\n",
    "\n",
    "        if segment_col:\n",
    "            subset_df = df[df[segment_col] == segment]\n",
    "            doc.add_heading(f\"Segment: {segment}\", level=1)\n",
    "        else:\n",
    "            subset_df = df\n",
    "            doc.add_heading(\"All Data\", level=1)\n",
    "\n",
    "        for col in label_columns:\n",
    "            summary_table = create_summary_table(subset_df, col, weight_col)\n",
    "            if summary_table.empty:\n",
    "                continue\n",
    "\n",
    "            doc.add_heading(col.replace(\"_label\", \"\").replace(\"_\", \" \").title(), level=2)\n",
    "\n",
    "            num_cols = summary_table.shape[1]\n",
    "            table = doc.add_table(rows=1, cols=num_cols)\n",
    "            table.style = 'Light Grid Accent 1'\n",
    "            table.autofit = False\n",
    "            set_column_widths(table, get_widths(num_cols))\n",
    "\n",
    "            for i, column_name in enumerate(summary_table.columns):\n",
    "                table.cell(0, i).text = column_name\n",
    "\n",
    "            for _, row in summary_table.iterrows():\n",
    "                cells = table.add_row().cells\n",
    "                for i, value in enumerate(row):\n",
    "                    cells[i].text = f'{str(value).replace(\"_label\", \"\").replace(\"_\", \" \").title()}'\n",
    "\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    doc.save(output_file)\n",
    "    print(f\"Word document saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word document saved as ../reports\\variable_summary_for_appendix.docx\n"
     ]
    }
   ],
   "source": [
    "generate_summary_document(data_model_output_df, weight_col='weight_departing_only', segment_col='summary_segment_label', output_file = summary_document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
