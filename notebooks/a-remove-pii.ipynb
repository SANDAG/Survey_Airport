{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Coordinates from Survey Responses\n",
    "Put coordinates into Series15 geographies, drop coordinates in responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import openmatrix as omx #TODO create requirements.txt\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found in GitHub repo -\n",
    "# https://github.com/SANDAG/Survey_Airport/blob/192019a7fd2cca1986af9a2e25d287fa9cdd7648/data_model/utils.py#L32\n",
    "survey_crs = \"EPSG:4326\"\n",
    "selected_geography = 'TAZ' #'MGRA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "geography_file = f\"T:/projects/sr15/geographies/{selected_geography}15.shp\"\n",
    "# processed_survey_data_path = \"../data/processed/data_model_output.csv\"\n",
    "processed_survey_data_path = \"../data/processed/data_model_output.csv\"\n",
    "base_scenario_path = r\"T:\\STORAGE-63T\\2025RP_draft\\abm_runs_v2\\2022_S0_v2\"\n",
    "\n",
    "# output\n",
    "processed_survey_data_low_pii_path = f'../data/processed/data_model_output_{selected_geography.lower()}.csv'\n",
    "processed_survey_data_low_pii_simplified_path = f'../data/processed/data_model_output_simplified_{selected_geography.lower()}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_8384\\424098965.py:3: DtypeWarning: Columns (1,13,14,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,54,55,59,65,70,74,77,78,80,82,83,86,93,95,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,142,147,150,151,152,155,156,157,167,169,177,179,194,195,196,199,208,209,214,221,237,239,240,241,242,243,244,246,248,249,273,283,284,285,288,291,295,296,297,299,300,335,337,338,340,410,413) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(processed_survey_data_path)\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "survey_respondent = (\n",
    "    pd.read_csv(processed_survey_data_path)\n",
    "    # .query('record_type_synthetic == False')\n",
    "    .query(\"validation_severity_person != 'Critical'\")\n",
    "    .query(\"validation_severity_trip != 'Critical'\")\n",
    "    # .query(\"weight.notna()\") #using non-synthetic data leaves synthetic records in data w/ 0 weight\n",
    "    # .query('inbound_or_outbound_label == \"INBOUND_TO_AIRPORT\"')\n",
    ")\n",
    "geographies = gpd.read_file(geography_file)\n",
    "# geographies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Coordinates w/ Geographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) for coords in SD counties -> \n",
    "    - match to TAZ\n",
    "    - for coords in ocean nearby, match to closest non-external TAZ\n",
    "        - WHAT LOGIC ? coordinate box?\n",
    "2) for origin coords outside of SD county:\n",
    "    1) if dest coord is inside county, make origin TAZ = AIRPORT\n",
    "    2) if dest coord is also outside county:\n",
    "        - match closest coord to closest external TAZ\n",
    "        - make furthest coord to any external TAZ = AIRPORT\n",
    "3) for remaining dest coords outside of SD county:\n",
    "    - make origin TAZ = AIRPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_survey_geodataframe(survey_df: pd.DataFrame, var_prefix:str)->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    survey_gdf =gpd.GeoDataFrame(\n",
    "                survey_df,\n",
    "                geometry=gpd.points_from_xy(\n",
    "                    survey_df[f\"{var_prefix}_longitude\"],\n",
    "                    survey_df[f\"{var_prefix}_latitude\"]\n",
    "                ),\n",
    "                crs=survey_crs,\n",
    "            )\n",
    "    return survey_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_geographies_df(geography_df:gpd.GeoDataFrame, var_prefix:str)->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geography_df = (\n",
    "            geography_df\n",
    "            [[selected_geography, \"geometry\"]]\n",
    "            .rename(columns={selected_geography:f'{var_prefix}_{selected_geography}'})\n",
    "        )\n",
    "    return geography_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sjoin_geographies(\n",
    "        survey_df:pd.DataFrame,\n",
    "        geography_df:gpd.GeoDataFrame,\n",
    "        var_prefix:str\n",
    "        )->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geography_df = transform_geographies_df(geography_df, var_prefix)\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "    survey_gdf = (\n",
    "        survey_gdf\n",
    "        .to_crs(geography_df.crs)\n",
    "        .sjoin(geography_df, how=\"left\")\n",
    "        .astype({f\"{var_prefix}_{selected_geography}\": \"Int32\"})\n",
    "        .drop(columns=['index_right'])\n",
    "    )\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps4386_coast = {\n",
    "    'lon': (-117.7,-117.1),\n",
    "    'lat': (32.535,33.385)\n",
    "}\n",
    "def rescue_adrift_respondents(\n",
    "        survey_df:pd.DataFrame,\n",
    "        geography_df:gpd.GeoDataFrame,\n",
    "        var_prefix:str\n",
    "        )->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geography_df = transform_geographies_df(geography_df, var_prefix)\n",
    "\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "    adrift_respondents_index = (\n",
    "        survey_gdf\n",
    "            .query(f'{var_prefix}_taz.isnull()')\n",
    "            .loc[survey_gdf[f'{var_prefix}_latitude'].between(eps4386_coast['lat'][0],eps4386_coast['lat'][1])]\n",
    "            .loc[survey_gdf[f'{var_prefix}_longitude'].between(eps4386_coast['lon'][0],eps4386_coast['lon'][1])]\n",
    "            .index\n",
    "    )\n",
    "    print(f'num adrift respondents: {adrift_respondents_index.shape}')\n",
    "    survey_gdf.loc[\n",
    "        adrift_respondents_index,\n",
    "        f'{var_prefix}_{selected_geography.lower()}'\n",
    "        ] = (\n",
    "                survey_gdf\n",
    "                .loc[adrift_respondents_index]\n",
    "                .reset_index(drop=False)\n",
    "                .rename(columns={'index':'adrift_index'})\n",
    "                .to_crs(geography_df.crs)\n",
    "                .sjoin_nearest(geography_df, how=\"left\", max_distance = 100000)\n",
    "                .set_index('adrift_index')\n",
    "                .astype({f\"{var_prefix}_{selected_geography}\": \"Int32\"})\n",
    "                [f'{var_prefix}_{selected_geography}']\n",
    "                .values\n",
    "    )\n",
    "\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_coordinates_to_nearby_external_taz(survey_df:pd.DataFrame, geography_df:gpd.GeoDataFrame, var_prefix:str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # select only external TAZs\n",
    "    geography_df = transform_geographies_df(geography_df, var_prefix).query(f'{var_prefix}_TAZ <= 12')\n",
    "\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "\n",
    "    missing_taz_index = (\n",
    "        survey_gdf\n",
    "            .query(f'{var_prefix}_taz.isnull()')\n",
    "            .index\n",
    "    )\n",
    "    print(f'num respondents w/ {var_prefix} outside of county: {missing_taz_index.shape}')\n",
    "    survey_gdf.loc[\n",
    "        missing_taz_index,\n",
    "        f'{var_prefix}_{selected_geography.lower()}'\n",
    "        ] = (\n",
    "                survey_gdf\n",
    "                .loc[missing_taz_index]\n",
    "                .reset_index(drop=False)\n",
    "                .rename(columns={'index':'missing_index'})\n",
    "                .to_crs(geography_df.crs)\n",
    "                .sjoin_nearest(geography_df, how=\"left\", max_distance = 1000000) # TODO introduce fixed max_distance https://github.com/geopandas/geopandas/discussions/2797\n",
    "                .set_index('missing_index')\n",
    "                .astype({f\"{var_prefix}_{selected_geography}\": \"Int32\"})\n",
    "                [f'{var_prefix}_{selected_geography}']\n",
    "                .values\n",
    "    )\n",
    "\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num adrift respondents: (9,)\n",
      "num adrift respondents: (8,)\n",
      "num adrift respondents: (6,)\n",
      "num adrift respondents: (0,)\n",
      "num adrift respondents: (0,)\n",
      "num respondents w/ origin outside of county: (389,)\n",
      "remaining null origin TAZs: 32\n"
     ]
    }
   ],
   "source": [
    "# process survey dataframe geographic features\n",
    "survey_respondent_geographies = survey_respondent.copy()\n",
    "for var_prefix in ['origin','destination','home_location','transit_boarding','transit_alighting']:\n",
    "    survey_respondent_geographies = sjoin_geographies(survey_respondent_geographies, geographies, var_prefix)\n",
    "    survey_respondent_geographies = rescue_adrift_respondents(survey_respondent_geographies, geographies, var_prefix)\n",
    "survey_respondent_geographies = match_coordinates_to_nearby_external_taz(survey_respondent_geographies, geographies, 'origin')\n",
    "print(f'remaining null origin TAZs: {survey_respondent_geographies['origin_taz'].isnull().sum()}')\n",
    "# survey_respondent_geographies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check matching respondents to geographies\n",
    "# var_prefix = \"origin\"\n",
    "# survey_mgra_gdf = survey_respondent_geographies.sample(100).copy()\n",
    "# geography_df = geographies.loc[geographies['MGRA'].isin(survey_mgra_gdf[f'{var_prefix}_mgra'])].copy()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geography_df.plot(ax = ax, color = 'red', alpha = 1)\n",
    "\n",
    "# survey_mgra_df = gpd.GeoDataFrame(\n",
    "#                 survey_mgra_gdf,\n",
    "#                 geometry=gpd.points_from_xy(\n",
    "#                     survey_mgra_gdf[f\"{var_prefix}_longitude\"], survey_mgra_gdf[f\"{var_prefix}_latitude\"]\n",
    "#                 ),\n",
    "#                 crs=survey_crs,\n",
    "#             )\n",
    "# survey_mgra_df.to_crs(geography_df.crs).plot(ax = ax, alpha = .5)\n",
    "# plt.xlim((6.25e6,6.35e6))\n",
    "# plt.ylim((1.8e6,1.94e6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # heatmap\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.plot(ax = ax, color = 'red', alpha = .1)\n",
    "\n",
    "# selected_geography_survey_weights = survey_respondent_geographies.groupby(f'{var_prefix}_{selected_geography.lower()}')['weight'].sum()\n",
    "# geographies_survey_weights = (\n",
    "#                     geographies.merge(\n",
    "#                         selected_geography_survey_weights,\n",
    "#                         left_on=selected_geography,\n",
    "#                         right_on=f'{var_prefix}_{selected_geography.lower()}'\n",
    "#                   )\n",
    "# )\n",
    "\n",
    "# geographies_survey_weights.to_crs(geographies.crs).plot(ax = ax, alpha = .5, column='weight', legend=True)\n",
    "# plt.xlim((6.15e6,6.65e6))\n",
    "# plt.ylim((1.75e6,2.2e6))\n",
    "\n",
    "# # zoom in on central SD\n",
    "# plt.xlim((6.25e6,6.35e6))\n",
    "# plt.ylim((1.8e6,1.95e6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check adrift respondents\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'orange', alpha = .1)\n",
    "\n",
    "# survey_mgra_df = gpd.GeoDataFrame(\n",
    "#                 survey_respondent_geographies,\n",
    "#                 geometry=gpd.points_from_xy(\n",
    "#                     survey_respondent_geographies[f\"{var_prefix}_longitude\"], survey_respondent_geographies[f\"{var_prefix}_latitude\"]\n",
    "#                 ),\n",
    "#                 crs=survey_crs,\n",
    "#             )\n",
    "# # survey_mgra_df.query('~origin_taz.isnull()').to_crs(geographies.crs).plot(ax = ax, alpha = .5)\n",
    "# (\n",
    "#     survey_mgra_df\n",
    "#     .query(f'{var_prefix}_taz.isnull()')\n",
    "#     .loc[survey_mgra_df[f'{var_prefix}_latitude'].between(32.55,33)]\n",
    "#     .loc[survey_mgra_df[f'{var_prefix}_longitude'].between(-117.5,-117)]\n",
    "#     .plot(ax = ax, alpha = .5, color = 'gray')\n",
    "# )\n",
    "\n",
    "# geographies.query('TAZ < 12').to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "\n",
    "# plt.xlim((-117.5,-117))\n",
    "# plt.ylim((32.55,33))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # origin coordinates missing TAZs\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'orange', alpha = .1)\n",
    "\n",
    "# survey_mgra_df = gpd.GeoDataFrame(\n",
    "#                 survey_respondent_geographies,\n",
    "#                 geometry=gpd.points_from_xy(\n",
    "#                     survey_respondent_geographies[f\"{var_prefix}_longitude\"], survey_respondent_geographies[f\"{var_prefix}_latitude\"]\n",
    "#                 ),\n",
    "#                 crs=survey_crs,\n",
    "#             )\n",
    "# survey_mgra_df.query(f'{var_prefix}_taz.isnull()').plot(ax = ax, alpha = .5, label = 'missing_TAZ')\n",
    "# # survey_mgra_df.query(f'{var_prefix}_taz.notna()').plot(ax = ax, alpha = .5, color = 'gray', label = 'has_TAZ')\n",
    "# plt.legend()\n",
    "\n",
    "# # geographies.query('TAZ < 12').to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "\n",
    "# # plt.xlim((-117.7,-116))\n",
    "# # plt.ylim((32.5,33.5))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Skims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_with_geographies = survey_respondent_geographies.query('(origin_taz.notna()) and (destination_taz.notna())')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_path = os.path.join(base_scenario_path,'output','skims')\n",
    "transit_am_skims_path = os.path.join(skim_path,'transit_skims_AM.omx')\n",
    "traffic_am_skims_path = os.path.join(skim_path,'traffic_skims_AM.omx')\n",
    "\n",
    "traffic_am_skims = omx.open_file(traffic_am_skims_path, 'r')\n",
    "transit_am_skims = omx.open_file(transit_am_skims_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_skims(skims, values)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert skims from omx to pandas DataFrame\n",
    "    \"\"\"\n",
    "    zones = list(skims.mapping('zone_number').keys())\n",
    "    df = pd.DataFrame(\n",
    "        np.array(skims[values]),\n",
    "        zones,\n",
    "        zones\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_skim_value(row, skim, col_name, set_zero_val_to_null=False):\n",
    "    \"\"\"\n",
    "    Pandas .apply() function that gets skim values for  O-D TAZ pairs\n",
    "    \"\"\"\n",
    "    value = skim.loc[row['origin_taz'], row['destination_taz']]\n",
    "    if set_zero_val_to_null and value == 0:\n",
    "        value = None\n",
    "    row[col_name] = value\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in auto skims\n",
    "auto_skim_names = ['DIST','SOV_NT_M_TIME__AM','SOV_NT_M_TOLLCOST__AM']\n",
    "auto_skim_new_names = ['auto_dist','auto_time','auto_tollcost']\n",
    "\n",
    "for value,col_name in zip(auto_skim_names,auto_skim_new_names):\n",
    "    set_zero_val_to_null = col_name in ['auto_dist','auto_time']\n",
    "    skim = read_skims(traffic_am_skims,value)\n",
    "    survey_with_geographies = (\n",
    "        survey_with_geographies\n",
    "        .apply(retrieve_skim_value,\n",
    "                skim=skim,\n",
    "                col_name=col_name,\n",
    "                set_zero_val_to_null=set_zero_val_to_null,\n",
    "                axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in transit skims\n",
    "transit_access_modes = ['PNRIN','WALK']\n",
    "transit_flavors = ['LOC','MIX','PRM']\n",
    "transit_values = ['FARE','ACC','FIRSTWAIT','TOTALIVTT','XFERWAIT','EGR']\n",
    "\n",
    "for transit_access_mode in transit_access_modes:\n",
    "    for transit_flavor in transit_flavors:\n",
    "        transit_mode = f'{transit_access_mode}_{transit_flavor}'\n",
    "        survey_with_geographies[f'{transit_mode.lower()}_time'] = 0\n",
    "        for transit_value in transit_values:\n",
    "            col_name = f'{transit_mode}_{transit_value}'\n",
    "            skim = read_skims(transit_am_skims,f'{col_name}__AM')\n",
    "            survey_with_geographies = (\n",
    "                survey_with_geographies\n",
    "                .apply(retrieve_skim_value,\n",
    "                        skim=skim,\n",
    "                        col_name=col_name,\n",
    "                        set_zero_val_to_null=transit_values=='FARE',\n",
    "                        axis=1)\n",
    "                )\n",
    "            # sum all transit travel times\n",
    "            if transit_value != 'FARE':\n",
    "                survey_with_geographies[f'{transit_mode.lower()}_time'] = (\n",
    "                    survey_with_geographies[f'{transit_mode.lower()}_time'] +\n",
    "                    survey_with_geographies[f'{transit_mode}_{transit_value}']\n",
    "                    )\n",
    "                survey_with_geographies.drop(\n",
    "                    columns=[f'{transit_mode}_{transit_value}'],\n",
    "                    inplace=True\n",
    "                    )\n",
    "        survey_with_geographies.rename(columns={\n",
    "                f'{transit_mode}_FARE':\n",
    "                f'{transit_mode.lower()}_fare'\n",
    "            }\n",
    "            ,inplace=True)\n",
    "        # set transit trips w/ total time = 0 to NULL\n",
    "        survey_with_geographies.loc[\n",
    "                survey_with_geographies[f'{transit_mode.lower()}_time']==0,\n",
    "                f'{transit_mode.lower()}_time'\n",
    "            ] = None\n",
    "# survey_with_geographies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations\n",
    "- ground access party size\n",
    "- purpose\n",
    "- parking costs\n",
    "- taxi/TNC fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_output = pd.DataFrame(survey_with_geographies).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party Size\n",
    "Prefer to use ground access party column instead of party size flight column when available\n",
    "\n",
    "431 Null values - equivalent to employee count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coalesce columns, prioritize ground access column\n",
    "survey_output['party_size_transformed'] = (\n",
    "    survey_output\n",
    "        ['party_size_ground_access']\n",
    "        .combine_first(survey_output['party_size_flight'])\n",
    ")\n",
    "\n",
    "survey_output['party_size_label_transformed'] = (\n",
    "    survey_output\n",
    "        ['party_size_ground_access_label']\n",
    "        .combine_first(survey_output['party_size_flight_label'])\n",
    ")\n",
    "\n",
    "# survey_output['party_size_transformed'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose Contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_resident_visitor_general_label = (((\n",
    "#     survey_output\n",
    "#        ['passenger_segment_label']\n",
    "#        .str.split('_')\n",
    "#        .str[0]\n",
    "#     ) + '_')\n",
    "#     .fillna('')\n",
    "# )\n",
    "\n",
    "# # transform resident_visitor question\n",
    "# survey_purpose_dict = {\n",
    "#        'BUSINESS_WORK': 'BUSINESS',\n",
    "#        'LEISURE_FAMILY': 'PERSONAL',\n",
    "#        'COMBINATION_BUSINESS_LEISURE': 'BUSINESS',\n",
    "#        'SCHOOL': 'BUSINESS', #TODO: is it proper to code school as business?\n",
    "#        'COMMUTE': 'BUSINESS'\n",
    "# }\n",
    "# new_flight_purpose_label = (\n",
    "#     survey_output\n",
    "#        ['flight_purpose_label']\n",
    "#        .replace(survey_purpose_dict)\n",
    "#        .fillna('')\n",
    "# )\n",
    "# new_marketsegment_label = (\n",
    "#     survey_output\n",
    "#        ['marketsegment_label']\n",
    "#        .where(\n",
    "#               survey_output['marketsegment_label']=='EMPLOYEE'\n",
    "#               ,''\n",
    "#        )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_output['purpose_transformed'] = (\n",
    "#               new_resident_visitor_general_label +\n",
    "#               new_flight_purpose_label +\n",
    "#               new_marketsegment_label\n",
    "#               )\n",
    "# survey_output.loc[\n",
    "#         survey_output['resident_visitor_followup_label']=='LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT'\n",
    "#         ,'purpose_transformed'\n",
    "#     ] = 'EXTERNAL'\n",
    "\n",
    "# survey_output['purpose_transformed'] = survey_output['purpose_transformed'].str.lower()\n",
    "# # survey_output['purpose_transformed'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSP's current method from notebook 17 - Apr 2, 2025\n",
    "# Define the classification logic using np.where\n",
    "survey_output['purpose_segment'] = np.where(\n",
    "    survey_output['is_sdia_home_airport'] & survey_output['flight_purpose_label'].isin(['BUSINESS_WORK', 'COMBINATION_BUSINESS_LEISURE']),\n",
    "    'RESIDENT_BUSINESS',\n",
    "    np.where(\n",
    "        survey_output['marketsegment_label']=='EMPLOYEE', 'EMPLOYEE',\n",
    "        np.where(\n",
    "            survey_output['is_sdia_home_airport'], 'RESIDENT_NON_BUSINESS',\n",
    "            np.where(\n",
    "                survey_output['flight_purpose_label'].isin(['BUSINESS_WORK', 'COMBINATION_BUSINESS_LEISURE']),\n",
    "                'VISITOR_BUSINESS',\n",
    "                'VISITOR_NON_BUSINESS'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# survey_output['purpose_segment'] = survey_output['purpose_segment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_output.fillna('-------').groupby(['purpose_transformed','passenger_flight_purpose_segment','passenger_flight_purpose_segment_alt'])['unique_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parking Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     survey_output\n",
    "#     .fillna('NULL')\n",
    "#     .groupby(['main_mode_label','purpose_transformed','parking_cost_numeric','parking_location_label'])\n",
    "#     ['unique_id']\n",
    "#     .count()\n",
    "#     .reset_index(drop=False)\n",
    "#     .query('main_mode_label.str.contains(\"PARK\")')\n",
    "#     .query('~main_mode_label.str.contains(\"RENT\")')\n",
    "#     .query('parking_cost_numeric==\"NULL\"')\n",
    "#     [['main_mode_label','purpose_transformed','parking_location_label','unique_id']]\n",
    "#     .head()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi/TNC Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # missing fares occurs rarely, missing wait time slightly more frequent\n",
    "# (\n",
    "#     survey_output\n",
    "#     .fillna('NULL')\n",
    "#     .groupby(['main_mode_label','taxi_fhv_fare_numeric','taxi_fhv_wait_numeric'])\n",
    "#     ['unique_id']\n",
    "#     .count()\n",
    "#     .reset_index(drop=False)\n",
    "#     .query('main_mode_label in [\"UBER_LYFT\",\"CAR_SERVICE_BLACK_LIMO\",\"TAXI\"]')\n",
    "#     # .query('taxi_fhv_wait_numeric==\"NULL\"')\n",
    "#     .query('taxi_fhv_fare_numeric==\"NULL\"')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fare\n",
    "    - survey column: taxi_fhv_fare_numeric\n",
    "    - from the model configs: \n",
    "        - https://github.com/SANDAG/ABM/blob/e5201dd13e2d370c6acd0f9f294ec06de876529e/src/asim/configs/common/constants.yaml\n",
    "    - taxi, TNC Single, excluding TNC Share for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxi/tnc fare\n",
    "taxi_base_fare = 3\n",
    "taxi_cost_mile = 3.3\n",
    "\n",
    "tnc_base_fare = 3.31\n",
    "tnc_cost_mile = .96\n",
    "tnc_min_fare = 9.19\n",
    "\n",
    "survey_output['taxi_fare_model'] = taxi_base_fare + taxi_cost_mile * survey_output['auto_dist']\n",
    "\n",
    "survey_output['tnc_fare_model'] = tnc_base_fare + tnc_cost_mile * survey_output['auto_dist']\n",
    "survey_output['tnc_fare_model'] = (\n",
    "    survey_output\n",
    "    ['tnc_fare_model']\n",
    "    .where(\n",
    "        survey_output['tnc_fare_model'] > tnc_min_fare,\n",
    "        tnc_min_fare\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  wait time \n",
    "    - survey column for comparison: taxi_fhv_wait_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Taxi_waitTime_mean = {\n",
    "  1: 5.5,\n",
    "  2: 9.5,\n",
    "  3: 13.3,\n",
    "  4: 17.3,\n",
    "  5: 26.5\n",
    "}\n",
    "TNC_single_waitTime_mean = {\n",
    "  1: 3.0,\n",
    "  2: 6.3,\n",
    "  3: 8.4,\n",
    "  4: 8.5,\n",
    "  5: 10.3\n",
    "}\n",
    "\n",
    "survey_output['taxi_mean_wait_model'] = survey_output['origin_pmsa'].map(Taxi_waitTime_mean)\n",
    "survey_output['tnc_mean_wait_model'] = survey_output['origin_pmsa'].map(TNC_single_waitTime_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "   'unique_id',\n",
    "   # 'weight_departing_and_arriving',\n",
    "   'weight_departing_only',\n",
    "   # 'weight_non_sas_departing_only',\n",
    "   # 'weight_departing_only_with_time_of_day',\n",
    "\n",
    "   # survey respondent demos\n",
    "   'age',\n",
    "   'age_label',\n",
    "   'gender',\n",
    "   'gender_label',\n",
    "   'occupation',\n",
    "   'occupation_label',\n",
    "   'household_income',\n",
    "   'household_income_label',\n",
    "   # 'purpose_transformed', # constructed trip characteristic\n",
    "   'purpose_segment', # WSP's constructed trip characteristic, w/ employee logic included\n",
    "   'passenger_segment',\n",
    "   'passenger_segment_label',\n",
    "   'resident_visitor',\n",
    "   'resident_visitor_label',\n",
    "   'flight_purpose',\n",
    "   'flight_purpose_label',\n",
    "   'car_available',\n",
    "   'car_available_label',\n",
    "\n",
    "   # survey trip characteristics\n",
    "   'main_mode',\n",
    "   'main_mode_label',\n",
    "#  'access_mode_label',\n",
    "#  'egress_mode_label',\n",
    "   'trip_arrival_time',\n",
    "   'trip_arrival_time_label',\n",
    "   'airline',\n",
    "   'airline_label',\n",
    "   'nights_away',\n",
    "   'nights_away_label',\n",
    "   'airport_terminal',\n",
    "   'convention_center',\n",
    "   'convention_center_label',\n",
    "   'convention_center_activity',\n",
    "   'convention_center_activity_label',\n",
    "   'party_size_transformed', # constructed trip characteristic\n",
    "   'party_size_label_transformed', # constructed trip characteristic\n",
    "   'parking_cost_numeric', # has NULL values\n",
    "   'parking_location',\n",
    "   'parking_location_label',\n",
    "   'parking_location_other',\n",
    "\n",
    "   # respondent TAZs\n",
    "   'origin_taz',\n",
    "   'destination_taz',\n",
    "   'home_location_taz',\n",
    "   'transit_alighting_taz',\n",
    "   'transit_boarding_taz',\n",
    "\n",
    "   # trip data from 2022 base scenario skims\n",
    "   'auto_dist', 'auto_time', 'auto_tollcost',\n",
    "   'pnrin_loc_fare', 'pnrin_mix_fare', 'pnrin_prm_fare',\n",
    "   'pnrin_loc_time', 'pnrin_mix_time', 'pnrin_prm_time',\n",
    "   'walk_loc_fare', 'walk_mix_fare', 'walk_prm_fare',\n",
    "   'walk_loc_time', 'walk_mix_time',  'walk_prm_time',\n",
    "\n",
    "   # TNC/taxi columns - mix of survey and constructed data\n",
    "   'taxi_fhv_fare_numeric', # fare\n",
    "   'taxi_fare_model',\n",
    "   'tnc_fare_model',\n",
    "   'taxi_fhv_wait_numeric', # wait\n",
    "   'taxi_mean_wait_model',\n",
    "   'tnc_mean_wait_model',\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    survey_output\n",
    "    [keep_cols]\n",
    "    .to_csv(processed_survey_data_low_pii_simplified_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destination_latitude',\n",
       " 'destination_longitude',\n",
       " 'geometry',\n",
       " 'home_location_latitude',\n",
       " 'home_location_longitude',\n",
       " 'origin_latitude',\n",
       " 'origin_longitude',\n",
       " 'transit_alighting_latitude',\n",
       " 'transit_alighting_longitude',\n",
       " 'transit_boarding_latitude',\n",
       " 'transit_boarding_longitude'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop high PII columns\n",
    "drop_columns = set()\n",
    "col_filters = ['latitude','longitude','geometry']#,'employer']\n",
    "for col_filter in col_filters:\n",
    "    drop_columns.update({col for col in survey_output.columns if col_filter in col})\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only label columns\n",
    "for i in range(len(survey_output.columns)-1):\n",
    "    col1 = survey_output.columns[i]\n",
    "    col2 = survey_output.columns[i+1].replace('_label','')\n",
    "    if col1 == col2 and col1 != 'trip_arrival_time':\n",
    "        drop_columns.add(col1)\n",
    "        # print(f'{col1}: {survey_output.columns[i+1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns.update({\n",
    "    'respondentid',\n",
    "    'is_completed',\n",
    "    'date_completed',\n",
    "    'is_pilot',\n",
    "    'is_self_administered',\n",
    "\n",
    "    'gender_other', # empty\n",
    "    'interview_location_label',\n",
    "    'interview_location_other',\n",
    "    'is_qualified_age',\n",
    "\n",
    "    # 'main_mode_other', #mapped some options to modes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    survey_output\n",
    "    .drop(columns=list(drop_columns))\n",
    "    .to_csv(processed_survey_data_low_pii_path)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandag_survey_airport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
