{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath(\"../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import ValidationError\n",
    "import data_model\n",
    "import enums as e\n",
    "from utils import extract_base_type, add_enum_label_columns, add_list_objects  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_model)\n",
    "importlib.reload(e)\n",
    "from data_model import Respondent, Employee, AirPassenger, Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dir = \"../data/external\"\n",
    "interim_dir = \"../data/interim\"\n",
    "processed_dir = \"../data/processed\"\n",
    "\n",
    "input_file = os.path.join(external_dir, \"etc/od_20241015_sandag_airport_pilot_4.xlsx\") #pilot survey 3, latest\n",
    "variable_map_file = os.path.join(processed_dir, \"revised_names.csv\")\n",
    "clean_survey_file = os.path.join(interim_dir, \"survey_data_clean.csv\")\n",
    "output_csv_filename = os.path.join(processed_dir, \"data_model_output.csv\")\n",
    "#summary_csv_filename = os.path.join(processed_dir, \"data_model_output_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data , Rename fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_excel(input_file)\n",
    "header_df = pd.read_csv(variable_map_file)[['ETC_name','WSP_name']]\n",
    "header_dict = pd.Series(header_df.WSP_name.values,index=header_df.ETC_name).to_dict()\n",
    "clean_df = in_df.rename(columns=header_dict).copy().drop(columns=[\"delete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3597, 302)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondentid</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>interview_location</th>\n",
       "      <th>interview_location_label</th>\n",
       "      <th>interview_location_other</th>\n",
       "      <th>inbound_or_outbound</th>\n",
       "      <th>inbound_or_outbound_label</th>\n",
       "      <th>marketsegment</th>\n",
       "      <th>marketsegment_label</th>\n",
       "      <th>is_qualified_age</th>\n",
       "      <th>...</th>\n",
       "      <th>household_income_label</th>\n",
       "      <th>is_income_below_poverty</th>\n",
       "      <th>number_workers</th>\n",
       "      <th>number_workers_label</th>\n",
       "      <th>sp_invitation</th>\n",
       "      <th>sp_invitation_label</th>\n",
       "      <th>stay_informed</th>\n",
       "      <th>survey_language</th>\n",
       "      <th>survey_language_label</th>\n",
       "      <th>survey_language_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4273</td>\n",
       "      <td>9/30/2024</td>\n",
       "      <td>Term1</td>\n",
       "      <td>Terminal 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OUT</td>\n",
       "      <td>OUTBOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>YES</td>\n",
       "      <td>...</td>\n",
       "      <td>$75,000-$99,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TWO (2)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4282</td>\n",
       "      <td>9/30/2024</td>\n",
       "      <td>Term1</td>\n",
       "      <td>Terminal 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>YES</td>\n",
       "      <td>...</td>\n",
       "      <td>$60,000-$74,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>SIX (6)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPANI</td>\n",
       "      <td>SPANISH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4283</td>\n",
       "      <td>9/30/2024</td>\n",
       "      <td>Term1</td>\n",
       "      <td>Terminal 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>YES</td>\n",
       "      <td>...</td>\n",
       "      <td>$60,000-$74,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE (0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4286</td>\n",
       "      <td>9/30/2024</td>\n",
       "      <td>Term1</td>\n",
       "      <td>Terminal 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>YES</td>\n",
       "      <td>...</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TWO (2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4290</td>\n",
       "      <td>9/30/2024</td>\n",
       "      <td>Term1</td>\n",
       "      <td>Terminal 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>INBOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>Air passenger</td>\n",
       "      <td>YES</td>\n",
       "      <td>...</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE (0)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondentid date_completed interview_location interview_location_label  \\\n",
       "0          4273      9/30/2024              Term1               Terminal 1   \n",
       "1          4282      9/30/2024              Term1               Terminal 1   \n",
       "2          4283      9/30/2024              Term1               Terminal 1   \n",
       "3          4286      9/30/2024              Term1               Terminal 1   \n",
       "4          4290      9/30/2024              Term1               Terminal 1   \n",
       "\n",
       "  interview_location_other inbound_or_outbound inbound_or_outbound_label  \\\n",
       "0                      NaN                 OUT                  OUTBOUND   \n",
       "1                      NaN                  IN                   INBOUND   \n",
       "2                      NaN                  IN                   INBOUND   \n",
       "3                      NaN                  IN                   INBOUND   \n",
       "4                      NaN                  IN                   INBOUND   \n",
       "\n",
       "   marketsegment marketsegment_label is_qualified_age  ...  \\\n",
       "0              1       Air passenger              YES  ...   \n",
       "1              1       Air passenger              YES  ...   \n",
       "2              1       Air passenger              YES  ...   \n",
       "3              1       Air passenger              YES  ...   \n",
       "4              1       Air passenger              YES  ...   \n",
       "\n",
       "   household_income_label is_income_below_poverty  number_workers  \\\n",
       "0         $75,000-$99,999                     NaN               2   \n",
       "1         $60,000-$74,999                     NaN               6   \n",
       "2         $60,000-$74,999                     NaN               0   \n",
       "3        $150,000 or more                     NaN               2   \n",
       "4       Prefer not to say                      No               0   \n",
       "\n",
       "  number_workers_label  sp_invitation sp_invitation_label  stay_informed  \\\n",
       "0              TWO (2)            2.0                  No             NO   \n",
       "1              SIX (6)            1.0                 Yes            NaN   \n",
       "2             NONE (0)            2.0                  No             NO   \n",
       "3              TWO (2)            1.0                 Yes            NaN   \n",
       "4             NONE (0)            2.0                  No             NO   \n",
       "\n",
       "  survey_language  survey_language_label survey_language_other  \n",
       "0         ENGLISH                ENGLISH                   NaN  \n",
       "1           SPANI                SPANISH                   NaN  \n",
       "2         ENGLISH                ENGLISH                   NaN  \n",
       "3         ENGLISH                ENGLISH                   NaN  \n",
       "4         ENGLISH                ENGLISH                   NaN  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly occuring invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interview_location', 'flight_purpose', 'shift_start_airport_building', 'employer', 'occupation', 'origin_activity_type', 'main_mode', 'access_mode', 'parking_location', 'parking_cost_frequency', 'car_available', 'reverse_mode_predicted', 'reverse_commute_mode', 'same_commute_mode', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of columns that contain '-oth-' as a value\n",
    "columns_with_oth_value = [col for col in clean_df.columns if clean_df[col].eq('-oth-').any()]\n",
    "\n",
    "print(columns_with_oth_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight_number', 'origin_city', 'origin_state', 'origin_zip', 'destination_city', 'destination_zip', 'transit_boarding_stop_name', 'transit_boarding_latitude', 'transit_boarding_longitude', 'transit_alighting_stop_name', 'transit_alighting_latitude', 'transit_alighting_longitude', 'home_location_city', 'home_location_zip']\n"
     ]
    }
   ],
   "source": [
    "columns_with_dash_value = [col for col in clean_df.columns if clean_df[col].eq('-').any()]\n",
    "\n",
    "print(columns_with_dash_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making all modes consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egress_mode_label\n",
       "Walk                                 20\n",
       "Picked up by car by family/friend     5\n",
       "Drive alone and park                  1\n",
       "Other shared van (please specify)     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['egress_mode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "DROPPED OFF BY CAR BY FRIEND FAMILY               190\n",
       "UBER LYFT                                          76\n",
       "DROVE ALONE AND PARKED                             32\n",
       "DROVE WITH OTHERS AND PARKED                       23\n",
       "OTHER PUBLIC TRANSIT                               17\n",
       "RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY     17\n",
       "TAXI                                               12\n",
       "WHEELCHAIR OR OTHER MOBILITY DEVICE                11\n",
       "RENTAL CAR AND PARKED IT                            8\n",
       "WALK                                                7\n",
       "CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR            3\n",
       "HOTEL SHUTTLE VAN                                   3\n",
       "CHARTERED TOUR BUS                                  1\n",
       "PERSONAL NON ELECTRIC BICYCLE                       1\n",
       "OTHER SHARED RIDE VAN SERVICE                       1\n",
       "RODE WITH OTHER TRAVELER AND PARKED                 1\n",
       "ELECTRIC BIKESHARE                                  1\n",
       "EMPLOYEE SHUTTLE                                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_airport_accessmode_label_map = {\n",
    "    'Walk': 'Walk',\n",
    "    'Wheelchair or other mobility device': 'Wheelchair or other mobility device',\n",
    "    'ELECTRIC BIKESHARE': 'Bicycle: electric bikeshare',\n",
    "    'NON ELECTRIC BIKESHARE': 'Bicycle: non-electric bikeshare',\n",
    "    'E SCOOTER SHARE': 'E-scooter: shared',\n",
    "    'PERSONAL ELECTRIC BICYCLE': 'Bicycle: personal electric bicycle',\n",
    "    'PERSONAL NON ELECTRIC BICYCLE': 'Bicycle: personal non-electric bicycle',\n",
    "    'PERSONAL E SCOOTER': 'E-scooter: personal',\n",
    "    'Taxi': 'Taxi',\n",
    "    'UBER LYFT': 'Uber/Lyft',\n",
    "    'CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR': 'Car service/black car/limo/executive car',\n",
    "    'DROPPED OFF BY CAR BY FRIEND FAMILY': 'Dropped off by car by family/friend',\n",
    "    'Drove alone and parked': 'Drove alone and parked',\n",
    "    'Drove with others and parked': 'Drove with others and parked',\n",
    "    'RODE WITH OTHER TRAVELER AND PARKED': 'Rode with other traveler(s) and parked',\n",
    "    'Other public transit': 'Other public transit',\n",
    "    'Chartered tour bus': 'Chartered tour bus',\n",
    "    'Employee shuttle': 'Employee shuttle',\n",
    "    'RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY': 'Rental car: Dropped off at rental agency',\n",
    "    'RENTAL CAR AND PARKED IT': 'Rental car: parked rental car',\n",
    "    'Hotel shuttle van': 'Hotel shuttle van',\n",
    "    'OTHER SHARED RIDE VAN SERVICE': 'Other shared van (please specify)',\n",
    "    'Other': 'Other',\n",
    "    'Refused/No Answer': 'Refused/No Answer'\n",
    "}\n",
    "clean_df['other_airport_accessmode_label'] = clean_df['other_airport_accessmode_label'].map(other_airport_accessmode_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         190\n",
       "Uber/Lyft                                    76\n",
       "Rental car: Dropped off at rental agency     17\n",
       "Rental car: parked rental car                 8\n",
       "Car service/black car/limo/executive car      3\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Rode with other traveler(s) and parked        1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_dict = {\n",
    "    'Walk': 1,\n",
    "    'Wheelchair or other mobility device': 2,\n",
    "    'Bicycle: electric bikeshare': 3,\n",
    "    'Bicycle: non-electric bikeshare': 4,\n",
    "    'E-scooter: shared': 5,\n",
    "    'Bicycle: personal electric bicycle': 6,\n",
    "    'Bicycle: personal non-electric bicycle': 7,\n",
    "    'E-scooter: personal': 8,\n",
    "    'Taxi': 9,\n",
    "    'Uber/Lyft': 10,\n",
    "    'Car service/black car/limo/executive car': 11,\n",
    "    'Dropped off by car by family/friend': 12,\n",
    "    'Drove alone and parked': 13,\n",
    "    'Drove with others and parked': 14,\n",
    "    'Chartered tour bus': 17,\n",
    "    'Employee shuttle': 18,\n",
    "    'Rental car: Dropped off at rental agency': 19,\n",
    "    'Rental car: parked rental car': 20,\n",
    "    'Hotel shuttle van': 21,\n",
    "    'Other shared van (please specify)': 22,\n",
    "    'Picked up by car by family/friend': 23,\n",
    "    'Get in a parked vehicle and drive alone': 24,\n",
    "    'Get in a parked vehicle and drive with others': 25,\n",
    "    'Get in a parked vehicle and ride with other traveler(s)': 26,\n",
    "    'Rental car: Picked up at rental agency': 27,\n",
    "    'Rental car: get in a parked rental car': 28,\n",
    "    'Rode with other traveler(s) and parked': 29,\n",
    "    'Other public transit': 30,\n",
    "    'Other': 98,\n",
    "    'Refused/No Answer': 99\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modes to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_code_columns = ['main_transit_mode', 'main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "mode_label_columns = ['main_transit_mode_label', 'main_mode_label', 'access_mode_label', 'egress_mode_label', 'reverse_mode_label', 'reverse_mode_predicted_label', 'other_airport_accessmode_label', 'reverse_commute_mode_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping codes using label strings\n",
    "for mode_code_col, mode_label_col in zip(mode_code_columns, mode_label_columns):\n",
    "    # Apply the mapping for each pair of columns\n",
    "    clean_df[mode_code_col] = clean_df[mode_label_col].map(travel_mode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         190\n",
       "Uber/Lyft                                    76\n",
       "Rental car: Dropped off at rental agency     17\n",
       "Rental car: parked rental car                 8\n",
       "Car service/black car/limo/executive car      3\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Rode with other traveler(s) and parked        1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_airport_accessmode\n",
       "12.0    190\n",
       "10.0     76\n",
       "19.0     17\n",
       "20.0      8\n",
       "11.0      3\n",
       "7.0       1\n",
       "22.0      1\n",
       "29.0      1\n",
       "3.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of some fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_39228\\1523206846.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  clean_df.replace('-oth-', 98, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "clean_df['date_completed'] = pd.to_datetime(clean_df['date_completed'])\n",
    "clean_df.replace('-oth-', 98, inplace=True)\n",
    "clean_df.replace('-', None, inplace = True )\n",
    "\n",
    "#Maps\n",
    "interview_location_map = {'Term1' : 1, 'Term2': 2, 'MTS_1_992': 3, 'SDA_1_Flyer': 4, 'ConracShuttle': 5, 'ParkingShuttle': 6, 'EmplParking': 7, '-oth-':98} \n",
    "inbound_outbound_map = {'IN':1, 'OUT':2}\n",
    "main_transit_mode_map = {'SDA_1_FLYER': 16, 'MTS_1_992': 15, 3: None}\n",
    "\n",
    "all_modes_map = {}\n",
    "#route_fields:\n",
    "route_fields = ['to_airport_transit_route_1', 'to_airport_transit_route_2', 'to_airport_transit_route_3', 'to_airport_transit_route_4',\n",
    "                'from_airport_transit_route_1', 'from_airport_transit_route_2', 'from_airport_transit_route_3', 'from_airport_transit_route_4']\n",
    "\n",
    "#Replacement\n",
    "clean_df['interview_location'] = clean_df['interview_location'].map(interview_location_map)\n",
    "clean_df['inbound_or_outbound'] = clean_df['inbound_or_outbound'].map(inbound_outbound_map)\n",
    "clean_df['main_transit_mode'] = clean_df['main_transit_mode'].map(main_transit_mode_map)\n",
    "clean_df[route_fields] = clean_df[route_fields].replace(98, 'OTHER')\n",
    "clean_df['nights_visited'] = clean_df['nights_visited'] - 1\n",
    "\n",
    "clean_df['household_income'] = np.where(clean_df['household_income'] >= 15, 13, clean_df['household_income'])\n",
    "clean_df['same_commute_mode'] = np.where(clean_df['same_commute_mode'] == 0, 2, clean_df['same_commute_mode'])\n",
    "clean_df['resident_visitor_followup'] = np.where(clean_df['resident_visitor_followup'] == 0, 2, clean_df['resident_visitor_followup'])\n",
    "\n",
    "#activity_type\n",
    "clean_df['origin_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.OUTBOUND_FROM_AIRPORT, None, clean_df['origin_activity_type'])\n",
    "clean_df['destination_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.INBOUND_TO_AIRPORT, None, clean_df['destination_activity_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "3592    2.0\n",
       "3593    1.0\n",
       "3594    1.0\n",
       "3595    2.0\n",
       "3596    1.0\n",
       "Name: interview_location, Length: 3597, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['interview_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(clean_survey_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Variables to verify for the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['validation_error', 'validation_severity', 'valid_record'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m variables_to_verify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(air_passenger_variables \u001b[38;5;241m+\u001b[39m respondent_variables \u001b[38;5;241m+\u001b[39m trip_variables \u001b[38;5;241m+\u001b[39m employee_variables))\n\u001b[0;32m     18\u001b[0m working_df \u001b[38;5;241m=\u001b[39m clean_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 19\u001b[0m working_df \u001b[38;5;241m=\u001b[39m \u001b[43mworking_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariables_to_verify\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     20\u001b[0m working_df \u001b[38;5;241m=\u001b[39m working_df\u001b[38;5;241m.\u001b[39mloc[working_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketsegment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     21\u001b[0m working_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['validation_error', 'validation_severity', 'valid_record'] not in index\""
     ]
    }
   ],
   "source": [
    "respondent_variables = [field_name for field_name, field_info in Respondent.__fields__.items()]\n",
    "\n",
    "\n",
    "trip_variables = [field_name for field_name, field_info in Trip.__fields__.items()]\n",
    "trip_variables.append('respondentid')\n",
    "\n",
    "employee_variables = [field_name for field_name, field_info in Employee.__fields__.items()]\n",
    "employee_variables.remove('trip')\n",
    "\n",
    "air_passenger_variables = [field_name for field_name, field_info in AirPassenger.__fields__.items()]\n",
    "air_passenger_variables.remove('trip')\n",
    "\n",
    "variables_to_verify = list(set(air_passenger_variables + respondent_variables + trip_variables + employee_variables))\n",
    "variables_to_verify.remove('trip')\n",
    "variables_to_verify.remove('valid_record')\n",
    "variables_to_verify.remove('validation_error')\n",
    "variables_to_verify.remove('validation_severity')\n",
    "\n",
    "\n",
    "working_df = clean_df.copy()\n",
    "working_df = working_df[variables_to_verify].copy()\n",
    "working_df = working_df.loc[working_df['marketsegment'].notna()].copy()\n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3597, 237)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = working_df[trip_variables].copy()\n",
    "persons_df = working_df[list[set(employee_variables + respondent_variables + air_passenger_variables)]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "respondent_list = add_list_objects(\n",
    "        trips_df.to_dict(orient=\"records\"),  #child list\n",
    "        \"respondentid\", # child key\n",
    "        persons_df.to_dict(orient=\"records\"), # parent list\n",
    "        \"respondentid\", # parent key\n",
    "        \"trip\", # parent var\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3597"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(respondent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Employee' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m market_segment \u001b[38;5;241m==\u001b[39m e\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mEMPLOYEE:\n\u001b[1;32m---> 10\u001b[0m         ev \u001b[38;5;241m=\u001b[39m \u001b[43mEmployee\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrespondent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         employee_list\u001b[38;5;241m.\u001b[39mappend(ev)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m market_segment \u001b[38;5;241m==\u001b[39m e\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mPASSENGER:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\projects\\SANDAG\\Survey_Airport\\data_model\\data_model.py:883\u001b[0m, in \u001b[0;36mRespondent.prefer_not_disclose_is_unique\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m race_unknown \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    875\u001b[0m     race_aian\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m race_asian\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m race_white\n\u001b[0;32m    881\u001b[0m ):\n\u001b[0;32m    882\u001b[0m     values\u001b[38;5;241m.\u001b[39mrace_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 883\u001b[0m     \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_record\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrefer Not to disclose cannot be combined with any other race\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    885\u001b[0m     values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_severity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Employee' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "employee_list = []\n",
    "air_passenger_list = []\n",
    "other_list = []\n",
    "failed_records = []\n",
    "\n",
    "for respondent in respondent_list:\n",
    "    market_segment = respondent[\"marketsegment\"]\n",
    "    try:\n",
    "        if market_segment == e.Type.EMPLOYEE:\n",
    "            ev = Employee(** respondent)\n",
    "            employee_list.append(ev)\n",
    "        elif market_segment == e.Type.PASSENGER:\n",
    "             av = AirPassenger(** respondent)\n",
    "             air_passenger_list.append(av)\n",
    "        else:\n",
    "            rv = Respondent(** respondent)\n",
    "            other_list.append(rv)\n",
    "    except ValidationError as err:\n",
    "            respondent['error_flag'] = 'failed'\n",
    "            respondent['error_message'] = str(err)\n",
    "            failed_records.append(respondent) \n",
    "\n",
    "\n",
    "failed_df = pd.DataFrame(failed_records)\n",
    "failed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 240)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1 validation error for AirPassenger\\nprevious_...\n",
       "Name: error_message, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_df['error_message'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df.to_csv('../data/processed/failed_records.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "employee_df = pd.DataFrame([Employee.model_dump() for Employee in employee_list])       \n",
    "employee_df = add_enum_label_columns(employee_df,Employee)\n",
    "employee_df = add_enum_label_columns(employee_df,Respondent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "passenger_df = pd.DataFrame([AirPassenger.model_dump() for AirPassenger in air_passenger_list])\n",
    "passenger_df = add_enum_label_columns(passenger_df,AirPassenger)\n",
    "passenger_df = add_enum_label_columns(passenger_df,Respondent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = pd.DataFrame([Respondent.model_dump() for Respondent in other_list])\n",
    "# other_df = add_enum_label_columns(other_df, Respondent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\USVV724227\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "trip_list = []\n",
    "id_list = []\n",
    "for record in employee_list + air_passenger_list + other_list:\n",
    "    trip_list.append(record.trip)\n",
    "    id_list.append(record.respondentid)\n",
    "\n",
    "trip_df = pd.DataFrame([Trip.model_dump() for Trip in trip_list])\n",
    "id_df = pd.DataFrame(id_list, columns=[\"respondentid\"])\n",
    "\n",
    "trip_df = pd.concat([id_df, trip_df], axis=1)\n",
    "trip_df = add_enum_label_columns(trip_df,Trip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USVV724227\\AppData\\Local\\Temp\\ipykernel_40520\\2189731026.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat([employee_df, passenger_df, other_df], axis=0).reset_index(drop=True).drop(columns=[\"trip\"])\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.concat([employee_df, passenger_df, other_df], axis=0).reset_index(drop=True).drop(columns=[\"trip\"])\n",
    "output_df = pd.merge(output_df, trip_df, on=\"respondentid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3596, 306)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondentid</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>access_mode</th>\n",
       "      <th>access_mode_label</th>\n",
       "      <th>access_mode_other</th>\n",
       "      <th>age</th>\n",
       "      <th>age_label</th>\n",
       "      <th>airline</th>\n",
       "      <th>airport_access_transit_use_elsewhere</th>\n",
       "      <th>airport_access_transit_use_elsewhere_label</th>\n",
       "      <th>...</th>\n",
       "      <th>transit_alighting_latitude</th>\n",
       "      <th>transit_alighting_longitude</th>\n",
       "      <th>transit_alighting_stop_name</th>\n",
       "      <th>transit_boarding_latitude</th>\n",
       "      <th>transit_boarding_longitude</th>\n",
       "      <th>transit_boarding_stop_name</th>\n",
       "      <th>trip_arrival_time</th>\n",
       "      <th>trip_arrival_time_label</th>\n",
       "      <th>trip_start_time</th>\n",
       "      <th>trip_start_time_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4399</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DROPPED_OFF_BY_FAMILY_FRIEND</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>AGE_20_24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>26.0</td>\n",
       "      <td>SEVENTEEN_THIRTY_TO_EIGHTEEN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NOON_TO_TWELVE_THIRTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4409</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>AGE_20_24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>18.0</td>\n",
       "      <td>THIRTEEN_THIRTY_TO_FOURTEEN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>THIRTEEN_TO_THIRTEEN_THIRTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4419</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>AGE_65_74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>TEN_THIRTY_TO_ELEVEN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EIGHT_TO_EIGHT_THIRTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4435</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>AGE_35_39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FOURTEEN_THIRTY_TO_FIFTEEN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FOURTEEN_THIRTY_TO_FIFTEEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4482</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>AGE_25_29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SEVEN_THIRTY_TO_EIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondentid date_completed  access_mode             access_mode_label  \\\n",
       "0          4399     2024-09-30         12.0  DROPPED_OFF_BY_FAMILY_FRIEND   \n",
       "1          4409     2024-09-30          NaN                           nan   \n",
       "2          4419     2024-09-30          NaN                           nan   \n",
       "3          4435     2024-09-30          NaN                           nan   \n",
       "4          4482     2024-10-01          NaN                           nan   \n",
       "\n",
       "  access_mode_other  age  age_label  airline  \\\n",
       "0              None    2  AGE_20_24      NaN   \n",
       "1              None    2  AGE_20_24      NaN   \n",
       "2              None   11  AGE_65_74      NaN   \n",
       "3              None    5  AGE_35_39      NaN   \n",
       "4              None    3  AGE_25_29      NaN   \n",
       "\n",
       "   airport_access_transit_use_elsewhere  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "  airport_access_transit_use_elsewhere_label  ... transit_alighting_latitude  \\\n",
       "0                                        NaN  ...                        NaN   \n",
       "1                                        NaN  ...                        NaN   \n",
       "2                                        NaN  ...                        NaN   \n",
       "3                                        NaN  ...                        NaN   \n",
       "4                                        NaN  ...                        NaN   \n",
       "\n",
       "  transit_alighting_longitude transit_alighting_stop_name  \\\n",
       "0                         NaN                        None   \n",
       "1                         NaN                        None   \n",
       "2                         NaN                        None   \n",
       "3                         NaN                        None   \n",
       "4                         NaN                        None   \n",
       "\n",
       "  transit_boarding_latitude transit_boarding_longitude  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "  transit_boarding_stop_name trip_arrival_time       trip_arrival_time_label  \\\n",
       "0                       None              26.0  SEVENTEEN_THIRTY_TO_EIGHTEEN   \n",
       "1                       None              18.0   THIRTEEN_THIRTY_TO_FOURTEEN   \n",
       "2                       None              12.0          TEN_THIRTY_TO_ELEVEN   \n",
       "3                       None              20.0    FOURTEEN_THIRTY_TO_FIFTEEN   \n",
       "4                       None               6.0         SEVEN_THIRTY_TO_EIGHT   \n",
       "\n",
       "  trip_start_time        trip_start_time_label  \n",
       "0            15.0        NOON_TO_TWELVE_THIRTY  \n",
       "1            17.0  THIRTEEN_TO_THIRTEEN_THIRTY  \n",
       "2             7.0        EIGHT_TO_EIGHT_THIRTY  \n",
       "3            20.0   FOURTEEN_THIRTY_TO_FIFTEEN  \n",
       "4             NaN                          nan  \n",
       "\n",
       "[5 rows x 306 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the first columns and the last column\n",
    "first_columns =  ['respondentid', 'date_completed']\n",
    "\n",
    "# Get the middle columns (excluding first and last columns) and sort them alphabetically\n",
    "middle_columns = sorted([col for col in output_df.columns if col not in first_columns])\n",
    "\n",
    "# Create the new column order\n",
    "new_column_order = first_columns + middle_columns\n",
    "\n",
    "# Reorder the DataFrame\n",
    "output_df = output_df[new_column_order]\n",
    "\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(output_csv_filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
