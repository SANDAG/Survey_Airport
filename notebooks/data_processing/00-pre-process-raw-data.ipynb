{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4833011",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef4bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath(\"../../data_model/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed990b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import ValidationError\n",
    "import data_model\n",
    "import enums as e\n",
    "from utils import extract_base_type, add_enum_label_columns, add_list_objects, add_synthetic_records, map_zones\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fd4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_model)\n",
    "importlib.reload(e)\n",
    "from data_model import Respondent, Employee, AirPassenger, Trip, DepartingPassengerResident, DepartingPassengerVisitor, ArrivingPassengerResident, ArrivingPassengerVisitor, DepartingAirPassenger, ArrivingAirPassenger, Resident, Visitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620468ee",
   "metadata": {},
   "source": [
    "### I/O Files:\n",
    "\n",
    "Raw Files provided by ETC:\n",
    "1. `od_20250314_sandag_airport_draftfinal.xlsx` - This includes the main intercept survey responses. \n",
    "2. `od_20250314_sandag_airport_pilotdata.xlsx` - This includes the pilot survey (also intercept) responses.\n",
    "3. `od_20253014_sandag_airport_sas_draftinal.xlsx` - This includes the self-administered survey (SAS) responses.\n",
    "4. `ATC_airport_travel_survey_SP_data_03212025.xlsx` - This includes the State Preference (SP) Survey responses. The respondents of the SP survey are a subset from the RP survey. \n",
    "\n",
    "Intermediate/Helper files:\n",
    "* `revised_names.csv` : This file acts as a mapping of variable names from the raw files to the data model's field names. Also has a 'delete' value to drop columns.\n",
    "\n",
    "Output Files:\n",
    "* `survey_data_clean.csv`: This is an intermediate file (an output of this script) which gets fed into the data model in the next script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2759821",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dir = \"../../data/external\"\n",
    "interim_dir = \"../../data/interim\"\n",
    "processed_dir = \"../../data/processed\"\n",
    "\n",
    "input_file1 = os.path.join(external_dir, \"etc/od_20250314_sandag_airport_draftfinal.xlsx\") #Main intercept survey responses\n",
    "input_file2 = os.path.join(external_dir, \"etc/od_20250314_sandag_airport_pilotdata.xlsx\") #Pilot responses\n",
    "input_file3 = os.path.join(external_dir, \"etc/od_20253014_sandag_airport_sas_draftinal.xlsx\") #Self administered survey responses\n",
    "input_file4 = os.path.join(external_dir, \"etc/ATC_airport_travel_survey_SP_data_03212025.xlsx\") #Stated Preference Survey Responses\n",
    "\n",
    "variable_map_file = os.path.join(processed_dir, \"revised_names.csv\")\n",
    "clean_survey_file = os.path.join(interim_dir, \"survey_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f389d5",
   "metadata": {},
   "source": [
    "### Clean Data , Rename fields\n",
    "\n",
    "This section does the following:\n",
    "1. Reads all the four files (including complete and incomplete sheets)\n",
    "2. Renames the columns using the `revised_names.csv` file, and drops unecessary columns\n",
    "3. Assigns a few new useful columns : to identify the record type and source, assign placeholder weights to records.\n",
    "4. Merges all datasets to a single dataset (by concating the RP datasets and joining the SP dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2cf10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['is_completed'] = 1\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight'] = 1\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight_departing_and_arriving'] = 1\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight_departing_only'] = 1\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight_non_sas_departing_only'] = 1\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2116306432.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  in_df_complete['weight_departing_only_with_time_of_day'] = 1\n"
     ]
    }
   ],
   "source": [
    "in_df_complete1 = pd.read_excel(input_file1, sheet_name = 0)\n",
    "in_df_incomplete1 = pd.read_excel(input_file1, sheet_name = 1)\n",
    "\n",
    "in_df_complete2 = pd.read_excel(input_file2, sheet_name = 0)\n",
    "in_df_incomplete2 = pd.read_excel(input_file2, sheet_name = 1)\n",
    "\n",
    "in_df_complete3 = pd.read_excel(input_file3, sheet_name = 0)\n",
    "in_df_incomplete3 = pd.read_excel(input_file3, sheet_name = 1)\n",
    "\n",
    "in_df_sp = pd.read_excel(input_file4, sheet_name = 1)\n",
    "\n",
    "in_df_complete2['is_self_administered'], in_df_incomplete2['is_self_administered'] = False, False\n",
    "in_df_complete1['is_self_administered'], in_df_incomplete1['is_self_administered'] = False, False\n",
    "in_df_complete3['is_self_administered'], in_df_incomplete3['is_self_administered'] = True, True\n",
    "\n",
    "\n",
    "header_df = pd.read_csv(variable_map_file)[['ETC_name','WSP_name']]\n",
    "header_dict = pd.Series(header_df.WSP_name.values,index=header_df.ETC_name).to_dict()\n",
    "\n",
    "in_df_complete1 = in_df_complete1.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_complete2 = in_df_complete2.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_complete3 = in_df_complete3.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "\n",
    "\n",
    "in_df_incomplete1 = in_df_incomplete1.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_incomplete2 = in_df_incomplete2.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_incomplete3 = in_df_incomplete3.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "in_df_sp = in_df_sp.rename(columns=header_dict).copy().drop(columns=[\"delete\"])\n",
    "\n",
    "\n",
    "in_df_complete = pd.concat([in_df_complete1, in_df_complete2, in_df_complete3], ignore_index = True)\n",
    "in_df_incomplete = pd.concat([in_df_incomplete1, in_df_incomplete2, in_df_incomplete3], ignore_index = True)\n",
    "\n",
    "in_df_complete['is_completed'] = 1\n",
    "in_df_incomplete['is_completed'] = 0\n",
    "\n",
    "#Populating all weights columns\n",
    "\n",
    "in_df_complete['weight'] = 1\n",
    "in_df_complete['weight_departing_and_arriving'] = 1\n",
    "in_df_complete['weight_departing_only'] = 1\n",
    "in_df_complete['weight_non_sas_departing_only'] = 1\n",
    "in_df_complete['weight_departing_only_with_time_of_day'] = 1\n",
    "\n",
    "in_df_incomplete['weight'] = 0\n",
    "in_df_incomplete['weight_departing_and_arriving'] = 0\n",
    "in_df_incomplete['weight_departing_only'] = 0\n",
    "in_df_incomplete['weight_non_sas_departing_only'] = 0\n",
    "in_df_incomplete['weight_departing_only_with_time_of_day'] = 0\n",
    "\n",
    "\n",
    "#Concat incomplete and complete dataframes\n",
    "clean_df = pd.concat([in_df_complete, in_df_incomplete], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f2b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "is_self_administered",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4a09e425-c9f3-4f2e-af4e-bfa922a0dcf4",
       "rows": [
        [
         "False",
         "8997"
        ],
        [
         "True",
         "955"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "is_self_administered\n",
       "False    8997\n",
       "True      955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['is_self_administered'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab00dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Records:  (5378, 333)\n",
      "Incomplete Records:  (4574, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Complete Records: \", in_df_complete.shape)\n",
    "print(\"Incomplete Records: \", in_df_incomplete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1dec692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9952, 335)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53c5017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5711"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_df['respondentid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e9c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5711, 335)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the duplicate respondentids\n",
    "clean_df.drop_duplicates('respondentid', keep = 'first', inplace = True)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9b4683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5378, 335)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['is_completed']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd74b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates from SP (keep only valid records)\n",
    "in_df_sp = in_df_sp[in_df_sp['sp_is_valid'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee2362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge SP\n",
    "clean_df = clean_df.merge(in_df_sp, on=\"respondentid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1686f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5711, 372)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c75691",
   "metadata": {},
   "source": [
    "#### Add Zones Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5414e88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(origin_pmsa\n",
       " 2     1586\n",
       " 3     1316\n",
       " 1      723\n",
       " 6      460\n",
       " 99     449\n",
       " 4      330\n",
       " 5      311\n",
       " 7      196\n",
       " 8        7\n",
       " Name: count, dtype: int64,\n",
       " destination_pmsa\n",
       " 2     5208\n",
       " 3       50\n",
       " 1       42\n",
       " 99      40\n",
       " 6       17\n",
       " 5       13\n",
       " 4        6\n",
       " 7        2\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PMSA\n",
    "pmsa_zones_shapefile = \"../../data/external/geometry/pmsa_geoms/pmsa_geoms.shp\"\n",
    "clean_df['origin_pmsa'] = map_zones(clean_df, 'origin_latitude', 'origin_longitude', pmsa_zones_shapefile, 'pseudomsa', 99)\n",
    "clean_df['destination_pmsa'] = map_zones(clean_df, 'destination_latitude', 'destination_longitude', pmsa_zones_shapefile, 'pseudomsa', 99)\n",
    "clean_df['origin_pmsa'].value_counts(), clean_df['destination_pmsa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93bb5c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(origin_municipal_zone\n",
       " SAN DIEGO         3431\n",
       " EXTERNAL           449\n",
       " S.D. COUNTY        260\n",
       " CHULA VISTA        233\n",
       " CARLSBAD           168\n",
       " OCEANSIDE          141\n",
       " CORONADO           112\n",
       " ESCONDIDO           77\n",
       " ENCINITAS           74\n",
       " LA MESA             72\n",
       " EL CAJON            59\n",
       " NATIONAL CITY       57\n",
       " POWAY               47\n",
       " SAN MARCOS          42\n",
       " VISTA               38\n",
       " DEL MAR             30\n",
       " LEMON GROVE         27\n",
       " IMPERIAL BEACH      26\n",
       " SANTEE              21\n",
       " SOLANA BEACH        14\n",
       " Name: count, dtype: int64,\n",
       " destination_municipal_zone\n",
       " SAN DIEGO        5293\n",
       " EXTERNAL           40\n",
       " EL CAJON            7\n",
       " S.D. COUNTY         6\n",
       " CARLSBAD            6\n",
       " CHULA VISTA         5\n",
       " OCEANSIDE           5\n",
       " CORONADO            4\n",
       " NATIONAL CITY       3\n",
       " LA MESA             3\n",
       " ENCINITAS           3\n",
       " POWAY               2\n",
       " SOLANA BEACH        1\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Municipal Zones\n",
    "municipal_zones_shapefile = \"../../data/external/geometry/Municipal_Boundaries/Municipal_Boundaries.shp\"\n",
    "clean_df['origin_municipal_zone'] = map_zones(clean_df, 'origin_latitude', 'origin_longitude', municipal_zones_shapefile, 'name', 'EXTERNAL')\n",
    "clean_df['destination_municipal_zone'] = map_zones(clean_df, 'destination_latitude', 'destination_longitude', municipal_zones_shapefile, 'name', 'EXTERNAL')\n",
    "clean_df['origin_municipal_zone'].value_counts(), clean_df['destination_municipal_zone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d47497",
   "metadata": {},
   "source": [
    "### Making all modes consistent\n",
    "\n",
    "This section aims at making the Enums used for all modes consistent, so that they follow the same mapping from `Enums.TravelMode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec161a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "egress_mode_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d6468d2a-87a5-4099-801c-4474cbd366f7",
       "rows": [
        [
         "Walk",
         "30"
        ],
        [
         "Picked up by car by family/friend",
         "15"
        ],
        [
         "Drive alone and park",
         "2"
        ],
        [
         "Uber/Lyft",
         "2"
        ],
        [
         "Taxi",
         "2"
        ],
        [
         "Other shared van (please specify)",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "egress_mode_label\n",
       "Walk                                 30\n",
       "Picked up by car by family/friend    15\n",
       "Drive alone and park                  2\n",
       "Uber/Lyft                             2\n",
       "Taxi                                  2\n",
       "Other shared van (please specify)     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['egress_mode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f794079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "other_airport_accessmode_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ce10b036-095f-4fd8-bf28-5ca07701c689",
       "rows": [
        [
         "DROPPED OFF BY CAR BY FRIEND FAMILY",
         "242"
        ],
        [
         "UBER LYFT",
         "107"
        ],
        [
         "DROVE ALONE AND PARKED",
         "42"
        ],
        [
         "DROVE WITH OTHERS AND PARKED",
         "28"
        ],
        [
         "OTHER PUBLIC TRANSIT",
         "24"
        ],
        [
         "RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY",
         "22"
        ],
        [
         "TAXI",
         "14"
        ],
        [
         "RENTAL CAR AND PARKED IT",
         "11"
        ],
        [
         "WHEELCHAIR OR OTHER MOBILITY DEVICE",
         "11"
        ],
        [
         "WALK",
         "9"
        ],
        [
         "Public transit",
         "5"
        ],
        [
         "Uber / Lyft",
         "5"
        ],
        [
         "CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR",
         "4"
        ],
        [
         "Rental car and dropped it off at rental agency",
         "4"
        ],
        [
         "HOTEL SHUTTLE VAN",
         "3"
        ],
        [
         "Drove alone and parked",
         "2"
        ],
        [
         "RODE WITH OTHER TRAVELER AND PARKED",
         "2"
        ],
        [
         "NON ELECTRIC BIKESHARE",
         "2"
        ],
        [
         "Personal e-scooter",
         "2"
        ],
        [
         "OTHER SHARED RIDE VAN SERVICE",
         "1"
        ],
        [
         "PERSONAL NON ELECTRIC BICYCLE",
         "1"
        ],
        [
         "Walk",
         "1"
        ],
        [
         "Taxi",
         "1"
        ],
        [
         "CHARTERED TOUR BUS",
         "1"
        ],
        [
         "EMPLOYEE SHUTTLE",
         "1"
        ],
        [
         "ELECTRIC BIKESHARE",
         "1"
        ],
        [
         "Other",
         "1"
        ],
        [
         "Car service / Black car / Limo / Executive car",
         "1"
        ],
        [
         "E scooter share",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 29
       }
      },
      "text/plain": [
       "other_airport_accessmode_label\n",
       "DROPPED OFF BY CAR BY FRIEND FAMILY               242\n",
       "UBER LYFT                                         107\n",
       "DROVE ALONE AND PARKED                             42\n",
       "DROVE WITH OTHERS AND PARKED                       28\n",
       "OTHER PUBLIC TRANSIT                               24\n",
       "RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY     22\n",
       "TAXI                                               14\n",
       "RENTAL CAR AND PARKED IT                           11\n",
       "WHEELCHAIR OR OTHER MOBILITY DEVICE                11\n",
       "WALK                                                9\n",
       "Public transit                                      5\n",
       "Uber / Lyft                                         5\n",
       "CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR            4\n",
       "Rental car and dropped it off at rental agency      4\n",
       "HOTEL SHUTTLE VAN                                   3\n",
       "Drove alone and parked                              2\n",
       "RODE WITH OTHER TRAVELER AND PARKED                 2\n",
       "NON ELECTRIC BIKESHARE                              2\n",
       "Personal e-scooter                                  2\n",
       "OTHER SHARED RIDE VAN SERVICE                       1\n",
       "PERSONAL NON ELECTRIC BICYCLE                       1\n",
       "Walk                                                1\n",
       "Taxi                                                1\n",
       "CHARTERED TOUR BUS                                  1\n",
       "EMPLOYEE SHUTTLE                                    1\n",
       "ELECTRIC BIKESHARE                                  1\n",
       "Other                                               1\n",
       "Car service / Black car / Limo / Executive car      1\n",
       "E scooter share                                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70042bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_airport_accessmode_label_map = {\n",
    "    'Walk': 'Walk',\n",
    "    'Wheelchair or other mobility device': 'Wheelchair or other mobility device',\n",
    "    'ELECTRIC BIKESHARE': 'Bicycle: electric bikeshare',\n",
    "    'NON ELECTRIC BIKESHARE': 'Bicycle: non-electric bikeshare',\n",
    "    'E SCOOTER SHARE': 'E-scooter: shared',\n",
    "    'PERSONAL ELECTRIC BICYCLE': 'Bicycle: personal electric bicycle',\n",
    "    'PERSONAL NON ELECTRIC BICYCLE': 'Bicycle: personal non-electric bicycle',\n",
    "    'PERSONAL E SCOOTER': 'E-scooter: personal',\n",
    "    'Taxi': 'Taxi',\n",
    "    'UBER LYFT': 'Uber/Lyft',\n",
    "    'CAR SERVICE BLACK CAR LIMO EXECUTIVE CAR': 'Car service/black car/limo/executive car',\n",
    "    'DROPPED OFF BY CAR BY FRIEND FAMILY': 'Dropped off by car by family/friend',\n",
    "    'Drove alone and parked': 'Drove alone and parked',\n",
    "    'Drove with others and parked': 'Drove with others and parked',\n",
    "    'RODE WITH OTHER TRAVELER AND PARKED': 'Rode with other traveler(s) and parked',\n",
    "    'Other public transit': 'Other public transit',\n",
    "    'Chartered tour bus': 'Chartered tour bus',\n",
    "    'Employee shuttle': 'Employee shuttle',\n",
    "    'RENTAL CAR AND DROPPED IT OFF AT RENTAL AGENCY': 'Rental car: Dropped off at rental agency',\n",
    "    'RENTAL CAR AND PARKED IT': 'Rental car: parked rental car',\n",
    "    'Hotel shuttle van': 'Hotel shuttle van',\n",
    "    'OTHER SHARED RIDE VAN SERVICE': 'Other shared van (please specify)',\n",
    "    'Other': 'Other',\n",
    "    'Refused/No Answer': 'Refused/No Answer'\n",
    "}\n",
    "clean_df['other_airport_accessmode_label'] = clean_df['other_airport_accessmode_label'].map(other_airport_accessmode_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb3b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "other_airport_accessmode_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "432a1a42-4616-4b9d-8c9d-b63559c1c060",
       "rows": [
        [
         "Dropped off by car by family/friend",
         "242"
        ],
        [
         "Uber/Lyft",
         "107"
        ],
        [
         "Rental car: Dropped off at rental agency",
         "22"
        ],
        [
         "Rental car: parked rental car",
         "11"
        ],
        [
         "Car service/black car/limo/executive car",
         "4"
        ],
        [
         "Rode with other traveler(s) and parked",
         "2"
        ],
        [
         "Drove alone and parked",
         "2"
        ],
        [
         "Bicycle: non-electric bikeshare",
         "2"
        ],
        [
         "Bicycle: personal non-electric bicycle",
         "1"
        ],
        [
         "Other shared van (please specify)",
         "1"
        ],
        [
         "Bicycle: electric bikeshare",
         "1"
        ],
        [
         "Taxi",
         "1"
        ],
        [
         "Walk",
         "1"
        ],
        [
         "Other",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 14
       }
      },
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Drove alone and parked                        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Taxi                                          1\n",
       "Walk                                          1\n",
       "Other                                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b71668ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# respondent gave main mode in error\n",
    "    # 'DROVE_WITH_OTHERS_AND_PARKED' specified that they were actually dropped off in col \"parking_location_other\"\n",
    "\n",
    "## to verify, run:\n",
    "# clean_df.loc[clean_df['respondentid']==8353, ['main_mode_label','parking_cost_frequency_other']]\n",
    "\n",
    "# update mode info based on 'parking_cost_frequency_other' response\n",
    "clean_df.loc[clean_df['respondentid']==8353,'main_mode'] = 12.0\n",
    "clean_df.loc[clean_df['respondentid']==8353,'main_mode_label'] = 'Dropped off by car by family/friend'\n",
    "# make parking information null\n",
    "clean_df.loc[\n",
    "    clean_df['respondentid']==8353,\n",
    "    ['parking_location','parking_location_label', 'parking_location_other','parking_cost','parking_cost_frequency_label']#,'parking_cost_frequency_other']\n",
    "    ] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05df29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_dict = {\n",
    "    'Walk': 1,\n",
    "    'Wheelchair or other mobility device': 2,\n",
    "    'Bicycle: electric bikeshare': 3,\n",
    "    'Bicycle: non-electric bikeshare': 4,\n",
    "    'E-scooter: shared': 5,\n",
    "    'Bicycle: personal electric bicycle': 6,\n",
    "    'Bicycle: personal non-electric bicycle': 7,\n",
    "    'E-scooter: personal': 8,\n",
    "    'Taxi': 9,\n",
    "    'Uber/Lyft': 10,\n",
    "    'Car service/black car/limo/executive car': 11,\n",
    "    'Dropped off by car by family/friend': 12,\n",
    "    'Drove alone and parked': 13,\n",
    "    'Drove with others and parked': 14,\n",
    "    'MTS Route 992': 15,\n",
    "    'Airport flyer shuttle': 16,\n",
    "    'Chartered tour bus': 17,\n",
    "    'Employee shuttle': 18,\n",
    "    'Rental car: Dropped off at rental agency': 19,\n",
    "    'Rental car: parked rental car': 20,\n",
    "    'Hotel shuttle van': 21,\n",
    "    'Other shared van (please specify)': 22,\n",
    "    'Picked up by car by family/friend': 23,\n",
    "    'Get in a parked vehicle and drive alone': 24,\n",
    "    'Get in a parked vehicle and drive with others': 25,\n",
    "    'Get in a parked vehicle and ride with other traveler(s)': 26,\n",
    "    'Rental car: Picked up at rental agency': 27,\n",
    "    'Rental car: get in a parked rental car': 28,\n",
    "    'Rode with other traveler(s) and parked': 29,\n",
    "    'Other public transit': 30,\n",
    "    'Public Transit': 30,\n",
    "    'Other': 98,\n",
    "    'Refused/No Answer': 99,\n",
    "    'None of the above': 98\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modes to fix\n",
    "mode_code_columns = ['main_transit_mode', 'main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "mode_label_columns = ['main_transit_mode_label', 'main_mode_label', 'access_mode_label', 'egress_mode_label', 'reverse_mode_label', 'reverse_mode_predicted_label', 'other_airport_accessmode_label', 'reverse_commute_mode_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5cf0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping codes using label strings\n",
    "travel_mode_dict = {k.lower(): v for k, v in travel_mode_dict.items()}\n",
    "for mode_code_col, mode_label_col in zip(mode_code_columns, mode_label_columns):\n",
    "    # Apply the mapping for each pair of columns\n",
    "    clean_df[mode_code_col] = clean_df[mode_label_col].str.lower().map(travel_mode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d33510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "other_airport_accessmode_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e9524beb-728d-4bab-bf0b-c27d00756200",
       "rows": [
        [
         "Dropped off by car by family/friend",
         "242"
        ],
        [
         "Uber/Lyft",
         "107"
        ],
        [
         "Rental car: Dropped off at rental agency",
         "22"
        ],
        [
         "Rental car: parked rental car",
         "11"
        ],
        [
         "Car service/black car/limo/executive car",
         "4"
        ],
        [
         "Rode with other traveler(s) and parked",
         "2"
        ],
        [
         "Drove alone and parked",
         "2"
        ],
        [
         "Bicycle: non-electric bikeshare",
         "2"
        ],
        [
         "Bicycle: personal non-electric bicycle",
         "1"
        ],
        [
         "Other shared van (please specify)",
         "1"
        ],
        [
         "Bicycle: electric bikeshare",
         "1"
        ],
        [
         "Taxi",
         "1"
        ],
        [
         "Walk",
         "1"
        ],
        [
         "Other",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 14
       }
      },
      "text/plain": [
       "other_airport_accessmode_label\n",
       "Dropped off by car by family/friend         242\n",
       "Uber/Lyft                                   107\n",
       "Rental car: Dropped off at rental agency     22\n",
       "Rental car: parked rental car                11\n",
       "Car service/black car/limo/executive car      4\n",
       "Rode with other traveler(s) and parked        2\n",
       "Drove alone and parked                        2\n",
       "Bicycle: non-electric bikeshare               2\n",
       "Bicycle: personal non-electric bicycle        1\n",
       "Other shared van (please specify)             1\n",
       "Bicycle: electric bikeshare                   1\n",
       "Taxi                                          1\n",
       "Walk                                          1\n",
       "Other                                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2195ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "other_airport_accessmode",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b9dbc469-f147-42d6-ab5d-371d2904d5ce",
       "rows": [
        [
         "12.0",
         "242"
        ],
        [
         "10.0",
         "107"
        ],
        [
         "19.0",
         "22"
        ],
        [
         "20.0",
         "11"
        ],
        [
         "11.0",
         "4"
        ],
        [
         "29.0",
         "2"
        ],
        [
         "13.0",
         "2"
        ],
        [
         "4.0",
         "2"
        ],
        [
         "7.0",
         "1"
        ],
        [
         "22.0",
         "1"
        ],
        [
         "3.0",
         "1"
        ],
        [
         "9.0",
         "1"
        ],
        [
         "1.0",
         "1"
        ],
        [
         "98.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 14
       }
      },
      "text/plain": [
       "other_airport_accessmode\n",
       "12.0    242\n",
       "10.0    107\n",
       "19.0     22\n",
       "20.0     11\n",
       "11.0      4\n",
       "29.0      2\n",
       "13.0      2\n",
       "4.0       2\n",
       "7.0       1\n",
       "22.0      1\n",
       "3.0       1\n",
       "9.0       1\n",
       "1.0       1\n",
       "98.0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['other_airport_accessmode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b31b5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "main_transit_mode",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9ad642b6-a0f4-4fb3-9318-3ed8322605f1",
       "rows": [
        [
         "98.0",
         "4919"
        ],
        [
         "16.0",
         "249"
        ],
        [
         "15.0",
         "209"
        ],
        [
         "99.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "main_transit_mode\n",
       "98.0    4919\n",
       "16.0     249\n",
       "15.0     209\n",
       "99.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['main_transit_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfbb23",
   "metadata": {},
   "source": [
    "### Pre-processing of some fields\n",
    "\n",
    "This section aims at converting a few more inconsistent values to be consistent with the enums defined as the part of the data model.\n",
    "For instance, it converts String codes to Integers, to keep the code-label format standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1ce82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1442525754.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  clean_df.replace('-oth-', 98, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "clean_df['date_completed'] = pd.to_datetime(clean_df['date_completed'])\n",
    "clean_df['is_pilot'] = np.where(clean_df['date_completed'].dt.date<=datetime.date(2024, 10, 3), 1, 0)\n",
    "clean_df['record_type_synthetic'] = 0\n",
    "clean_df.replace('-oth-', 98, inplace=True)\n",
    "clean_df.replace('-', None, inplace = True )\n",
    "clean_df['is_income_below_poverty'] = np.where(clean_df['is_income_below_poverty'] == 0, 2, clean_df['is_income_below_poverty'])\n",
    "clean_df['household_income'] = np.where(clean_df['household_income']=='13B', 17, clean_df['household_income'] )\n",
    "\n",
    "clean_df['stay_informed'] = np.where(clean_df['stay_informed'] == 0, 2, clean_df['stay_informed'])\n",
    "#Maps\n",
    "interview_location_map = {'Term1' : 1, 'Term2': 2, 'MTS_1_992': 3, 'SDA_1_FLYER': 4, 'ConracShuttle': 5, 'ParkingShuttle': 6, 'EmplParking': 7, '-oth-':98}\n",
    "inbound_outbound_map = {'IN':1, 'OUT':2}\n",
    "\n",
    "#route_fields:\n",
    "route_fields = ['to_airport_transit_route_1', 'to_airport_transit_route_2', 'to_airport_transit_route_3', 'to_airport_transit_route_4',\n",
    "                'from_airport_transit_route_1', 'from_airport_transit_route_2', 'from_airport_transit_route_3', 'from_airport_transit_route_4']\n",
    "\n",
    "#Replacement\n",
    "clean_df['interview_location'] = clean_df['interview_location'].map(interview_location_map)\n",
    "clean_df['inbound_or_outbound'] = clean_df['inbound_or_outbound'].map(inbound_outbound_map)\n",
    "clean_df['main_mode'] = np.where(clean_df['main_transit_mode'].isin([15,16]), clean_df['main_transit_mode'], clean_df['main_mode'])\n",
    "\n",
    "clean_df[route_fields] = clean_df[route_fields].replace(98, 'OTHER')\n",
    "clean_df['nights_visited'] = clean_df['nights_visited'] - 1\n",
    "\n",
    "clean_df['same_commute_mode'] = np.where(clean_df['same_commute_mode'] == 0, 2, clean_df['same_commute_mode'])\n",
    "clean_df['resident_visitor_followup'] = np.where(clean_df['resident_visitor_followup'] == 0, 2, clean_df['resident_visitor_followup'])\n",
    "\n",
    "#activity_type\n",
    "clean_df['origin_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.OUTBOUND_FROM_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['origin_activity_type'])\n",
    "clean_df['destination_activity_type'] = np.where(clean_df['inbound_or_outbound'] == e.InboundOutbound.INBOUND_TO_AIRPORT, e.ActivityType.SAN_DIEGO_AIRPORT, clean_df['destination_activity_type'])\n",
    "\n",
    "#For incomplete records:\n",
    "clean_df['marketsegment'] = clean_df['marketsegment'].fillna(99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f315a",
   "metadata": {},
   "source": [
    "### Fix main_mode to not take EMPLOYEE_SHUTTLE\n",
    "\n",
    "EMPLOYEE_SHUTTLE has been disqualified as being a main_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "815c14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['main_mode'] = np.where(\n",
    "    clean_df['main_mode'] == e.TravelMode.EMPLOYEE_SHUTTLE,\n",
    "    np.where(\n",
    "        clean_df['marketsegment'] == e.Type.PASSENGER,\n",
    "        e.TravelMode.OTHER,\n",
    "        np.where(\n",
    "            clean_df['marketsegment'] == e.Type.EMPLOYEE,\n",
    "            clean_df['reverse_commute_mode'],\n",
    "            clean_df['main_mode']  # fallback if neither condition is met\n",
    "        )\n",
    "    ),\n",
    "    clean_df['main_mode']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ba9f2",
   "metadata": {},
   "source": [
    "### Re-assign some main_mode_others to main_mode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b1c8d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('marketsegment_label', 'main_mode_other')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "63460944-2f49-431e-9492-675efb77f759",
       "rows": [
        [
         "('Air passenger', 'Hospital shuttle')",
         "2"
        ],
        [
         "('Air passenger', 'Medical shuttle')",
         "2"
        ],
        [
         "('Air passenger', 'Refugee shuttle')",
         "2"
        ],
        [
         "('Employee working at the airport', 'Motorcycle')",
         "2"
        ],
        [
         "('Air passenger', 'Bus')",
         "1"
        ],
        [
         "('Air passenger', 'Connecting flights')",
         "1"
        ],
        [
         "('Air passenger', 'Airplane')",
         "1"
        ],
        [
         "('Air passenger', 'Medical')",
         "1"
        ],
        [
         "('Air passenger', 'Flew in')",
         "1"
        ],
        [
         "('Air passenger', 'Personal car')",
         "1"
        ],
        [
         "('Air passenger', 'Paratransit')",
         "1"
        ],
        [
         "('Air passenger', 'Shelter')",
         "1"
        ],
        [
         "('Air passenger', 'Stayed with family near airport and they drove me')",
         "1"
        ],
        [
         "('Air passenger', 'Team bus')",
         "1"
        ],
        [
         "('Air passenger', 'Personal shuttle')",
         "1"
        ],
        [
         "('Air passenger', 'Turo')",
         "1"
        ],
        [
         "('Air passenger', 'Work')",
         "1"
        ],
        [
         "('Airport employee (including airline employees)', 'Flight')",
         "1"
        ],
        [
         "('Airport employee (including airline employees)', 'Flew')",
         "1"
        ],
        [
         "('Airport employee (including airline employees)', 'Mts blue line')",
         "1"
        ],
        [
         "('Airport employee (including airline employees)', 'Route 10 and then Employee Shuttle')",
         "1"
        ],
        [
         "('Employee working at the airport', 'Telecommute Day but on a working day I use the hours below')",
         "1"
        ],
        [
         "('Employee working at the airport', 'Work from home today')",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "marketsegment_label                             main_mode_other                                           \n",
       "Air passenger                                   Hospital shuttle                                              2\n",
       "                                                Medical shuttle                                               2\n",
       "                                                Refugee shuttle                                               2\n",
       "Employee working at the airport                 Motorcycle                                                    2\n",
       "Air passenger                                   Bus                                                           1\n",
       "                                                Connecting flights                                            1\n",
       "                                                Airplane                                                      1\n",
       "                                                Medical                                                       1\n",
       "                                                Flew in                                                       1\n",
       "                                                Personal car                                                  1\n",
       "                                                Paratransit                                                   1\n",
       "                                                Shelter                                                       1\n",
       "                                                Stayed with family near airport and they drove me             1\n",
       "                                                Team bus                                                      1\n",
       "                                                Personal shuttle                                              1\n",
       "                                                Turo                                                          1\n",
       "                                                Work                                                          1\n",
       "Airport employee (including airline employees)  Flight                                                        1\n",
       "                                                Flew                                                          1\n",
       "                                                Mts blue line                                                 1\n",
       "                                                Route 10 and then Employee Shuttle                            1\n",
       "Employee working at the airport                 Telecommute Day but on a working day I use the hours below    1\n",
       "                                                Work from home today                                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[['marketsegment_label', 'main_mode_other']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d1d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes which are invalid, should make main_mode blank, and hence throw a critical validation error\n",
    "# Some of the modes can stay as they are (i.e., OTHER) - Like, Refugee Shuttle, Hospital Shuttle, Medical Shuttle.\n",
    "# Others can be classified - for example\n",
    "# Mapping for reclassification\n",
    "mode_mapping = {\n",
    "    \"Hospital shuttle\": e.TravelMode.OTHER,\n",
    "    \"Medical shuttle\": e.TravelMode.OTHER,\n",
    "    \"Refugee shuttle\": e.TravelMode.OTHER,\n",
    "    \"Motorcycle\": e.TravelMode.OTHER,\n",
    "    \"Bus\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Connecting flights\": None,\n",
    "    \"Airplane\": None,\n",
    "    \"Flew in\": None,\n",
    "    \"Medical\": e.TravelMode.OTHER,\n",
    "    \"Personal car\": e.TravelMode.DROVE_ALONE_AND_PARKED,\n",
    "    \"Paratransit\": e.TravelMode.OTHER,\n",
    "    \"Shelter\": None,\n",
    "    \"Stayed with family near airport and they drove me\": e.TravelMode.DROPPED_OFF_BY_FAMILY_FRIEND,\n",
    "    \"Team bus\": e.TravelMode.CHARTERED_TOUR_BUS,\n",
    "    \"Personal shuttle\": e.TravelMode.OTHER_SHARED_VAN,\n",
    "    \"Turo\": e.TravelMode.RENTAL_CAR_PICKED_UP,\n",
    "    \"Work\": None,\n",
    "    \"Flight\": None,\n",
    "    \"Flew\": None,\n",
    "    \"Mts blue line\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Route 10 and then Employee Shuttle\": e.TravelMode.OTHER_PUBLIC_TRANSIT,\n",
    "    \"Telecommute Day but on a working day I use the hours below\": None,\n",
    "    \"Work from home today\": None\n",
    "}\n",
    "\n",
    "# Create a mapped column without modifying main_mode yet\n",
    "# Create a mapped column\n",
    "mapped_modes = clean_df[\"main_mode_other\"].map(mode_mapping)\n",
    "\n",
    "# Update main_mode where main_mode_other exists in mode_mapping (including None values)\n",
    "clean_df.loc[clean_df[\"main_mode_other\"].isin(mode_mapping.keys()), \"main_mode\"] = mapped_modes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "766defc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "main_mode_other",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9200cd6b-60ee-4fc0-893f-d6092a2c6dbb",
       "rows": [
        [
         "0",
         null
        ],
        [
         "1",
         null
        ],
        [
         "2",
         null
        ],
        [
         "3",
         null
        ],
        [
         "4",
         null
        ],
        [
         "5",
         null
        ],
        [
         "6",
         null
        ],
        [
         "7",
         null
        ],
        [
         "8",
         null
        ],
        [
         "9",
         null
        ],
        [
         "10",
         null
        ],
        [
         "11",
         null
        ],
        [
         "12",
         null
        ],
        [
         "13",
         null
        ],
        [
         "14",
         null
        ],
        [
         "15",
         null
        ],
        [
         "16",
         null
        ],
        [
         "17",
         null
        ],
        [
         "18",
         null
        ],
        [
         "19",
         null
        ],
        [
         "20",
         null
        ],
        [
         "21",
         null
        ],
        [
         "22",
         null
        ],
        [
         "23",
         null
        ],
        [
         "24",
         null
        ],
        [
         "25",
         null
        ],
        [
         "26",
         null
        ],
        [
         "27",
         null
        ],
        [
         "28",
         null
        ],
        [
         "29",
         null
        ],
        [
         "30",
         null
        ],
        [
         "31",
         null
        ],
        [
         "32",
         null
        ],
        [
         "33",
         null
        ],
        [
         "34",
         null
        ],
        [
         "35",
         null
        ],
        [
         "36",
         null
        ],
        [
         "37",
         null
        ],
        [
         "38",
         null
        ],
        [
         "39",
         null
        ],
        [
         "40",
         null
        ],
        [
         "41",
         null
        ],
        [
         "42",
         null
        ],
        [
         "43",
         null
        ],
        [
         "44",
         null
        ],
        [
         "45",
         null
        ],
        [
         "46",
         null
        ],
        [
         "47",
         null
        ],
        [
         "48",
         null
        ],
        [
         "49",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5711
       }
      },
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "        ..\n",
       "5706   NaN\n",
       "5707   NaN\n",
       "5708   NaN\n",
       "5709   NaN\n",
       "5710   NaN\n",
       "Name: main_mode_other, Length: 5711, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdda2d",
   "metadata": {},
   "source": [
    "### Create Grouped Modes\n",
    "This section creates grouped modes for better readability and analysis. Particularly, it makes modes direction-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773afd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_mode_to_grouped = {\n",
    "    e.TravelMode.WALK: e.TravelModeGrouped.WALK,\n",
    "    e.TravelMode.WHEELCHAIR_OR_MOBILITY_DEVICE: e.TravelModeGrouped.WHEELCHAIR_OR_OTHER_MOBILITY_DEVICE,\n",
    "    e.TravelMode.BICYCLE_ELECTRIC_BIKESHARE: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.BICYCLE_NON_ELECTRIC_BIKESHARE: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.BICYCLE_PERSONAL_ELECTRIC: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.BICYCLE_PERSONAL_NON_ELECTRIC: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.E_SCOOTER_SHARED: e.TravelModeGrouped.MICROMOBILITY_SHARED,\n",
    "    e.TravelMode.E_SCOOTER_PERSONAL: e.TravelModeGrouped.MICROMOBILITY_PERSONAL,\n",
    "    e.TravelMode.TAXI: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.UBER_LYFT: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.CAR_SERVICE_BLACK_LIMO: e.TravelModeGrouped.RIDEHAIL_TAXI,\n",
    "    e.TravelMode.MTS_ROUTE_992: e.TravelModeGrouped.BUS_992,\n",
    "    e.TravelMode.AIRPORT_FLYER_SHUTTLE: e.TravelModeGrouped.AIRPORT_FLYER_SHUTTLE,\n",
    "    e.TravelMode.OTHER_PUBLIC_TRANSIT: e.TravelModeGrouped.PUBLIC_TRANSPORTATION,\n",
    "    e.TravelMode.DROPPED_OFF_BY_FAMILY_FRIEND: e.TravelModeGrouped.PERSONAL_CAR_DROPPED_OFF_PICKED_UP,\n",
    "    e.TravelMode.PICKED_UP_BY_FAMILY_FRIEND: e.TravelModeGrouped.PERSONAL_CAR_DROPPED_OFF_PICKED_UP,\n",
    "    e.TravelMode.DROVE_ALONE_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.DROVE_WITH_OTHERS_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.RODE_WITH_OTHER_TRAVELERS_AND_PARKED: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_DRIVE_ALONE: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_DRIVE_WITH_OTHERS: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.GET_IN_PARKED_VEHICLE_AND_RIDE_WITH_OTHER_TRAVELERS: e.TravelModeGrouped.PERSONAL_CAR_PARKED,\n",
    "    e.TravelMode.RENTAL_CAR_DROPPED_OFF: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_PARKED: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_PICKED_UP: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.RENTAL_CAR_GET_IN_PARKED: e.TravelModeGrouped.RENTAL_CAR,\n",
    "    e.TravelMode.HOTEL_SHUTTLE_VAN: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.EMPLOYEE_SHUTTLE: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.OTHER_SHARED_VAN: e.TravelModeGrouped.SHARED_SHUTTLE_VAN,\n",
    "    e.TravelMode.CHARTERED_TOUR_BUS: e.TravelModeGrouped.OTHER,\n",
    "    e.TravelMode.OTHER: e.TravelModeGrouped.OTHER,\n",
    "    e.TravelMode.REFUSED_NO_ANSWER: e.TravelModeGrouped.REFUSED_NO_ANSWER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20809722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping Done for main_mode\n",
      "Remapping Done for access_mode\n",
      "Remapping Done for egress_mode\n",
      "Remapping Done for reverse_mode\n",
      "Remapping Done for reverse_mode_predicted\n",
      "Remapping Done for other_airport_accessmode\n",
      "Remapping Done for reverse_commute_mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2441277645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n"
     ]
    }
   ],
   "source": [
    "mode_columns_to_remap = ['main_mode', 'access_mode', 'egress_mode', 'reverse_mode', 'reverse_mode_predicted', 'other_airport_accessmode', 'reverse_commute_mode']\n",
    "for col in mode_columns_to_remap:\n",
    "    clean_df[f'{col}_grouped'] = clean_df[col].map(travel_mode_to_grouped)\n",
    "    print(f\"Remapping Done for {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe693541",
   "metadata": {},
   "source": [
    "### Consolidating multiple columns into one string column:\n",
    "A few columns can be merged into one single list, instead of being represented as a long list of columns. This is done to deliver a cleaner dataset with fewer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab605f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"general_modes_used_visitor_list\"] = clean_df[general_modes_used_visitor_mode_columns].apply(lambda row:\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"alt_commute_mode_list\"] = clean_df[alt_commute_mode_columns].apply(lambda row:\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"sdia_accessmode_split_list\"] = clean_df[sdia_accessmode_split_columns].apply(lambda row:\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"race_list\"] = clean_df[race_columns].apply(lambda row:\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"reasons_no_transit_list\"] = clean_df[reasons_no_transit_columns].apply(lambda row:\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1679023918.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['party_composition_list'] = clean_df[party_composition_columns].apply(lambda row:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "general_modes_used_visitor_mode_columns = [col for col in clean_df.columns if col.startswith(\"general_modes_used_visitor\")]\n",
    "alt_commute_mode_columns = [col for col in clean_df.columns if col.startswith(\"alt_commute_mode\")]\n",
    "sdia_accessmode_split_columns = [col for col in clean_df.columns if col.startswith(\"sdia_accessmode_split_\")]\n",
    "race_columns = [col for col in clean_df.columns if col.startswith(\"race_\")]\n",
    "reasons_no_transit_columns = [col for col in clean_df.columns if col.startswith(\"reasons_no_transit_\")]\n",
    "party_composition_columns = [col for col in clean_df.columns if col.startswith(\"party_includes_\")]\n",
    "\n",
    "\n",
    "# Create a new column with a comma-separated list of active modes\n",
    "clean_df[\"general_modes_used_visitor_list\"] = clean_df[general_modes_used_visitor_mode_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"general_modes_used_visitor_\", \"\").replace(\"_\", \" \") for col in general_modes_used_visitor_mode_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"alt_commute_mode_list\"] = clean_df[alt_commute_mode_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"alt_commute_mode_\", \"\").replace(\"_\", \" \") for col in alt_commute_mode_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"sdia_accessmode_split_list\"] = clean_df[sdia_accessmode_split_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"sdia_accessmode_split_\", \"\").replace(\"_\", \" \") for col in sdia_accessmode_split_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"race_list\"] = clean_df[race_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"race_\", \"\").replace(\"_\", \" \") for col in race_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df[\"reasons_no_transit_list\"] = clean_df[reasons_no_transit_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"reasons_no_transit_\", \"\").replace(\"_\", \" \") for col in reasons_no_transit_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "clean_df['party_composition_list'] = clean_df[party_composition_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"party_includes_\", \"\").replace(\"_\", \" \") for col in party_composition_columns if row[col]=='Yes']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef6cfb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1507753342.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"transit_routes_list\"] = clean_df[valid_transit_columns].apply(\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1507753342.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"num_transit_transfers\"] = clean_df[\"transit_routes_list\"].apply(lambda x: max(len(x.split(\", \")) - 1, 0) if x else 0)\n"
     ]
    }
   ],
   "source": [
    "ordered_transit_columns = [\n",
    "    \"from_airport_transit_route_1\", \"from_airport_transit_route_1_other\",\n",
    "    \"from_airport_transit_route_2\", \"from_airport_transit_route_2_other\",\n",
    "    \"from_airport_transit_route_3\", \"from_airport_transit_route_3_other\",\n",
    "    \"from_airport_transit_route_4\", \"from_airport_transit_route_4_other\",\n",
    "    \"to_airport_transit_route_1\", \"to_airport_transit_route_1_other\",\n",
    "    \"to_airport_transit_route_2\", \"to_airport_transit_route_2_other\",\n",
    "    \"to_airport_transit_route_3\", \"to_airport_transit_route_3_other\",\n",
    "    \"to_airport_transit_route_4\", \"to_airport_transit_route_4_other\"\n",
    "]\n",
    "\n",
    "# Ensure only valid columns (those that exist in the DataFrame)\n",
    "valid_transit_columns = [col for col in ordered_transit_columns if col in clean_df.columns]\n",
    "\n",
    "# Concatenate only non-null values while maintaining the correct order\n",
    "clean_df[\"transit_routes_list\"] = clean_df[valid_transit_columns].apply(\n",
    "    lambda row: \", \".join(row.dropna().astype(str)), axis=1\n",
    ")\n",
    "\n",
    "# Compute the number of transfers (number of routes - 1), ensuring no negative values\n",
    "clean_df[\"num_transit_transfers\"] = clean_df[\"transit_routes_list\"].apply(lambda x: max(len(x.split(\", \")) - 1, 0) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8224cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2428646809.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"sp_other_airport_list\"] = clean_df[sp_other_airport_columns].apply(lambda row:\n"
     ]
    }
   ],
   "source": [
    "##Merge SP Survey fields:\n",
    "sp_other_airport_columns = [col for col in clean_df.columns if col.startswith(\"sp_other_airport_\")]\n",
    "\n",
    "\n",
    "# Create a new column with a comma-separated list of active modes\n",
    "clean_df[\"sp_other_airport_list\"] = clean_df[sp_other_airport_columns].apply(lambda row:\n",
    "    \", \".join([col.replace(\"sp_other_airport_\", \"\").replace(\"_\", \" \") for col in sp_other_airport_columns if row[col]==1]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b216f",
   "metadata": {},
   "source": [
    "### Add Passenger Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d7e6bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\1011052984.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"passenger_segment\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "# Add the `passenger_segment` column based on the updated logic\n",
    "clean_df[\"passenger_segment\"] = np.where(\n",
    "    # Resident Arriving\n",
    "    (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING) &\n",
    "    ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.COMING_HOME) |\n",
    "     (clean_df[\"resident_visitor_followup\"] == e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT)),\n",
    "    e.PassengerSegment.RESIDENT_ARRIVING,  # Resident Arriving\n",
    "    np.where(\n",
    "        (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING),\n",
    "        e.PassengerSegment.VISITOR_ARRIVING,  # Visitor Arriving\n",
    "        np.where(\n",
    "            (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING) &\n",
    "            ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.LEAVING_HOME) |\n",
    "             (clean_df[\"resident_visitor_followup\"] == e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT)),\n",
    "            e.PassengerSegment.RESIDENT_DEPARTING,  # Resident Departing\n",
    "            np.where(\n",
    "                # Visitor Departing\n",
    "                (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING),\n",
    "                e.PassengerSegment.VISITOR_DEPARTING,  # Visitor Departing\n",
    "                None  # Default case (if no conditions match)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10107bfb",
   "metadata": {},
   "source": [
    "### Add combined resident visitor status and flight purpose:\n",
    "\n",
    "Also adds EMPLOYEE as a segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b875c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\524262598.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"resident_visitor_purpose\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "clean_df[\"resident_visitor_purpose\"] = np.where(\n",
    "    # Resident Business\n",
    "    (clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING])) &\n",
    "    (clean_df[\"flight_purpose\"].isin([e.FlightPurpose.BUSINESS_WORK, e.FlightPurpose.COMBINATION_BUSINESS_LEISURE])),\n",
    "    e.ResidentVisitorPurpose.RESIDENT_BUSINESS,\n",
    "\n",
    "    np.where(\n",
    "        # Resident Non-Business\n",
    "        clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING]),\n",
    "        e.ResidentVisitorPurpose.RESIDENT_NON_BUSINESS,\n",
    "\n",
    "        np.where(\n",
    "            # Visitor Business\n",
    "            (clean_df[\"flight_purpose\"].isin([e.FlightPurpose.BUSINESS_WORK, e.FlightPurpose.COMBINATION_BUSINESS_LEISURE])),\n",
    "            e.ResidentVisitorPurpose.VISITOR_BUSINESS,\n",
    "\n",
    "            # Visitor Non-Business (default case)\n",
    "            e.ResidentVisitorPurpose.VISITOR_NON_BUSINESS\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dfa9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2550702533.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"qualified_visitor\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "## Explicit Visitor Check\n",
    "clean_df[\"qualified_visitor\"] = np.where(\n",
    "    # Arriving and visiting or neither, and does not live in the same region traveled\n",
    "    (clean_df[\"passenger_type\"] == e.PassengerType.ARRIVING) &\n",
    "    ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.VISITING) |\n",
    "     (clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.NEITHER)) &\n",
    "    (clean_df[\"resident_visitor_followup\"] != e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT),\n",
    "    1,  # Qualified visitor\n",
    "    np.where(\n",
    "        # Departing and going home or neither, and does not live in the same region traveled\n",
    "        (clean_df[\"passenger_type\"] == e.PassengerType.DEPARTING) &\n",
    "        ((clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.GOING_HOME) |\n",
    "         (clean_df[\"resident_visitor_general\"] == e.ResidentVisitorGeneral.NEITHER)) &\n",
    "        (clean_df[\"resident_visitor_followup\"] != e.ResidentVisitorFollowup.LIVE_OUTSIDE_REGION_TRAVELED_TO_AIRPORT),\n",
    "        1,  # Qualified visitor\n",
    "        0  # Not a qualified visitor\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd18340",
   "metadata": {},
   "source": [
    "### Add some new consolidated variables, Combine some variables to exclude directionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8194a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2665429719.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['number_of_nights'] = clean_df['nights_away'].fillna(clean_df['nights_visited'])\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2665429719.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df[\"is_sdia_home_airport\"] = np.where(\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2665429719.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['reverse_mode_combined'] = clean_df['reverse_mode_grouped'].combine_first(clean_df['reverse_mode_predicted_grouped'])\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2665429719.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['reverse_mode_combined_other'] = clean_df['reverse_mode_predicted_other']\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\2665429719.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['party_size_flight'] = clean_df['number_of_travel_companions'].fillna(0) + 1\n"
     ]
    }
   ],
   "source": [
    "## New changes:\n",
    "clean_df['number_of_nights'] = clean_df['nights_away'].fillna(clean_df['nights_visited'])\n",
    "\n",
    "# Set is_sdia_home_airport to 1 for resident arriving or departing passengers\n",
    "clean_df[\"is_sdia_home_airport\"] = np.where(\n",
    "    clean_df[\"passenger_segment\"].isin([e.PassengerSegment.RESIDENT_ARRIVING, e.PassengerSegment.RESIDENT_DEPARTING]),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "### Combining reverse_mode, as reverse_mode_combined -\n",
    "clean_df['reverse_mode_combined'] = clean_df['reverse_mode_grouped'].combine_first(clean_df['reverse_mode_predicted_grouped'])\n",
    "clean_df['reverse_mode_combined_other'] = clean_df['reverse_mode_predicted_other']\n",
    "\n",
    "clean_df['party_size_flight'] = clean_df['number_of_travel_companions'].fillna(0) + 1\n",
    "\n",
    "# ## party size\n",
    "# clean_df[\"party_size_ground_access\"] = np.where(\n",
    "#     clean_df[\"party_size_ground_access_same\"] == \"Yes\",\n",
    "#     clean_df[\"party_size_flight\"],\n",
    "#     clean_df[\"party_size_ground_access\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a90f77",
   "metadata": {},
   "source": [
    "Remove origin, destination coordinates, when the location does not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c95c71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For origin columns: if origin_state not in ['CA', 'BC'] OR origin_place_name is not 'Yuma'\n",
    "mask_origin = ((clean_df['origin_state'].isin(['CA', 'BC'])) | (clean_df['origin_place_name'] == 'Yuma'))\n",
    "clean_df.loc[~mask_origin, ['origin_latitude', 'origin_longitude']] = np.nan\n",
    "\n",
    "# For destination columns: if destination_state not in ['CA', 'BC'] OR destination_place_name is not 'Yuma'\n",
    "mask_destination = ((clean_df['destination_state'].isin(['CA', 'BC'])) | (clean_df['destination_place_name'] == 'Yuma'))\n",
    "clean_df.loc[~mask_destination, ['destination_latitude', 'destination_longitude']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d42d85",
   "metadata": {},
   "source": [
    "### Populate Home Location fields when it is not explicitly asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01ab7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\962731990.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'origin_municipal_zone']\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\962731990.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'origin_pmsa']\n"
     ]
    }
   ],
   "source": [
    "# Create masks for home activity types\n",
    "mask_origin_home = clean_df['origin_activity_type'] == e.ActivityType.HOME\n",
    "mask_destination_home = clean_df['destination_activity_type'] == e.ActivityType.HOME\n",
    "\n",
    "# For rows where origin is home, copy the origin fields to home_location_ fields\n",
    "clean_df.loc[mask_origin_home, 'home_location_place_name'] = clean_df.loc[mask_origin_home, 'origin_place_name']\n",
    "clean_df.loc[mask_origin_home, 'home_location_state'] = clean_df.loc[mask_origin_home, 'origin_state']\n",
    "clean_df.loc[mask_origin_home, 'home_location_zip'] = clean_df.loc[mask_origin_home, 'origin_zip']\n",
    "clean_df.loc[mask_origin_home, 'home_location_latitude'] = clean_df.loc[mask_origin_home, 'origin_latitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_longitude'] = clean_df.loc[mask_origin_home, 'origin_longitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'origin_municipal_zone']\n",
    "clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'origin_pmsa']\n",
    "\n",
    "# For rows where destination is home, copy the destination fields to home_location_ fields\n",
    "clean_df.loc[mask_destination_home, 'home_location_place_name'] = clean_df.loc[mask_destination_home, 'destination_place_name']\n",
    "clean_df.loc[mask_destination_home, 'home_location_state'] = clean_df.loc[mask_destination_home, 'destination_state']\n",
    "clean_df.loc[mask_destination_home, 'home_location_zip'] = clean_df.loc[mask_destination_home, 'destination_zip']\n",
    "clean_df.loc[mask_destination_home, 'home_location_latitude'] = clean_df.loc[mask_destination_home, 'destination_latitude']\n",
    "clean_df.loc[mask_destination_home, 'home_location_longitude'] = clean_df.loc[mask_destination_home, 'destination_longitude']\n",
    "clean_df.loc[mask_origin_home, 'home_location_municipal_zone'] = clean_df.loc[mask_origin_home, 'destination_municipal_zone']\n",
    "clean_df.loc[mask_origin_home, 'home_location_pmsa'] = clean_df.loc[mask_origin_home, 'destination_pmsa']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60c2a1",
   "metadata": {},
   "source": [
    "#### Fix transit_boarding and alighting coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6a45327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\3010364468.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_boarding_latitude'] = (\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\3010364468.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_boarding_longitude'] = (\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\3010364468.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_alighting_latitude'] = (\n",
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_72112\\3010364468.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  clean_df['transit_alighting_longitude'] = (\n"
     ]
    }
   ],
   "source": [
    "clean_df['transit_boarding_latitude'] = (\n",
    "    clean_df['transit_board_1_lat']\n",
    "    .combine_first(clean_df['stop_on_latitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_boarding_longitude'] = (\n",
    "    clean_df['transit_board_1_long']\n",
    "    .combine_first(clean_df['stop_on_longitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_alighting_latitude'] = (\n",
    "    clean_df['transit_alight_4_lat']\n",
    "    .combine_first(clean_df['transit_alight_3_lat'])\n",
    "    .combine_first(clean_df['transit_alight_2_lat'])\n",
    "    .combine_first(clean_df['transit_alight_1_lat'])\n",
    "    .combine_first(clean_df['stop_off_latitude'])\n",
    ")\n",
    "\n",
    "clean_df['transit_alighting_longitude'] = (\n",
    "    clean_df['transit_alight_4_long']\n",
    "    .combine_first(clean_df['transit_alight_3_long'])\n",
    "    .combine_first(clean_df['transit_alight_2_long'])\n",
    "    .combine_first(clean_df['transit_alight_1_long'])\n",
    "    .combine_first(clean_df['stop_off_longitude'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037f383",
   "metadata": {},
   "source": [
    "# Write Out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96a5bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(clean_survey_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
