{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Coordinates from Survey Responses to SANDAG Geographies\n",
    "Put coordinates into Series15 geographies, drop coordinates in responses in next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: python notebook version of the script: notebooks\\data_processing\\x05_data_processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found in GitHub repo -\n",
    "# https://github.com/SANDAG/Survey_Airport/blob/192019a7fd2cca1986af9a2e25d287fa9cdd7648/data_model/utils.py#L32\n",
    "survey_crs = \"EPSG:4326\"\n",
    "selected_geography = 'TAZ' #'MGRA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "geography_file = f\"../data/geographies/{selected_geography}15.shp\"\n",
    "# processed_survey_data_path = \"../data/processed/data_model_output.csv\"\n",
    "processed_survey_data_path = \"../data/processed/data_model_output.csv\"\n",
    "base_scenario_path = r\"T:\\STORAGE-63T\\2025RP_draft\\abm_runs_v2\\2022_S0_v2\"\n",
    "\n",
    "# output\n",
    "survey_data_matched_geographies = f'../data/processed/survey_data_matched_geographies_{selected_geography.lower()}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_29924\\3495733368.py:3: DtypeWarning: Columns (1,13,14,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,54,55,59,65,69,74,77,78,80,82,83,86,93,95,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,142,147,150,151,152,155,156,157,167,169,177,179,196,197,198,201,210,211,216,223,237,239,240,241,242,243,244,246,248,249,273,283,284,285,288,291,295,296,297,299,300,335,337,338,340,411,414,435) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(processed_survey_data_path)\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "survey_respondent = (\n",
    "    pd.read_csv(processed_survey_data_path)\n",
    "    # .query('record_type_synthetic == False')\n",
    "    .query(\"validation_severity_person != 'Critical'\")\n",
    "    .query(\"validation_severity_trip != 'Critical'\")\n",
    "    .query(\"weight_departing_only > 0\") #using non-synthetic data leaves synthetic records in data w/ 0 weight\n",
    "    # .query('inbound_or_outbound_label == \"INBOUND_TO_AIRPORT\"')\n",
    ")\n",
    "geographies = gpd.read_file(geography_file).query('~TAZ.isin([3,11])') # remove external TAZs that do not exist\n",
    "# geographies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Coordinates w/ Geographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) for coords in SD counties -> \n",
    "    - match to TAZ\n",
    "    - for coords in ocean nearby, match to closest non-external TAZ\n",
    "        - WHAT LOGIC ? coordinate box?\n",
    "2) for origin coords outside of SD county:\n",
    "    1) if dest coord is inside county, make origin TAZ = AIRPORT\n",
    "    2) if dest coord is also outside county:\n",
    "        - match closest coord to closest external TAZ\n",
    "        - make furthest coord to any external TAZ = AIRPORT\n",
    "3) for remaining dest coords outside of SD county:\n",
    "    - make origin TAZ = AIRPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO update logic documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_survey_geodataframe(survey_df: pd.DataFrame, var_prefix:str)->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    survey_gdf =gpd.GeoDataFrame(\n",
    "                survey_df,\n",
    "                geometry=gpd.points_from_xy(\n",
    "                    survey_df[f\"{var_prefix}_longitude\"],\n",
    "                    survey_df[f\"{var_prefix}_latitude\"]\n",
    "                ),\n",
    "                crs=survey_crs,\n",
    "            )\n",
    "    return survey_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_geographies_df(geography_df:gpd.GeoDataFrame, var_prefix:str)->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geography_df = (\n",
    "            geography_df\n",
    "            [[selected_geography, \"geometry\"]]\n",
    "            .rename(columns={selected_geography:f'{var_prefix}_{selected_geography.lower()}'})\n",
    "        )\n",
    "    return geography_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sjoin_geographies(\n",
    "        survey_df:pd.DataFrame,\n",
    "        geography_df:gpd.GeoDataFrame,\n",
    "        var_prefix:str\n",
    "        )->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geography_df = transform_geographies_df(geography_df, var_prefix)\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "    survey_gdf = (\n",
    "        survey_gdf\n",
    "        .to_crs(geography_df.crs)\n",
    "        .sjoin(geography_df, how=\"left\")\n",
    "        .astype({f\"{var_prefix}_{selected_geography.lower()}\": \"Int32\"})\n",
    "        .drop(columns=['index_right'])\n",
    "    )\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps4386_coast = {\n",
    "    'lon': (-117.7,-117.1),\n",
    "    'lat': (32.535,33.385)\n",
    "}\n",
    "def rescue_adrift_respondents(\n",
    "        survey_df:pd.DataFrame,\n",
    "        geography_df:gpd.GeoDataFrame,\n",
    "        var_prefix:str\n",
    "        )->gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    geo_col = f\"{var_prefix}_{selected_geography.lower()}\"\n",
    "    geography_df = transform_geographies_df(geography_df, var_prefix)\n",
    "\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "    adrift_respondents_index = (\n",
    "        survey_gdf\n",
    "            .query(f'{geo_col}.isnull()')\n",
    "            .loc[survey_gdf[f'{var_prefix}_latitude'].between(eps4386_coast['lat'][0],eps4386_coast['lat'][1])]\n",
    "            .loc[survey_gdf[f'{var_prefix}_longitude'].between(eps4386_coast['lon'][0],eps4386_coast['lon'][1])]\n",
    "            .index\n",
    "    )\n",
    "    print(f'num adrift respondents: {adrift_respondents_index.shape}')\n",
    "    survey_gdf.loc[\n",
    "        adrift_respondents_index,\n",
    "        geo_col\n",
    "        ] = (\n",
    "                survey_gdf\n",
    "                .loc[adrift_respondents_index,'geometry']\n",
    "                .reset_index(drop=False)\n",
    "                .rename(columns={'index':'adrift_index'})\n",
    "                .to_crs(geography_df.crs)\n",
    "                .sjoin_nearest(geography_df, how=\"left\", max_distance = 100000)\n",
    "                .set_index('adrift_index')\n",
    "                .astype({geo_col: \"Int32\"})\n",
    "                [geo_col]\n",
    "                .values\n",
    "    )\n",
    "\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 100 * 5280 # max distance is 100 miles, but in feet\n",
    "def match_coordinates_to_nearby_external_taz(survey_df:pd.DataFrame, geography_df:gpd.GeoDataFrame, var_prefix:str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # select only external TAZs\n",
    "    geo_col = f\"{var_prefix}_{selected_geography.lower()}\"\n",
    "\n",
    "    geography_df = transform_geographies_df(geography_df.query(f'TAZ <= 12'), var_prefix)\n",
    "    geography_df['geometry'] = geography_df['geometry'].centroid\n",
    "    geography_df = gpd.GeoDataFrame(geography_df)\n",
    "\n",
    "    survey_gdf = make_survey_geodataframe(survey_df, var_prefix)\n",
    "\n",
    "    missing_taz_index = (\n",
    "        survey_df\n",
    "            .query(f'{geo_col}.isnull()')\n",
    "            .index\n",
    "    )\n",
    "    print(f'num respondents w/ {var_prefix} outside of county: {missing_taz_index.shape}')\n",
    "\n",
    "    closest_geographies = (\n",
    "                survey_gdf\n",
    "                .loc[missing_taz_index, 'geometry']\n",
    "                .reset_index(drop=False)\n",
    "                .rename(columns={'index':'missing_index'})\n",
    "                .to_crs(geography_df.crs)\n",
    "                .sjoin_nearest(geography_df, how=\"left\", distance_col = 'distance_between_points')\n",
    "                .groupby(['missing_index', geo_col])\n",
    "                ['distance_between_points']\n",
    "                .min()\n",
    "                .reset_index(drop=False)\n",
    "                .set_index('missing_index')\n",
    "                .astype({geo_col: \"Int32\"})\n",
    "        )\n",
    "    survey_gdf.loc[missing_taz_index,geo_col]=(\n",
    "        closest_geographies\n",
    "            .where(closest_geographies['distance_between_points'] < max_distance, None)\n",
    "            [geo_col]\n",
    "            # .values\n",
    "    )\n",
    "\n",
    "    survey_gdf.columns = [col.lower() for col in survey_gdf.columns]\n",
    "    return survey_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num adrift respondents: (9,)\n",
      "num adrift respondents: (0,)\n",
      "num adrift respondents: (4,)\n",
      "num adrift respondents: (0,)\n",
      "num adrift respondents: (0,)\n",
      "num respondents w/ origin outside of county: (270,)\n",
      "remaining null origin TAZs: 0\n"
     ]
    }
   ],
   "source": [
    "# process survey dataframe geographic features\n",
    "survey_respondent_geographies = survey_respondent.copy()\n",
    "for var_prefix in ['origin','destination','home_location','transit_boarding','transit_alighting']:\n",
    "    survey_respondent_geographies = sjoin_geographies(survey_respondent_geographies, geographies, var_prefix)\n",
    "    survey_respondent_geographies = rescue_adrift_respondents(survey_respondent_geographies, geographies, var_prefix)\n",
    "survey_respondent_geographies = match_coordinates_to_nearby_external_taz(survey_respondent_geographies, geographies, 'origin')\n",
    "print(f'remaining null origin TAZs: {survey_respondent_geographies['origin_taz'].isnull().sum()}')\n",
    "# survey_respondent_geographies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwe\\AppData\\Local\\Temp\\ipykernel_29924\\956501490.py:5: RuntimeWarning: Engine has switched to 'python' because numexpr does not support extension array dtypes. Please set your engine to python manually.\n",
      "  .query(f'transit_boarding_taz.isin({old_town_taz15})')\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "access_mode_grouped_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weight_departing_only",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "80b0d09b-9a25-44cb-b2c7-8ce5e26f86e1",
       "rows": [
        [
         "OTHER",
         "0.1820474921250302"
        ],
        [
         "PERSONAL_CAR_DROPPED_OFF_PICKED_UP",
         "6.821015811842828"
        ],
        [
         "PERSONAL_CAR_PARKED",
         "41.97919556985602"
        ],
        [
         "PUBLIC_TRANSPORTATION",
         "0.1820474921250302"
        ],
        [
         "RIDEHAIL_TAXI",
         "1.2743324448752116"
        ],
        [
         "WALK",
         "4.1317843823566545"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "access_mode_grouped_label\n",
       "OTHER                                  0.182047\n",
       "PERSONAL_CAR_DROPPED_OFF_PICKED_UP     6.821016\n",
       "PERSONAL_CAR_PARKED                   41.979196\n",
       "PUBLIC_TRANSPORTATION                  0.182047\n",
       "RIDEHAIL_TAXI                          1.274332\n",
       "WALK                                   4.131784\n",
       "Name: weight_departing_only, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many pax + employees board transit at Old Town\n",
    "old_town_taz15 = [1376,1385,1403]\n",
    "(\n",
    "    survey_respondent_geographies\n",
    "    .query(f'transit_boarding_taz.isin({old_town_taz15})')\n",
    "    # .query(f'destination_taz.isin({old_town_taz15})') #null\n",
    "    .groupby('access_mode_grouped_label')\n",
    "    ['weight_departing_only']\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rental car destinations\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.boundary.plot(ax = ax, color = 'red', alpha = .1)\n",
    "# (\n",
    "#     make_survey_geodataframe(\n",
    "#         (survey_respondent_geographies\n",
    "#             .query('main_mode_grouped_label == \"RENTAL_CAR\"')\n",
    "#             .query('weight_departing_only>0')\n",
    "#         ),\n",
    "#         var_prefix='destination')\n",
    "#     .to_crs(geographies.crs)\n",
    "#     .plot(ax = ax, alpha = 1, color = 'gray')#, column='weight_departing_opn', legend=True)\n",
    "# )\n",
    "# # zoom in on central SD\n",
    "# plt.xlim((6.25e6,6.35e6))\n",
    "# plt.ylim((1.8e6,1.95e6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # heatmap\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.plot(ax = ax, color = 'red', alpha = .1)\n",
    "\n",
    "# selected_geography_survey_weights = survey_respondent_geographies.groupby(f'{var_prefix}_{selected_geography.lower()}')['weight'].sum()\n",
    "# geographies_survey_weights = (\n",
    "#                     geographies.merge(\n",
    "#                         selected_geography_survey_weights,\n",
    "#                         left_on=selected_geography,\n",
    "#                         right_on=f'{var_prefix}_{selected_geography.lower()}'\n",
    "#                   )\n",
    "# )\n",
    "\n",
    "# geographies_survey_weights.to_crs(geographies.crs).plot(ax = ax, alpha = .5, column='weight', legend=True)\n",
    "# plt.xlim((6.15e6,6.65e6))\n",
    "# plt.ylim((1.75e6,2.2e6))\n",
    "\n",
    "# # zoom in on central SD\n",
    "# plt.xlim((6.25e6,6.35e6))\n",
    "# plt.ylim((1.8e6,1.95e6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check adrift respondents OR check null all resp[ondents]\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'orange', alpha = .1)\n",
    "\n",
    "# survey_mgra_df = gpd.GeoDataFrame(\n",
    "#                 survey_respondent_geographies,\n",
    "#                 geometry=gpd.points_from_xy(\n",
    "#                     survey_respondent_geographies[f\"{var_prefix}_longitude\"], survey_respondent_geographies[f\"{var_prefix}_latitude\"]\n",
    "#                 ),\n",
    "#                 crs=survey_crs,\n",
    "#             )\n",
    "# # survey_mgra_df.query('~origin_taz.isnull()').to_crs(geographies.crs).plot(ax = ax, alpha = .5)\n",
    "# (\n",
    "#     survey_mgra_df\n",
    "#     .query(f'{var_prefix}_taz.isnull()')\n",
    "#     # .loc[survey_mgra_df[f'{var_prefix}_latitude'].between(32.55,33)]\n",
    "#     # .loc[survey_mgra_df[f'{var_prefix}_longitude'].between(-117.5,-117)]\n",
    "#     .plot(ax = ax, alpha = .5, color = 'gray')\n",
    "# )\n",
    "\n",
    "# geographies.query('TAZ < 12').to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "\n",
    "# # plt.xlim((-117.5,-117))\n",
    "# # plt.ylim((32.55,33))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # origin coordinates missing TAZs\n",
    "# var_prefix = \"origin\"\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'orange', alpha = .1)\n",
    "\n",
    "# survey_mgra_df = gpd.GeoDataFrame(\n",
    "#                 survey_respondent_geographies,\n",
    "#                 geometry=gpd.points_from_xy(\n",
    "#                     survey_respondent_geographies[f\"{var_prefix}_longitude\"], survey_respondent_geographies[f\"{var_prefix}_latitude\"]\n",
    "#                 ),\n",
    "#                 crs=survey_crs,\n",
    "#             )\n",
    "# survey_mgra_df.query(f'{var_prefix}_taz.isnull()').plot(ax = ax, alpha = .5, label = 'missing_TAZ')\n",
    "# # survey_mgra_df.query(f'{var_prefix}_taz.notna()').plot(ax = ax, alpha = .5, color = 'gray', label = 'has_TAZ')\n",
    "# plt.legend()\n",
    "\n",
    "# # geographies.query('TAZ < 12').to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "# geographies.to_crs(survey_crs).plot(ax = ax, color = 'red', alpha = 1)\n",
    "\n",
    "# # plt.xlim((-117.7,-116))\n",
    "# # plt.ylim((32.5,33.5))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skims - Auto and Transit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skim Reading Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drops 0 respondents\n"
     ]
    }
   ],
   "source": [
    "survey_output = survey_respondent_geographies.query('(origin_taz.notna()) and (destination_taz.notna())')\n",
    "print(f'Drops {survey_respondent_geographies.shape[0] - survey_output.shape[0]} respondents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_path = os.path.join(base_scenario_path,'output','skims')\n",
    "transit_am_skims_path = os.path.join(skim_path,'transit_skims_AM.omx')\n",
    "traffic_am_skims_path = os.path.join(skim_path,'traffic_skims_AM.omx')\n",
    "\n",
    "traffic_am_skims = omx.open_file(traffic_am_skims_path, 'r')\n",
    "transit_am_skims = omx.open_file(transit_am_skims_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_omx(veh_type:str, tod:str):\n",
    "    \"\"\" Navigate to and open skims\n",
    "\n",
    "    Args:\n",
    "        veh_typ (str): 'traffic' or 'transit'\n",
    "        tod (str): uppercase time-of-day value ('EA','AM','MD','PM','EV')\n",
    "\n",
    "    Returns:\n",
    "        omx_file: target skim\n",
    "    \"\"\"\n",
    "    if veh_type not in ('traffic', 'transit') or tod not in ('EA','AM','MD','PM','EV'):\n",
    "        raise ValueError('Invalid argument for function \"open_omx()\"')\n",
    "    skim_path = os.path.join(base_scenario_path,'output','skims',f'{veh_type}_skims_{tod}.omx')\n",
    "    omx_file = omx.open_file(skim_path, 'r')\n",
    "\n",
    "    return omx_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_skims(skims, values)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert skims from omx to pandas DataFrame\n",
    "    \"\"\"\n",
    "    zones = list(skims.mapping('zone_number').keys())\n",
    "    df = pd.DataFrame(\n",
    "        np.array(skims[values]),\n",
    "        zones,\n",
    "        zones\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_skim_value(\n",
    "        row,\n",
    "        skim,\n",
    "        set_zero_val_to_null=False,\n",
    "        origin_col='origin_taz',\n",
    "        destination_col = 'destination_taz'\n",
    "        ):\n",
    "    \"\"\"Pandas .apply() function that gets skim values for O-D TAZ pairs\n",
    "    \"\"\"\n",
    "    value = skim.loc[row[origin_col], row[destination_col]]\n",
    "    if set_zero_val_to_null and value == 0:\n",
    "        value = None\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOD Binning for Respondents\n",
    "https://github.com/SANDAG/ABM/blob/87c3eac743973719d02ffba5b46bb81123e337ac/docs/inputs.md?plain=1#L268\n",
    "- EA = Early morning (3am - 5:59am)<br>\n",
    "- AM = AM peak (6am to 8:59am)<br>\n",
    "- MD = Mid-day (9am to 3:29pm)<br>\n",
    "- PM = PM peak (3:30pm to 6:59pm)<br>\n",
    "- EV = Evening (7pm to 2:59am)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_output[['skim_tod','trip_start_time','trip_start_time_label']].drop_duplicates().sort_values(by='trip_start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_list = ['EA','AM','MD','PM','EV','EA']\n",
    "time_cut = [0,2,8,21,28,44,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_output.loc[:,'skim_tod'] = (\n",
    "    pd.cut(\n",
    "        survey_output['trip_start_time'],\n",
    "        bins = time_cut,\n",
    "        right = True,\n",
    "        include_lowest = True,\n",
    "        labels = tod_list,\n",
    "        ordered = False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjustments for Irregular Transit Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # some respondents drove long distances to Old Town/Rt992/etc to take transit to the airport\n",
    "    # # these respondents need to have custom skim calcs\n",
    "# drop_off_transit_unique_ids = [90,699,1075,1109,1209,1267,1608,1635,3381,5229]\n",
    "# drop_off_transit_unique_id_index = survey_output.query(f'unique_id.isin({drop_off_transit_unique_ids})').index.copy()\n",
    "# survey_output.loc[drop_off_transit_unique_id_index, 'transit_and_auto_costs'] = True\n",
    "\n",
    "# # preserve to compare access times\n",
    "# survey_output['auto_origin_taz'] = survey_output['origin_taz']\n",
    "# survey_output.loc[:,'auto_destination_taz'] = survey_output['destination_taz'].copy()\n",
    "# survey_output.loc[drop_off_transit_unique_id_index,'auto_destination_taz'] = survey_output.loc[drop_off_transit_unique_id_index,'transit_boarding_taz']\n",
    "\n",
    "# # TODO currently not used\n",
    "# TODO - apply to ALL null times, not just transit options\n",
    "survey_output.loc[:,'transit_origin_taz'] = survey_output['origin_taz'].copy()\n",
    "# survey_output.loc[drop_off_transit_unique_id_index,'transit_origin_taz'] = survey_output.loc[drop_off_transit_unique_id_index,'transit_boarding_taz']\n",
    "# survey_output['transit_destination_taz'] = survey_output['destination_taz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_modes = ['DROVE_ALONE_AND_PARKED','GET_IN_PARKED_VEHICLE_AND_DRIVE_WITH_OTHERS',\n",
    "#        'DROPPED_OFF_BY_FAMILY_FRIEND','UBER_LYFT', 'HOTEL_SHUTTLE_VAN', 'DROVE_WITH_OTHERS_AND_PARKED',\n",
    "#        'CAR_SERVICE_BLACK_LIMO', 'PICKED_UP_BY_FAMILY_FRIEND','GET_IN_PARKED_VEHICLE_AND_DRIVE_ALONE',\n",
    "#        'BICYCLE_PERSONAL_ELECTRIC', 'RENTAL_CAR_PARKED','RENTAL_CAR_DROPPED_OFF', 'TAXI',\n",
    "#        'GET_IN_PARKED_VEHICLE_AND_RIDE_WITH_OTHER_TRAVELERS','RENTAL_CAR_PICKED_UP', 'RENTAL_CAR_GET_IN_PARKED',\n",
    "#        'OTHER_SHARED_VAN', 'CHARTERED_TOUR_BUS','RODE_WITH_OTHER_TRAVELERS_AND_PARKED','EMPLOYEE_SHUTTLE']\n",
    "# transit_modes = ['AIRPORT_FLYER_SHUTTLE','MTS_ROUTE_992','OTHER_PUBLIC_TRANSIT']\n",
    "# at_modes = ['WALK', 'BICYCLE_PERSONAL_NON_ELECTRIC','E_SCOOTER_PERSONAL', 'BICYCLE_NON_ELECTRIC_BIKESHARE',\n",
    "#             'BICYCLE_ELECTRIC_BIKESHARE', 'WHEELCHAIR_OR_MOBILITY_DEVICE']\n",
    "# other_modes = ['OTHER']\n",
    "\n",
    "# auto_mode_index = survey_output.query(f'main_mode_label.isin({auto_modes})').index\n",
    "# auto_mode_index = auto_mode_index.tolist() + drop_off_transit_unique_id_index.tolist()\n",
    "# transit_mode_index = survey_output.query(f'main_mode_label.isin({transit_modes})').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_transit_tazs = {\n",
    "    4: 4587,\n",
    "    # 6:\n",
    "    # 7:\n",
    "    8: 2345,\n",
    "    9: 2196,\n",
    "    10: 1930,\n",
    "    12: 15,\n",
    "    14: 15,\n",
    "    17: 42,\n",
    "    71: 42,\n",
    "    1394: 1200,\n",
    "    1457: 1472,\n",
    "    2119: 1930,\n",
    "    2138: 1930,\n",
    "    3657: 1930,\n",
    "    3733: 1930,\n",
    "    4705: 4586,\n",
    "    4712: 4586,\n",
    "    4739: 4586,\n",
    "    4747: 4586,\n",
    "    4754: 4586,\n",
    "    # 4836:\n",
    "    # 4863:\n",
    "    # 4876:\n",
    "    # 4877:\n",
    "    # 4890:\n",
    "    # 4894:\n",
    "}\n",
    "\n",
    "survey_output['transit_origin_taz'] = survey_output['origin_taz'].replace(map_transit_tazs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Skims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in auto skims\n",
    "auto_skim_names = ['SOV_NT_M_DIST','SOV_NT_M_TIME','SOV_NT_M_TOLLCOST']\n",
    "auto_skim_new_names = ['auto_dist','auto_time','auto_tollcost']\n",
    "transit_boarding_index = survey_output['transit_boarding_taz'].notna()\n",
    "\n",
    "for tod in tod_list:\n",
    "    tod_omx_file = open_omx('traffic',tod)\n",
    "    tod_index = (survey_output['skim_tod']==tod)\n",
    "    for skim_name,col_name in zip(auto_skim_names,auto_skim_new_names):\n",
    "        skim = read_skims(tod_omx_file,f'{skim_name}__{tod}')\n",
    "        # get auto skims for all survey respondents\n",
    "        survey_output.loc[tod_index,col_name] = (\n",
    "            survey_output\n",
    "            .loc[tod_index]\n",
    "            .apply(retrieve_skim_value,\n",
    "                    skim = skim,\n",
    "                    set_zero_val_to_null = (col_name in ['auto_dist','auto_time']),\n",
    "                    axis = 1)\n",
    "            )\n",
    "        # generate comparisons for transit ACC times\n",
    "        if col_name == 'auto_time':\n",
    "            survey_output.loc[tod_index * transit_boarding_index,'auto_to_transit_time'] = (\n",
    "                survey_output\n",
    "                .loc[tod_index * transit_boarding_index]\n",
    "                .apply(retrieve_skim_value,\n",
    "                        skim=skim,\n",
    "                        destination_col='transit_boarding_taz',\n",
    "                        set_zero_val_to_null=True,\n",
    "                        axis=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in transit skims\n",
    "transit_access_modes = ['PNROUT','WALK']\n",
    "transit_flavors = ['LOC','MIX','PRM']\n",
    "transit_values = ['ACC','FIRSTWAIT','TOTALIVTT','XFERWAIT','EGR','FARE','XFERS']\n",
    "\n",
    "for tod in tod_list:\n",
    "    tod_omx_file = open_omx('transit',tod)\n",
    "    tod_index = (survey_output['skim_tod']==tod)\n",
    "    for transit_access_mode in transit_access_modes:\n",
    "        for transit_flavor in transit_flavors:\n",
    "            transit_mode = f'{transit_access_mode}_{transit_flavor}'.lower()\n",
    "            survey_output[f'{transit_mode}_time'] = 0.0\n",
    "            for transit_value in transit_values:\n",
    "                col_name = f'{transit_mode}_{transit_value.lower()}'\n",
    "                skim = read_skims(tod_omx_file,f'{col_name.upper()}__{tod}')\n",
    "                survey_output.loc[tod_index, col_name] = (\n",
    "                    survey_output\n",
    "                    .loc[tod_index]\n",
    "                    .apply(retrieve_skim_value,\n",
    "                            skim = skim,\n",
    "                            origin_col = 'transit_origin_taz',\n",
    "                            set_zero_val_to_null = (transit_value=='FARE'),\n",
    "                            axis = 1)\n",
    "                    )\n",
    "                    # survey_output.drop(\n",
    "                    #     columns=[f'{transit_mode}_{transit_value}'],\n",
    "                    #     inplace=True\n",
    "                    #     )\n",
    "            # # set transit trips w/ total time = 0 to NULL\n",
    "            # survey_output.loc[\n",
    "            #         tod_index * (survey_output[f'{transit_mode}_time']==0),\n",
    "            #         f'{transit_mode}_time'\n",
    "            #     ] = None\n",
    "# survey_output.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transit adjustments for coaster riders\n",
    "#     # coming from Camp Pendleton\n",
    "# survey_output.loc[\n",
    "#     survey_output['unique_id'].isin([3464,4453]),\n",
    "#     ['pnrout_prm_acc','pnrout_prm_time']\n",
    "#     ] += 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total transit travel times\n",
    "for transit_access_mode in transit_access_modes:\n",
    "    for transit_flavor in transit_flavors:\n",
    "        transit_mode = f'{transit_access_mode}_{transit_flavor}'.lower()\n",
    "        survey_output[f'{transit_mode}_time'] = (\n",
    "            survey_output[[\n",
    "                    f'{transit_mode}_acc',\n",
    "                    f'{transit_mode}_firstwait',\n",
    "                    f'{transit_mode}_xferwait',\n",
    "                    f'{transit_mode}_totalivtt',\n",
    "                    f'{transit_mode}_egr'\n",
    "                ]].sum(axis=1)\n",
    "        )\n",
    "\n",
    "        # transit trips cannot have 0 trip time\n",
    "        survey_output.loc[\n",
    "                survey_output[f'{transit_mode}_time'] == 0,\n",
    "                f'{transit_mode}_time'\n",
    "            ] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_mode = ['MTS_ROUTE_992','AIRPORT_FLYER_SHUTTLE','OTHER_PUBLIC_TRANSIT']\n",
    "transit_mode_index = survey_output.query(f'main_mode_label.isin({transit_mode})').index\n",
    "# survey_output.loc[transit_mode_index].fillna('------').groupby(['access_mode','access_mode_label'])['unique_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify transit access to match to skims\n",
    "    # PNR access is (2.0)\n",
    "    # walk acccess code is (1.0)\n",
    "survey_output['simplified_transit_access'] = (survey_output.loc[transit_mode_index, 'access_mode'] != 1.0) + 1\n",
    "survey_output['simplified_transit_access'] = survey_output['simplified_transit_access'].fillna(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_transit_cols = ['walk_loc_time','walk_mix_time','walk_prm_time','walk_loc_fare','walk_mix_fare','walk_prm_fare']\n",
    "prm_transit_cols = ['pnrout_loc_time','pnrout_mix_time','pnrout_prm_time','pnrout_loc_fare','pnrout_mix_fare','pnrout_prm_fare']\n",
    "all_time_cols = walk_transit_cols[:3] + prm_transit_cols[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# walk to transit has transit type w/ lowest walk to transit stop transit travel times\n",
    "survey_output.loc[\n",
    "        survey_output['simplified_transit_access'] == 1,\n",
    "        'transit_type'\n",
    "    ] = (\n",
    "    survey_output\n",
    "        .loc[\n",
    "            survey_output['simplified_transit_access'] == 1,\n",
    "            walk_transit_cols[:3] # transit time columns\n",
    "            ] #WALK\n",
    "        .idxmin(skipna=True, axis=1)\n",
    "        .str.rsplit('_', n=1, expand = True)\n",
    "        [0]\n",
    "    )\n",
    "# not walk to transit gets lowest transit travel time\n",
    "survey_output.loc[\n",
    "        survey_output['simplified_transit_access'] == 2,\n",
    "        'transit_type'\n",
    "    ] = (\n",
    "    survey_output\n",
    "        .loc[\n",
    "            (survey_output['simplified_transit_access'] == 2) # NOT WALK transit access\n",
    "            ,all_time_cols # transit time columns, take lowest between walk and prm -> some walk less than prm\n",
    "            ]\n",
    "        .idxmin(skipna=True, axis=1)\n",
    "        .str.rsplit('_', n=1, expand = True)\n",
    "        [0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get times and fares for each respondent riding transit based on transit_type column\n",
    "transit_type_index = survey_output.query('transit_type.notna()').index\n",
    "for metric in ['time','fare', 'acc', 'firstwait', 'totalivtt', 'xferwait', 'egr', 'xfers']:\n",
    "    survey_output.loc[:, f'transit_{metric}'] = (\n",
    "        survey_output\n",
    "        .loc[transit_type_index]\n",
    "        .apply(lambda x: x[f\"{x['transit_type']}_{metric}\"], axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    survey_output\n",
    "    .to_csv(survey_data_matched_geographies)#, index_label = 'unique_id')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
